# Trademark Similarity Prediction API

[![Python Version](https://img.shields.io/badge/python-3.10%2B-blue.svg)](https://www.python.org/)
[![Framework](https://img.shields.io/badge/FastAPI-0.100%2B-green.svg)](https://fastapi.tiangolo.com/)

## Overview

This project provides a backend API designed to assist trademark lawyers by comparing two trademarks (wordmarks) and their associated goods/services. It predicts the likelihood and potential outcome of a trademark opposition case using multi-faceted similarity analysis powered by Google's Gemini 2.5 Pro large language model via Vertex AI.

The API requires authentication using Firebase Authentication.

## Core Features

-   **Multi-faceted Mark Similarity:**
    -   **Visual:** Levenshtein distance between wordmarks.
    -   **Aural:** Double Metaphone phonetic encoding compared using Levenshtein distance.
    -   **Conceptual:** Semantic similarity assessed by the Gemini LLM.
-   **Goods & Services Analysis:** Compares applicant and opponent goods/services based on their terms and Nice classifications, assessing similarity, competitiveness, and complementarity using the LLM.
-   **Likelihood of Confusion Assessment:** The LLM synthesizes mark and G&S comparisons to determine the overall likelihood of confusion.
-   **Structured Outcome Prediction:** Provides a categorized outcome (e.g., "Opposition likely to succeed"), a confidence score, and detailed reasoning generated by the LLM.

## Tech Stack

-   **API Framework:** FastAPI
-   **Cloud Platform:** Google Cloud (Deployed via Cloud Functions/Run)
-   **Authentication:** Firebase Authentication
-   **Language Model:** Google Vertex AI (Gemini 2.5 Pro)
-   **Language:** Python 3.11
-   **Linting/Formatting:** Ruff
-   **Testing:** Pytest

## API Reference

### Base URL

The API is hosted on Google Cloud Functions. Obtain the specific function URL after deployment.
Example format:
`https://<region>-<your-gcp-project-id>.cloudfunctions.net/<function-name>`

*Replace placeholders with your actual deployment details.* 

### Authentication

All requests to the `/predict` endpoint **must** include a valid Firebase ID Token in the `Authorization` header.

-   **Header:** `Authorization: Bearer <FIREBASE_ID_TOKEN>`

Clients must authenticate using Firebase Authentication (e.g., via the Firebase Web SDK) to obtain this token before calling the API.

### Endpoints

#### 1. Health Check

-   **Endpoint:** `/health`
-   **Method:** `GET`
-   **Authentication:** None required.
-   **Description:** Verifies API availability.
-   **Example Request:**
    ```bash
    curl https://<your-function-url>/health
    ```
-   **Success Response (200 OK):**
    ```json
    {"status": "ok"}
    ```

#### 2. Predict Opposition Outcome

-   **Endpoint:** `/predict`
-   **Method:** `POST`
-   **Authentication:** Firebase ID Token required (Bearer Token).
-   **Description:** Analyzes trademarks and goods/services to predict opposition outcome.
-   **Request Body:** A JSON object conforming to the `PredictionRequest` schema.
    ```typescript
    // Request Body Schema (from trademark_core/models.py)
    interface PredictionRequest {
      applicant: Mark;
      opponent: Mark;
      applicant_goods: GoodService[]; // max_length: 3
      opponent_goods: GoodService[]; // max_length: 3
    }

    interface Mark {
      wordmark: string;
      is_registered?: boolean; // default: false
      registration_number?: string | null;
    }

    interface GoodService {
      term: string;
      nice_class: number; // 1-45
    }
    ```
-   **Example Request:**
    ```bash
    # Replace <FIREBASE_ID_TOKEN> with a valid token
    # Replace <your-function-url> with the deployed URL
    curl -X POST https://<your-function-url>/predict \
      -H "Authorization: Bearer <FIREBASE_ID_TOKEN>" \
      -H "Content-Type: application/json" \
      -d '{
        "applicant": {
          "wordmark": "CloudCanvas"
        },
        "opponent": {
          "wordmark": "Kloud Kanvas",
          "is_registered": true,
          "registration_number": "UK7654321"
        },
        "applicant_goods": [
          {"term": "Platform as a service (PAAS)", "nice_class": 42},
          {"term": "Software as a service (SAAS)", "nice_class": 42}
        ],
        "opponent_goods": [
          {"term": "Computer software development tools", "nice_class": 9},
          {"term": "Cloud computing services", "nice_class": 42}
        ]
      }'
    ```
-   **Response Body:** A JSON object conforming to the `CasePrediction` schema.
    ```typescript
    // Response Body Schema (from trademark_core/models.py)
    type EnumStr = "dissimilar" | "low" | "moderate" | "high" | "identical";
    type OppositionResultEnum = "Opposition likely to succeed" | "Opposition may partially succeed" | "Opposition likely to fail";

    interface CasePrediction {
      mark_comparison: MarkComparison;
      goods_services_comparisons: GoodServiceComparison[];
      likelihood_of_confusion: boolean;
      opposition_outcome: OppositionOutcome;
    }

    interface MarkComparison {
      visual: EnumStr;
      aural: EnumStr;
      conceptual: EnumStr;
      overall: EnumStr;
    }

    interface GoodServiceComparison {
      applicant_good: GoodService;
      opponent_good: GoodService;
      overall_similarity: EnumStr;
      are_competitive: boolean;
      are_complementary: boolean;
    }

    interface OppositionOutcome {
      result: OppositionResultEnum;
      confidence: number; // 0.0 to 1.0
      reasoning: string;
    }
    // Note: GoodService and Mark interfaces are as defined in the request section.
    ```
-   **Example Response Snippet (Structure):**
    ```json
    {
      "mark_comparison": {
        "visual": "high",
        "aural": "high",
        "conceptual": "moderate",
        "overall": "high"
      },
      "goods_services_comparisons": [
        {
          "applicant_good": {
            "term": "Platform as a service (PAAS)",
            "nice_class": 42
          },
          "opponent_good": {
            "term": "Computer software development tools",
            "nice_class": 9
          },
          "overall_similarity": "low",
          "are_competitive": false,
          "are_complementary": true
        },
        {
          "applicant_good": {
            "term": "Platform as a service (PAAS)",
            "nice_class": 42
          },
          "opponent_good": {
            "term": "Cloud computing services",
            "nice_class": 42
          },
          "overall_similarity": "high",
          "are_competitive": true,
          "are_complementary": false
        }
        // ... more comparisons for other pairs ...
      ],
      "likelihood_of_confusion": true,
      "opposition_outcome": {
        "result": "Opposition likely to succeed",
        "confidence": 0.85,
        "reasoning": "The marks exhibit high visual and aural similarity... The goods/services in class 42 are highly related and competitive..."
      }
    }
    ```
-   **Error Responses:**
    -   `401 Unauthorized`: Missing, invalid, or expired Firebase token.
    -   `422 Unprocessable Entity`: Request body validation failed (e.g., missing fields, incorrect types).
    -   `500 Internal Server Error`: Unexpected error during prediction processing (e.g., LLM API issue).

## Project Structure

```
trademark_prod/
├── .gcloudignore           # Files ignored by gcloud CLI deployments
├── .gitignore              # Files ignored by Git
├── .pytest_cache/          # pytest cache
├── .ruff_cache/            # Ruff linter cache
├── .env.yaml               # Environment variables for cloud deployment (sensitive)
├── env.example             # Template for environment variables
├── api/
│   ├── __init__.py
│   ├── auth.py             # Firebase Authentication dependency logic
│   └── main.py             # FastAPI app definition, CORS, /health, /predict endpoints
├── trademark_core/
│   ├── __init__.py
│   ├── llm.py              # Gemini LLM interaction logic, structured output generation
│   ├── models.py           # Pydantic models (SSoT for API schemas & internal data)
│   ├── prompts.py          # Central store for LLM prompt templates
│   └── similarity.py       # Visual, Aural, Conceptual similarity calculation logic
├── tests/                  # Automated tests
│   ├── __init__.py
│   └── # ... test files ...
├── main.py                 # Cloud Functions entry point (imports app from api.main)
├── pyproject.toml          # Project metadata & dependencies (Poetry or similar)
├── requirements.txt        # Project dependencies (pip format)
└── README.md               # This file
```

### Key File Descriptions

*   **`README.md`**: Project overview, API usage, setup instructions.
*   **`main.py` (root)**: Entry point for Google Cloud Functions.
*   **`api/main.py`**: Defines the FastAPI application, middleware (CORS), authentication dependency (`api/auth.py`), and the `/health` and `/predict` endpoints. It orchestrates the request flow.
*   **`api/auth.py`**: Handles Firebase ID token verification logic for securing endpoints.
*   **`trademark_core/models.py`**: **Single Source of Truth (SSoT)** for all data structures using Pydantic. Defines the exact request (`PredictionRequest`) and response (`CasePrediction`) schemas for the `/predict` API endpoint.
*   **`trademark_core/similarity.py`**: Contains functions to calculate visual, aural, and conceptual similarity scores. Calls `llm.py` for the conceptual part.
*   **`trademark_core/llm.py`**: Manages interaction with the Google Vertex AI Gemini model. Uses prompts from `prompts.py`, sends requests, parses structured JSON responses, and handles LLM API errors. Contains `generate_full_prediction` which synthesizes all inputs into the final prediction.
*   **`trademark_core/prompts.py`**: Stores all f-string templates used to prompt the Gemini LLM.
*   **`tests/`**: Contains unit and integration tests.
*   **`pyproject.toml` / `requirements.txt`**: Define project dependencies.
*   **`.env.example` / `.env.yaml`**: Template and actual configuration for environment variables (GCP Project ID, API keys, etc.). **Sensitive files should not be committed to Git.**

## Local Development (For Contributors)

1.  **Prerequisites:**
    *   Python 3.11
    *   Git
    *   Access to a Google Cloud Project with Vertex AI enabled.
    *   Firebase Project set up for authentication.
    *   `gcloud` CLI installed and authenticated (`gcloud auth application-default login`).
2.  **Clone:**
    ```bash
    git clone <repository-url>
    cd trademark_prod
    ```
3.  **Virtual Environment (Recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate # Linux/macOS
    # venv\Scripts\activate # Windows
    ```
4.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
5.  **Environment Variables:**
    *   Copy `env.example` to a new file named `.env` (this file is gitignored).
    *   Fill in the required values in `.env`, especially:
        *   `GOOGLE_CLOUD_PROJECT`: Your GCP Project ID.
        *   `GOOGLE_CLOUD_LOCATION`: The region for Vertex AI (e.g., `us-central1`).
    *   Ensure your environment is configured for Application Default Credentials (ADC) by running `gcloud auth application-default login`.
6.  **Run Tests:**
    ```bash
    pytest
    ```
7.  **Linting/Formatting:**
    ```bash
    ruff check .
    ruff format .
    ```
8.  **Run Server Locally:**
    *   Ensure environment variables from `.env` are loaded (e.g., using `python-dotenv` implicitly via FastAPI/Uvicorn or exporting them manually).
    ```bash
    # Requires uvicorn installed (pip install uvicorn)
    uvicorn api.main:app --reload --host 0.0.0.0 --port 8000
    ```
    *   The server will be available at `http://localhost:8000`. You'll need a valid Firebase ID token to test the `/predict` endpoint locally (e.g., obtained from a test frontend).

## Deployment

This application is designed for deployment to Google Cloud Functions (or potentially Cloud Run).

-   Ensure `requirements.txt` is up-to-date.
-   Use the `gcloud functions deploy` command, specifying the entry point (`app` from `main.py`), runtime, region, and necessary environment variables (can be set via `.env.yaml` or command-line flags).
-   Configure appropriate IAM permissions for the function's service account to access Vertex AI.

Refer to Google Cloud Functions documentation for detailed deployment steps.

