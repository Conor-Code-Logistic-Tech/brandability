"""
Single source of truth (SSoT) for all data models in the Trademark-AI system.

This module defines the core Pydantic models used across the API layer, domain logic,
and tests. These models serve as the canonical schema definitions and should never
be redeclared elsewhere in the codebase.
"""

from typing import Annotated, Literal

from pydantic import BaseModel, Field

# Define EnumStr here for MarkComparison consistency, generated by LLM
EnumStr = Literal["dissimilar", "low", "moderate", "high", "identical"]
# Define OppositionOutcome result literals
OppositionResultEnum = Literal["Opposition likely to succeed", "Opposition may partially succeed", "Opposition likely to fail"]
# Define ConfusionType literals
ConfusionTypeEnum = Literal["direct", "indirect"]


class Mark(BaseModel):
    """A trademark mark, consisting of text and registration details."""
    wordmark: str = Field(..., description="Literal mark text, case-sensitive")
    is_registered: bool = False
    registration_number: str | None = None


class GoodService(BaseModel):
    """A single good or service term in a Nice class."""
    term: str = Field(..., description="The good or service term")
    nice_class: int = Field(..., ge=1, le=45, description="The Nice Classification class number (1-45)")


# Model for conceptual similarity score calculation input/output
class ConceptualSimilarityScore(BaseModel):
    """Numeric score for conceptual similarity (0.0-1.0)."""
    score: Annotated[float, Field(ge=0.0, le=1.0)] = Field(..., description="Conceptual similarity score")


# Model for mark similarity assessment - used by /mark_similarity endpoint
class MarkSimilarityOutput(BaseModel):
    """Detailed assessment of mark similarity across multiple dimensions."""
    visual: EnumStr = Field(..., description="Visual similarity category")
    aural: EnumStr = Field(..., description="Aural similarity category")  
    conceptual: EnumStr = Field(..., description="Conceptual similarity category")
    overall: EnumStr = Field(..., description="Overall similarity category considering all dimensions")
    reasoning: str | None = Field(None, description="Optional reasoning for the overall assessment")


# Model for goods service likelihood assessment - used by /gs_similarity endpoint
class GoodServiceLikelihoodOutput(BaseModel):
    """Detailed assessment of goods/service similarity and likelihood of confusion."""
    are_competitive: bool = Field(..., description="Whether the goods/services compete in the marketplace")
    are_complementary: bool = Field(..., description="Whether the goods/services are complementary or used together")
    similarity_score: Annotated[float, Field(ge=0.0, le=1.0)] = Field(..., description="Similarity score between the goods/services")
    likelihood_of_confusion: bool = Field(..., description="Whether there is a likelihood of confusion for this G/S pair considering mark similarity")
    confusion_type: ConfusionTypeEnum | None = Field(None, description="Type of confusion (null if no likelihood)")


# Model for the structured opposition outcome - keeping the existing one
class OppositionOutcome(BaseModel):
    """Structured prediction of the opposition outcome."""
    result: OppositionResultEnum = Field(..., description="The predicted outcome category")
    confidence: Annotated[float, Field(ge=0.0, le=1.0)] = Field(..., description="Confidence score (0.0 to 1.0) for the prediction")
    reasoning: str = Field(..., description="Detailed reasoning supporting the predicted outcome and confidence")


# New model for the full case prediction result
class CasePredictionResult(BaseModel):
    """Complete trademark opposition case prediction including mark similarity and goods/services likelihoods."""
    mark_comparison: MarkSimilarityOutput = Field(..., description="Detailed mark similarity assessment")
    goods_services_likelihoods: list[GoodServiceLikelihoodOutput] = Field(..., description="List of detailed likelihood assessments for each applicant vs. opponent good/service pair")
    opposition_outcome: OppositionOutcome = Field(..., description="Structured prediction of the opposition outcome including reasoning")


# Model for comparison of two wordmarks
class MarkSimilarityRequest(BaseModel):
    """Input for mark similarity assessment."""
    applicant: Mark = Field(..., description="The applicant's mark details")
    opponent: Mark = Field(..., description="The opponent's mark details")


# Model for goods/services similarity and likelihood of confusion
class GsSimilarityRequest(BaseModel):
    """Input for goods/services similarity and likelihood assessment."""
    applicant_good: GoodService = Field(..., description="The applicant's good/service")
    opponent_good: GoodService = Field(..., description="The opponent's good/service")
    mark_similarity: MarkSimilarityOutput = Field(..., description="Mark similarity assessment from /mark_similarity endpoint")


# Model for batch goods/services similarity processing
class BatchGsSimilarityRequest(BaseModel):
    """Input for batch processing of multiple goods/services similarity assessments."""
    applicant_goods: list[GoodService] = Field(..., min_length=1, description="List of the applicant's goods/services")
    opponent_goods: list[GoodService] = Field(..., min_length=1, description="List of the opponent's goods/services")
    mark_similarity: MarkSimilarityOutput = Field(..., description="Mark similarity assessment from /mark_similarity endpoint")


# Model for the case prediction based on previous assessments
class CasePredictionRequest(BaseModel):
    """Input for final case prediction."""
    mark_similarity: MarkSimilarityOutput = Field(..., description="The mark similarity assessment from /mark_similarity endpoint")
    goods_services_likelihoods: list[GoodServiceLikelihoodOutput] = Field(..., min_length=1, description="The G/S likelihood assessments from /gs_similarity endpoint")
