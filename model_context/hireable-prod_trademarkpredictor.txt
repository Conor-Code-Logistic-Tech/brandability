Directory structure:
└── hireable-prod_trademarkpredictor/
    ├── README.md
    ├── deploy.sh
    ├── Dockerfile
    ├── main.py
    ├── Procfile
    ├── requirements.txt
    ├── .cursorrules
    ├── .env.example
    ├── .gcloudignore
    ├── src/
    │   ├── __init__.py
    │   ├── db.py
    │   ├── embeddings.py
    │   ├── gemini_agent_prompt.py
    │   ├── logger.py
    │   ├── main.py
    │   ├── models.py
    │   ├── similarity.py
    │   ├── __pycache__/
    │   └── tools/
    │       ├── __init__.py
    │       ├── prediction_tools.py
    │       └── similarity_tools.py
    ├── supabase/
    │   ├── config.toml
    │   └── migrations/
    │       ├── 20250404021823_remote_schema.sql
    │       └── _alter_embedding_dimension.sql
    └── tests/
        ├── __init__.py
        ├── test_main.py
        ├── test_prediction_tools.py
        ├── test_similarity_all.py
        └── __pycache__/

================================================
FILE: README.md
================================================
# Trademark Decision Intelligence AI Agent

A Google Cloud Function-based AI agent for analyzing trademark similarity and predicting opposition outcomes in UK/EU trademark law. Built using Google's Agent Development Kit (ADK) and deployed on Google Cloud Functions v2.

## Overview

This project implements an AI agent that:
1. Analyzes trademark similarity across multiple dimensions (visual, aural, conceptual, goods/services)
2. Predicts opposition outcomes based on similarity analysis
3. Provides detailed reasoning for its predictions

The system uses vector embeddings for semantic similarity comparisons and traditional algorithms (Levenshtein, phonetic matching) for wordmark comparisons.

## Project Structure

```
.
├── src/                    # Source code
│   ├── main.py            # Cloud Function entry point
│   ├── models.py          # Pydantic and SQLAlchemy models
│   └── tools/             # Agent tools and utilities
├── tests/                 # Test suite
├── docs/                  # Documentation
├── sft_jsonl/            # Training data
├── requirements.txt      # Python dependencies
├── .env.example         # Example environment variables
└── .cursorrules         # Cursor IDE configuration
```

## Key Components

### Data Models (`src/models.py`)

- **Pydantic Models**: For request/response validation and data transfer
  - `Trademark`: Core trademark representation
  - `GoodsService`: Goods/services items with NICE classification
  - `SimilarityScores`: Multi-dimensional similarity metrics
  - `PredictionResult`: Opposition outcome predictions

- **SQLAlchemy Models**: For database persistence
  - `TrademarkOrm`: Trademark database table
  - `GoodsServiceOrm`: Goods/services database table with vector embeddings

### Cloud Function (`src/main.py`)

- HTTP-triggered Cloud Function entry point
- Request validation using Pydantic models
- Error handling and response formatting
- Integration with Google ADK agent

## Prerequisites

1. Python 3.9+
2. Google Cloud Platform account with:
   - Cloud Functions v2 enabled
   - Appropriate IAM permissions
3. Supabase account and project

## Setup

1. Clone the repository:
   ```bash
   git clone [repository-url]
   cd trademark-prediction-system
   ```

2. Create and activate a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   .\venv\Scripts\activate   # Windows
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Copy `.env.example` to `.env` and configure:
   ```bash
   cp .env.example .env
   # Edit .env with your configuration:
   # SUPABASE_URL=your_supabase_url
   # SUPABASE_KEY=your_supabase_key
   ```

5. Set up the database tables in Supabase:
   ```sql
   -- Enable the pgvector extension
   CREATE EXTENSION IF NOT EXISTS vector;

   -- Create the trademarks table
   CREATE TABLE trademarks (
       id SERIAL PRIMARY KEY,
       identifier VARCHAR NOT NULL UNIQUE,
       mark_text VARCHAR NOT NULL
   );

   -- Create the goods_services table
   CREATE TABLE goods_services (
       id SERIAL PRIMARY KEY,
       term VARCHAR NOT NULL,
       nice_class INTEGER NOT NULL,
       embedding FLOAT[],
       trademark_id INTEGER REFERENCES trademarks(id) ON DELETE CASCADE
   );

   -- Create indexes
   CREATE INDEX idx_trademarks_identifier ON trademarks(identifier);
   CREATE INDEX idx_goods_services_nice_class ON goods_services(nice_class);
   ```

## Development

### Local Development

1. Start the Cloud Function locally:
   ```bash
   functions-framework --target handle_request --debug
   ```

2. Run tests:
   ```bash
   pytest
   ```

### Code Style

- Follow PEP 8 guidelines
- Use type hints for all function signatures
- Include docstrings for all public modules, classes, and functions
- Use Pydantic models for data validation
- Follow async/await patterns for I/O operations

## Deployment

1. Build and deploy to Cloud Functions v2:
   ```bash
   gcloud functions deploy trademark-agent \
     --gen2 \
     --runtime=python39 \
     --region=europe-west2 \
     --source=. \
     --entry-point=handle_request \
     --trigger-http
   ```

## API Usage

### Similarity Analysis Request

```json
{
  "applicant_trademark": {
    "identifier": "UK000012345678",
    "wordmark": {
      "mark_text": "EXAMPLE"
    },
    "goods_services": [
      {
        "term": "Computer software",
        "nice_class": 9
      }
    ]
  },
  "opponent_trademark": {
    "identifier": "UK000087654321",
    "wordmark": {
      "mark_text": "EXEMPLAR"
    },
    "goods_services": [
      {
        "term": "Software as a service",
        "nice_class": 9
      }
    ]
  }
}
```

### Response Format

```json
{
  "message": "Successfully parsed request.",
  "applicant_identifier": "UK000012345678",
  "opponent_identifier": "UK000087654321"
}
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## License

[License details to be added]

## Acknowledgments

- Google Cloud Platform
- Google Agent Development Kit (ADK)
- Supabase
- Python-Levenshtein 


================================================
FILE: deploy.sh
================================================
gcloud run deploy trademark-agent \
    --source=. \
    --region=europe-west2 \
    --allow-unauthenticated \
    --env-vars-file=.env.yaml \
    --memory=1Gi \
    --cpu=2


================================================
FILE: Dockerfile
================================================
# Use the official Python 3.11 slim image as a base
FROM python:3.11-slim

# Set environment variables
# Prevents Python from writing pyc files to disc (equivalent to python -B)
ENV PYTHONDONTWRITEBYTECODE 1
# Ensures Python output is sent straight to the terminal without buffering
ENV PYTHONUNBUFFERED 1
# Set the port the container will listen on. Cloud Run injects its own PORT env var (default 8080)
ENV PORT 8080

# Set the working directory in the container
WORKDIR /app

# Copy the dependencies file
COPY requirements.txt .

# Install dependencies
# Use --no-cache-dir to reduce image size
RUN pip install --no-cache-dir -r requirements.txt

# Copy the rest of the application code into the container
COPY . .

# Create a non-root user and switch to it for security
# RUN adduser --disabled-password --gecos "" appuser
# USER appuser
# Note: Cloud Run's sandbox runs as non-root anyway, so creating
# a specific user isn't strictly necessary unless required by other tools.
# Keeping it simple for now.

# Expose the port the app runs on
EXPOSE $PORT

# Define the command to run the application
# Assumes your FastAPI app instance is named 'app' in 'src/main.py'
# Uses the PORT environment variable defined above (or injected by Cloud Run)
CMD uvicorn src.main:app --host 0.0.0.0 --port ${PORT} 


================================================
FILE: main.py
================================================
# main.py
"""
Entry point for Google Cloud Functions v2.
Imports and exports the handle_request function from src/main.py.
"""

# Import the main handler from the src module
from src.main import handle_request

# This exports the handle_request function for Cloud Functions
# No need to redefine the function as we're directly exporting it

# If needed, add any additional global initialization here 


================================================
FILE: Procfile
================================================
web: uvicorn src.main:app --host=0.0.0.0 --port=$PORT 


================================================
FILE: requirements.txt
================================================
# requirements.txt
# Core Cloud Function framework
functions-framework

# Google Cloud Libraries
google-adk
google-genai

# Database Interaction
supabase
postgrest
SQLAlchemy
# psycopg2-binary  # Remove synchronous adapter
asyncpg          # Add asynchronous adapter

# Data Validation and Modeling
pydantic>=2.0.0

# Vector Embeddings and Similarity (Placeholder/Examples)
# pgvector integration likely handled via SQLAlchemy/psycopg extensions or raw SQL
# Levenshtein distance for visual string similarity
python-Levenshtein
pgvector
sentence-transformers
torch
Metaphone
nltk             # Added for enhanced conceptual similarity (WordNet, etc.)
transformers     # For LegalBERT and other transformer models
datasets         # Required for working with Hugging Face models

# Utilities
python-dotenv # For loading environment variables during local development

# Test
pytest
pytest-asyncio   # For testing async functions

# FastAPI and Uvicorn
fastapi
uvicorn[standard]

# Additional dependencies
aiosqlite  # For async SQLite support
httpx  # For async HTTP client


================================================
FILE: .cursorrules
================================================
# Combined Cursor Rules for Trademark AI Agent Project

## I. Core Persona & Approach

You are an expert AI assistant specialized in Python development, Agent creation, and data analysis, with specific expertise relevant to this project. Your focus is on building a **Decision Intelligence AI Agent for UK/EU Trademark Law using Google's Agent Development Kit (ADK)**, deployable to **Google Cloud Run**.

**Key Expertise Areas:**
*   **Google Cloud:** Cloud Run, Cloud SQL for PostgreSQL (or Supabase equivalent), `pgvector` extension, Identity Platform/Firebase Auth (potential), Cloud Storage (potential), Cloud Build.
*   **AI & Agent Development:** Google Agent Development Kit (ADK) with FastAPI integration, Google Gemini API, designing agent tools and flows.
*   **Web Frameworks:** FastAPI (as integrated by ADK), Functions Framework for Cloud Functions v2.
*   **Python Development:** Best practices, asynchronous programming (`asyncio`, `async`/`await`), type annotations, error handling.
*   **Data Handling & ML:** `Pydantic` for data modeling/validation, `pgvector` for vector similarity search (via SQLAlchemy), `Levenshtein` distance, embeddings via `sentence-transformers`, NLTK for enhanced conceptual similarity.
*   **Database Interaction:** Async SQLAlchemy with `asyncpg`, Supabase client integration, pgvector extension.
*   **Relevant Libraries/Tools:** `Ruff` (linting/formatting), `pytest` (testing), `uvicorn` (ASGI server), Double Metaphone for phonetic similarity.
*   **Domain Context:** UK/EU trademark concepts (wordmarks, goods/services), NICE Classification, and different types of legal similarity (visual, aural, conceptual, goods/services).

**Approach:** Prioritize clear, maintainable, and robust Python code suitable for Cloud Run deployment. Leverage multi-dimensional similarity calculations with the established model dimensions (384D from all-MiniLM-L6-v2). Focus on ADK tool integration and async database operations.

## II. Interaction & Response Rules (How You Behave)

1.  **Verify Information:** Always verify information against the current codebase before suggesting changes.
2.  **File-by-File Changes:** Introduce changes file by file for review, unless a single logical change naturally spans multiple files.
3.  **No Apologies:** Avoid apologetic phrases.
4.  **No "Understanding" Feedback:** Avoid commenting on your own understanding (e.g., "I understand you want...").
5.  **No Whitespace Suggestions:** Do not suggest *solely* whitespace changes unless violating `Ruff` rules.
6.  **No Summaries:** Do not summarize changes made at the end of a response.
7.  **Stick to the Request:** Do not invent changes beyond the request or project scope.
8.  **No Redundant Confirmations:** Do not ask for confirmation of information already clear from the context.
9.  **Preserve Unrelated Code:** Do not remove/modify unrelated code. Respect existing structures.
10. **Single Chunk Edits (Per File):** Provide all edits for a *single file* in one code block.
11. **Trust Provided Context:** Rely on the code and information provided in the context window.
12. **No Unnecessary Updates:** Don't suggest changes if none are needed based on the request.
13. **Use Real File Paths:** Use actual project paths when referring to files.
14. **Focus on the Goal:** Concentrate on implementing the requested changes or features.
15. **Check Context Files:** Check context files for current implementations before suggesting changes.

## III. General Development Principles

1.  **Project Structure:** Follow the established structure with src/ directory organization:
    * `src/main.py` - FastAPI app and Cloud Function handler
    * `src/models.py` - Pydantic and SQLAlchemy models
    * `src/similarity.py` - Core similarity calculation functions
    * `src/db.py` - Database access with async SQLAlchemy
    * `src/embeddings.py` - Embedding generation using sentence-transformers
    * `src/tools/` - ADK tool implementation
2.  **Cloud Run Configuration:** 
    * Use environment variables via `.env.yaml` for Cloud Run deployment
    * Follow the Dockerfile configuration for containerization
    * Maintain proper concurrent request handling with async operations
3.  **ADK Integration:**
    * Use the FastAPI app generated by `get_fast_api_app()`
    * Register tools via lists passed to the ADK initialization
    * Bridge Functions Framework and FastAPI in the handler function

## IV. Python-Specific Rules & Tooling

1.  **Dependency Management:** Maintain accurate `requirements.txt` with all necessary dependencies.
2.  **Typing (Mandatory):**
    *   Continue using type hints for all function/method signatures (parameters/return types), with special attention to the `Optional` type for functions that may return None.
    *   Maintain Pydantic models for all API inputs and outputs.
    *   Follow the SQLAlchemy Column type annotation pattern already established: `column_name: Column[type] = Column(type, ...)`
3.  **Docstrings:**
    *   Include comprehensive docstrings for all public functions, especially those used as ADK tools.
    *   Document async function behavior, embedding dimension details, and similarity score interpretations.
4.  **Testing:**
    *   Expand test coverage for similarity calculations beyond the visual similarity tests.
    *   Add async tests for database operations using `pytest-asyncio`.
    *   Include tests for edge cases in similarity calculations.
5.  **Asynchronous Code:**
    *   Maintain the async/await pattern for all database operations.
    *   Consider using `asyncio.to_thread()` for CPU-bound operations like embedding generation.
    *   Ensure proper session management and error handling in async contexts.

## V. Code Quality & Project Specifics

1.  **Similarity Implementations:**
    *   **Visual:** Maintain Levenshtein ratio-based implementation.
    *   **Aural:** Continue using Double Metaphone with Levenshtein on phonetic codes.
    *   **Conceptual:** Support both embedding-based and WordNet-enhanced conceptual similarity.
    *   **Goods/Services:** Maintain vector embedding search using pgvector's cosine_distance.
    *   **Overall:** Use the weighted similarity calculation with proper handling of missing scores.
    
2.  **Database Design:**
    *   Current schema separates embeddings into `vector_embeddings` table with proper relationships.
    *   Maintain the 384-dimension embedding space (all-MiniLM-L6-v2 model).
    *   Use the established relationship pattern between `GoodsServiceOrm` and `VectorEmbeddingOrm`.

3.  **Error Handling & Logging:**
    *   Replace print statements with structured logging where appropriate.
    *   Maintain comprehensive try/except blocks, especially for embedding generation and database operations.

4.  **Prediction Implementation:**
    *   Next development focus should be on implementing the prediction tools/functionality referenced in the `PredictionTaskInput` and `PredictionResult` models.
    *   Ensure prediction logic properly consumes the similarity scores and provides meaningful reasoning.

5.  **ADK Patterns:**
    *   Follow the established pattern of defining tool input models with Pydantic.
    *   Wrap core functionality in tool functions conforming to ADK expectations.
    *   Use common weighted structure for combining similarity scores.


================================================
FILE: .env.example
================================================
# .env.example
# Example configuration for connecting to the AlloyDB instance.
# Copy this file to .env and fill in your actual values.
# DO NOT COMMIT .env to version control. Add .env to your .gitignore file.

# --- AlloyDB Database Configuration ---
# Database user (e.g., 'postgres')
DB_USER="postgres"

# Database password for the specified user
DB_PASS="<your_db_password>"

# Database name (e.g., 'postgres')
DB_NAME="postgres"

# AlloyDB Instance Connection Name (Format: projects/PROJECT/locations/REGION/clusters/CLUSTER/instances/INSTANCE)
DB_INSTANCE_CONNECTION_NAME="projects/<your_gcp_project_id>/locations/<your_db_region>/clusters/<your_cluster_id>/instances/<your_primary_instance_id>"

# IP Type for connection (PRIVATE or PUBLIC). Use PRIVATE for AlloyDB VPC Peering.
DB_IP_TYPE="PRIVATE"

# Supabase Configuration
SUPABASE_URL=your_supabase_url
SUPABASE_KEY=your_supabase_key
# Add the Service Role Key for backend database operations (e.g., via SQLAlchemy)
# Keep this key secure and only use it in trusted backend environments.
SUPABASE_SERVICE_KEY=your_supabase_service_role_key

# Optional: Development Settings
DEBUG=false
LOG_LEVEL=INFO


================================================
FILE: .gcloudignore
================================================
# .gcloudignore
# Exclude files and directories not needed for the Cloud Function deployment

# Standard Python ignores
__pycache__/
*.pyc
*.pyo
*.pyd
*~
*.swp

# Virtual environment
venv/
.venv/

# Testing artifacts
.pytest_cache/
htmlcov/
.coverage

# IDE/Editor config
.vscode/
.idea/

# Local config (keep .env.yaml, but ignore others if present)
.env
*.local

# Supabase local development files (if any)
supabase/

# Documentation / Large data files not needed at runtime
docs/
sft_jsonl/

# Other build/cache files
*.egg-info/
.eggs/
dist/
build/ 


================================================
FILE: src/__init__.py
================================================
"""Source package for the Trademark AI Agent."""



================================================
FILE: src/db.py
================================================
# src/db.py
"""
Database connection management for Supabase and data access functions.

This module provides a reusable SQLAlchemy engine configured to connect
to a Supabase instance. It relies on environment variables for database credentials.
It also includes functions for interacting with trademark-related data,
including storing and searching vector embeddings for goods/services.

Required Environment Variables:
    SUPABASE_URL: The Supabase project URL.
    SUPABASE_KEY: The Supabase API key (service role key recommended for backend).

Usage:
    from src.db import get_engine, store_goods_service_embedding, find_similar_goods_services

    engine = get_engine()
    # ... (Example usage for storing/searching)
"""

import os
from typing import Optional, List, Tuple

import sqlalchemy
from sqlalchemy import select, Index, cast, String # Add index import
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker # Import async components
from sqlalchemy.exc import OperationalError, IntegrityError
from supabase import create_client, Client

# Import the logger
from src.logger import get_logger, info, warning, error, exception

# Import ORM models and embedding function
from src.models import Base, GoodsServiceOrm, VectorEmbeddingOrm
from src.embeddings import generate_embedding

# Load environment variables from .env file for local development
# In Cloud Functions, set these variables in the runtime environment settings.
try:
    from dotenv import load_dotenv

    load_dotenv()
except ImportError:
    # dotenv is optional, mainly for local development
    logger.info("dotenv not installed, skipping .env file loading")
    pass


# Module-level variables to store instances for reuse
# within the same Cloud Function instance (improves efficiency)
_async_engine: Optional[sqlalchemy.ext.asyncio.AsyncEngine] = None # Rename for clarity
_supabase: Optional[Client] = None
_async_session_local: Optional[async_sessionmaker[AsyncSession]] = None # Use async_sessionmaker


def get_supabase() -> Client:
    """
    Initializes and returns a Supabase client.

    Creates a Supabase client using the project URL and API key.
    Ensures the client is created only once per Cloud Function instance.

    Raises:
        ValueError: If required environment variables are not set.

    Returns:
        A configured Supabase client instance.
    """
    global _supabase

    # Return existing client if already initialized
    if _supabase:
        return _supabase

    # Get Configuration from Environment Variables
    supabase_url: Optional[str] = os.getenv("SUPABASE_URL")
    # Consider using SUPABASE_SERVICE_KEY for backend operations
    supabase_key: Optional[str] = os.getenv("SUPABASE_KEY")

    if not all([supabase_url, supabase_key]):
        error_msg = "Missing required Supabase environment variables: SUPABASE_URL, SUPABASE_KEY"
        logger.error(error_msg)
        raise ValueError(error_msg)

    try:
        # Create and store the Supabase client
        _supabase = create_client(supabase_url, supabase_key)
        logger.info("Successfully created Supabase client")
        return _supabase
    except Exception as e:
        exception("Failed to create Supabase client", exc=e)
        raise OperationalError(f"Failed to create Supabase client: {e}", params={}, orig=e) from e


async def get_async_engine() -> sqlalchemy.ext.asyncio.AsyncEngine: # Make async (optional, but good practice if init involves IO)
    """
    Initializes and returns an asynchronous SQLAlchemy Engine configured for Supabase.

    Creates an async connection pool using the Supabase connection details with asyncpg.
    Ensures the engine is created only once per Cloud Function instance.

    Raises:
        ValueError: If required environment variables are not set.
        OperationalError: If the database connection fails.

    Returns:
        A configured asynchronous SQLAlchemy Engine instance.
    """
    global _async_engine

    # Return existing engine if already initialized
    if _async_engine:
        return _async_engine

    # Get Configuration from Environment Variables (same as before)
    supabase_url: Optional[str] = os.getenv("SUPABASE_URL")
    db_password: Optional[str] = os.getenv("SUPABASE_SERVICE_KEY")
    db_user: str = "postgres"
    db_host: Optional[str] = None
    db_name: str = "postgres"

    if supabase_url:
        try:
            host_part = supabase_url.split("//")[1]
            db_host = f"db.{host_part}"
        except IndexError:
            error_msg = "Invalid SUPABASE_URL format."
            logger.error(error_msg)
            raise ValueError(error_msg)

    if not all([db_host, db_password]):
        error_msg = "Missing required environment variables for DB engine: SUPABASE_URL, SUPABASE_SERVICE_KEY"
        logger.error(error_msg)
        raise ValueError(error_msg)

    try:
        # Use postgresql+asyncpg dialect
        db_url = f"postgresql+asyncpg://{db_user}:{db_password}@{db_host}:5432/{db_name}"
        logger.info("Initializing async database engine")

        # Use create_async_engine
        async_engine = create_async_engine(
            db_url,
            pool_size=5,
            max_overflow=2,
            pool_timeout=30,
            pool_recycle=1800,
            # Async engines typically don't need json serializers specified here
            # echo=True # Uncomment for debugging SQL
        )

        # Optional: Test connection asynchronously
        async with async_engine.connect() as connection:
            await connection.execute(sqlalchemy.text("SELECT 1"))

        # Store the engine globally for reuse
        _async_engine = async_engine
        logger.info("Async database engine created successfully.")
        return _async_engine
    except OperationalError as e:
        exception("Database connection failed", exc=e)
        raise
    except Exception as e:
        # Ensure the original exception type is preserved if possible
        if isinstance(e, OperationalError):
             raise
        exception("Failed to create async database engine", exc=e)
        raise OperationalError(f"Failed to create async database engine: {e}", params={}, orig=e) from e


async def get_async_session() -> async_sessionmaker[AsyncSession]: # Make async (consistent with get_engine)
    """
    Returns an asynchronous SQLAlchemy sessionmaker instance bound to the async engine.

    Creates the sessionmaker only once.
    """
    global _async_session_local
    if _async_session_local is None:
        engine = await get_async_engine() # Await the async engine getter
        _async_session_local = async_sessionmaker(
            engine,
            class_=AsyncSession,
            expire_on_commit=False # Recommended for async sessions
        )
        logger.info("Async session maker created.")
    return _async_session_local


# --- Embedding Storage and Search Functions ---

async def store_goods_service_embedding(goods_service_id: int, term: str, session: AsyncSession) -> bool: # Make async, accept AsyncSession
    """
    Generates an embedding for the given term and stores it async in the vector_embeddings table,
    linked to the specified goods_services ID. Skips if embedding already exists.

    Args:
        goods_service_id: The ID of the GoodsServiceOrm record.
        term: The text term of the goods/service to embed.
        session: The asynchronous SQLAlchemy session to use for database operations.

    Returns:
        True if the embedding was successfully generated and stored (or already existed),
        False otherwise.
    """
    try:
        # Check if embedding already exists using async session
        stmt = select(VectorEmbeddingOrm).filter_by(
            entity_type='goods_services',
            entity_id=goods_service_id
        )
        result = await session.execute(stmt)
        existing = result.scalars().first() # Use await and scalars()

        if existing:
            logger.info(f"Embedding already exists for goods_services ID {goods_service_id}")
            return True

        # Generate the embedding (Use the async version now)
        embedding_vector: Optional[List[float]] = await generate_embedding(term)

        if embedding_vector is None:
            logger.warning(f"Failed to generate embedding for term", term=term)
            return False

        # Create and store the new embedding record
        new_embedding = VectorEmbeddingOrm(
            entity_type='goods_services',
            entity_id=goods_service_id,
            embedding=embedding_vector
        )
        session.add(new_embedding)
        await session.flush() # Use await
        logger.info(f"Successfully stored embedding for goods_services ID {goods_service_id}")
        # No explicit commit here, assuming caller manages the transaction boundary
        return True

    except IntegrityError as e:
        # Handle potential race conditions if another process inserted concurrently
        exception("IntegrityError storing embedding", exc=e, goods_service_id=goods_service_id)
        await session.rollback() # Use await
        # Optionally, re-query async to confirm if it exists now
        stmt = select(VectorEmbeddingOrm).filter_by(
            entity_type='goods_services',
            entity_id=goods_service_id
        )
        result = await session.execute(stmt)
        return result.scalars().first() is not None # Check if exists after rollback
    except Exception as e:
        exception("Error storing embedding", exc=e, goods_service_id=goods_service_id)
        await session.rollback() # Use await
        return False


async def find_similar_goods_services( # Make async
    query_embedding: List[float],
    limit: int = 10,
    distance_threshold: float = 0.3, # Add threshold parameter
    session: Optional[AsyncSession] = None, # Accept optional AsyncSession
) -> List[Tuple[GoodsServiceOrm, float]]:
    """
    Finds goods/services terms similar to the provided query embedding asynchronously.

    Performs a vector similarity search (cosine distance) against the
    `vector_embeddings` table where entity_type is 'goods_services'.

    Args:
        query_embedding: The vector embedding to search against.
        limit: The maximum number of similar items to return.
        distance_threshold: Maximum cosine distance to consider (0.0-2.0, lower is more similar).
        session: An optional existing asynchronous SQLAlchemy session. If None, a new one is created and managed.

    Returns:
        A list of tuples, where each tuple contains:
        (GoodsServiceOrm object, similarity_score (cosine distance, lower is better)).
        Returns an empty list if an error occurs or no matches are found.
    """
    # Determine if we need to manage the session locally
    manage_session = session is None
    db_session: AsyncSession

    if manage_session:
        AsyncSessionLocal = await get_async_session() # Await the async factory
        db_session = AsyncSessionLocal() # Create a new session instance
    else:
        # Use the provided session, ensuring it's not None (checked by type hint Optional[AsyncSession])
        db_session = session # type: ignore

    results: List[Tuple[GoodsServiceOrm, float]] = []
    try:
        # Use the <=> operator for cosine distance (provided by pgvector)
        # Query VectorEmbeddingOrm, get distance, join with GoodsServiceOrm
        # Add WHERE clause with distance threshold
        stmt = (
            select( # Use select() from sqlalchemy
                GoodsServiceOrm,
                VectorEmbeddingOrm.embedding.cosine_distance(query_embedding).label("distance")
            )
            .join(VectorEmbeddingOrm,
                  (VectorEmbeddingOrm.entity_id == GoodsServiceOrm.id) &
                  (VectorEmbeddingOrm.entity_type == 'goods_services'))
            .where(VectorEmbeddingOrm.embedding.cosine_distance(query_embedding) <= distance_threshold)
            .order_by(sqlalchemy.asc("distance")) # Use sqlalchemy.asc explicitly
            .limit(limit)
        )

        # Log search parameters
        logger.info("Executing vector similarity search", limit=limit, distance_threshold=distance_threshold)

        # Execute the query asynchronously
        query_result = await db_session.execute(stmt)
        results = query_result.all() # Returns List[Row], Row contains (GoodsServiceOrm, float)
        
        # Log search results
        logger.info(f"Vector search found {len(results)} similar items")

    except Exception as e:
        exception("Error finding similar goods/services", exc=e)
        if manage_session: # Only rollback if we created the session
            await db_session.rollback() # Use await
    finally:
        if manage_session: # Only close if we created the session
            await db_session.close() # Use await

    # Ensure the return type matches the signature
    # query_result.all() gives List[Row], need List[Tuple[GoodsServiceOrm, float]]
    # In SQLAlchemy 2.0, Row behaves like a tuple, so this should be fine.
    # Explicit conversion if needed: return [(row[0], row[1]) for row in results]
    return results # type: ignore


# --- CREATE INDEXES FOR VECTOR SEARCH OPTIMIZATION ---
async def create_vector_indexes(session: AsyncSession) -> None:
    """
    Creates optimized indexes for vector similarity searches if they don't exist.
    This includes both B-tree indexes for traditional filtering and an IVFFlat index
    for efficient approximate nearest neighbor searches with pgvector.
    
    Args:
        session: An asynchronous SQLAlchemy session.
    """
    try:
        logger.info("Checking and creating vector search indexes")
        
        # Check if indexes exist first
        check_index_query = sqlalchemy.text("""
            SELECT indexname FROM pg_indexes 
            WHERE tablename = 'vector_embeddings' AND indexname = 'idx_vector_embeddings_embedding_ivfflat'
        """)
        result = await session.execute(check_index_query)
        if result.first() is None:
            # Create IVFFlat index for faster ANN searches
            # Lists 100 is a good starting point for most collections, can be tuned based on data size
            ivfflat_query = sqlalchemy.text("""
                CREATE INDEX IF NOT EXISTS idx_vector_embeddings_embedding_ivfflat 
                ON vector_embeddings USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100)
            """)
            await session.execute(ivfflat_query)
            logger.info("Created IVFFlat index for vector embeddings")
        
        # Check for entity type+id index
        check_entity_index_query = sqlalchemy.text("""
            SELECT indexname FROM pg_indexes 
            WHERE tablename = 'vector_embeddings' AND indexname = 'idx_vector_embeddings_entity_combined'
        """)
        result = await session.execute(check_entity_index_query)
        if result.first() is None:
            # Create optimized index for entity type + id searches (frequently used in joins)
            entity_index_query = sqlalchemy.text("""
                CREATE INDEX IF NOT EXISTS idx_vector_embeddings_entity_combined 
                ON vector_embeddings (entity_type, entity_id)
            """)
            await session.execute(entity_index_query)
            logger.info("Created combined entity type+id index")
        
        # Add GIN index for text search on goods_services terms if needed
        check_gin_index_query = sqlalchemy.text("""
            SELECT indexname FROM pg_indexes 
            WHERE tablename = 'goods_services' AND indexname = 'idx_goods_services_term_gin'
        """)
        result = await session.execute(check_gin_index_query)
        if result.first() is None:
            gin_index_query = sqlalchemy.text("""
                CREATE INDEX IF NOT EXISTS idx_goods_services_term_gin 
                ON goods_services USING gin (term gin_trgm_ops)
            """)
            
            # Add the trgm extension if not present
            await session.execute(sqlalchemy.text("CREATE EXTENSION IF NOT EXISTS pg_trgm"))
            
            # Create the index
            await session.execute(gin_index_query)
            logger.info("Created GIN index for text search on goods_services terms")
        
        # Commit all index changes
        await session.commit()
        logger.info("Successfully created all vector search indexes")
            
    except Exception as e:
        exception("Error creating vector indexes", exc=e)
        await session.rollback()
        raise


# --- Initialize Database with Indexes ---
async def initialize_database() -> None:
    """
    Initializes the database by:
    1. Creating tables if they don't exist
    2. Adding optimized indexes for vector searches
    
    Should be called during application startup.
    """
    logger.info("Initializing database")
    try:
        # Get engine and create tables
        engine = await get_async_engine()
        async with engine.begin() as conn:
            # Create tables if they don't exist
            # Note: This assumes your models have __table_args__ with 'extend_existing=True'
            # to avoid errors if tables already exist
            await conn.run_sync(Base.metadata.create_all)
        
        # Create session and add indexes
        AsyncSessionLocal = await get_async_session()
        async with AsyncSessionLocal() as session:
            async with session.begin():
                await create_vector_indexes(session)
        
        logger.info("Database initialization completed successfully")
    except Exception as e:
        exception("Database initialization failed", exc=e)
        raise


# Need to import Base for potential Base.metadata.create_all usage
from src.models import Base
# Remove psycopg2 import as we now use asyncpg via the connection string
# import psycopg2
# Import asyncpg for type checking or direct use if needed, though SQLAlchemy handles it
import asyncpg # Add asyncpg import



================================================
FILE: src/embeddings.py
================================================
"""
Functions for generating text embeddings using sentence-transformers and specialized models.
"""

import asyncio
from typing import List, Optional, Dict, Any, Tuple, Union

from sentence_transformers import SentenceTransformer
# Add imports for LegalBERT
from transformers import AutoTokenizer, AutoModel
import torch

# Import the logger
from src.logger import get_logger, exception

# Initialize logger
logger = get_logger(__name__)

# Initialize the model globally for efficiency
# Consider making the model name configurable (e.g., via environment variable)
# 'all-MiniLM-L6-v2' is a good starting point (384 dimensions)
# 'all-mpnet-base-v2' is another strong model (768 dimensions)
# However, the DB schema expects 1536 dimensions. We need a model that outputs this.
# Let's use 'text-embedding-3-large' (OpenAI, needs separate handling) or find a suitable sentence-transformer.
# For now, using a placeholder model name that *might* not match 1536 dims for demonstration.
# IMPORTANT: Ensure the chosen model ACTUALLY outputs 1536 dimensions for the DB schema.
# Using 'all-mpnet-base-v2' (768 dims) as a placeholder - THIS NEEDS REPLACEMENT.
# MODEL_NAME = 'all-mpnet-base-v2' # <-- *** Placeholder - Needs model outputting 1536 dims ***
# Using all-MiniLM-L6-v2 for 384-dimension embeddings
MODEL_NAME = 'sentence-transformers/all-MiniLM-L6-v2'
_model: Optional[SentenceTransformer] = None
_model_lock = asyncio.Lock()  # Add a lock for thread safety

# LegalBERT model from Hugging Face
LEGAL_BERT_MODEL = 'nlpaueb/legal-bert-base-uncased'
_legal_bert_tokenizer: Optional[AutoTokenizer] = None
_legal_bert_model: Optional[AutoModel] = None
_legal_bert_lock = asyncio.Lock()  # Add a lock for thread safety


def _get_embedding_model() -> SentenceTransformer:
    """Loads and returns the sentence transformer model, caching it globally."""
    global _model
    if _model is None:
        try:
            logger.info(f"Loading embedding model: {MODEL_NAME}")
            _model = SentenceTransformer(MODEL_NAME)
            logger.info(f"Embedding model loaded successfully: {MODEL_NAME}")
        except Exception as e:
            logger.exception(f"Error loading SentenceTransformer model", exc=e, model=MODEL_NAME)
            raise
    return _model


def _sync_generate_embedding(text: str) -> Optional[List[float]]:
    """
    Synchronous implementation of embedding generation - for use with asyncio.to_thread().
    
    Args:
        text: The input text to embed.
        
    Returns:
        A list of floats representing the embedding, or None if embedding fails.
    """
    if not text:  # Handle empty input
        return None

    try:
        model = _get_embedding_model()
        # The model's encode function returns a numpy array, convert it to list
        embedding = model.encode(text, convert_to_numpy=False)
        # Ensure the output is List[float]
        if hasattr(embedding, 'tolist'):  # Handle numpy array
            return embedding.tolist()
        elif isinstance(embedding, list):
            return [float(val) for val in embedding]  # Ensure elements are floats
        else:
            # Log an error for unexpected type
            logger.error(f"Unexpected embedding type", type=str(type(embedding)))
            return None

    except Exception as e:
        # Log the error with context
        exception(
            f"Error generating embedding for text", 
            exc=e, 
            text_snippet=text[:50] + ("..." if len(text) > 50 else "")
        )
        return None


async def generate_embedding(text: str) -> Optional[List[float]]:
    """
    Asynchronously generates a vector embedding for the given text.
    
    Uses asyncio.to_thread() to run the CPU-bound embedding generation
    in a separate thread, allowing other async tasks to run concurrently.
    
    Args:
        text: The input text (e.g., a goods/services term) to embed.
        
    Returns:
        A list of floats representing the embedding, or None if embedding fails.
    """
    if not text:  # Handle empty input
        return None
    
    # Use the lock to prevent multiple threads from initializing the model simultaneously
    async with _model_lock:
        # Ensure model is loaded (lazy loading)
        if _model is None:
            try:
                _model = _get_embedding_model()
            except Exception as e:
                logger.exception("Failed to load embedding model", exc=e)
                return None
    
    # Run the CPU-bound embedding generation in a separate thread
    try:
        # This effectively makes the synchronous operation non-blocking
        return await asyncio.to_thread(_sync_generate_embedding, text)
    except Exception as e:
        # Log any errors that occur during thread execution
        exception(
            "Error in async embedding generation", 
            exc=e, 
            text_snippet=text[:50] + ("..." if len(text) > 50 else "")
        )
        return None


def _get_legal_bert_model() -> Tuple[AutoTokenizer, AutoModel]:
    """Loads and returns the LegalBERT model and tokenizer, caching them globally."""
    global _legal_bert_tokenizer, _legal_bert_model
    if _legal_bert_tokenizer is None or _legal_bert_model is None:
        try:
            logger.info(f"Loading LegalBERT model: {LEGAL_BERT_MODEL}")
            _legal_bert_tokenizer = AutoTokenizer.from_pretrained(LEGAL_BERT_MODEL)
            _legal_bert_model = AutoModel.from_pretrained(LEGAL_BERT_MODEL)
            logger.info(f"LegalBERT model loaded successfully: {LEGAL_BERT_MODEL}")
        except Exception as e:
            logger.exception(f"Error loading LegalBERT model", exc=e, model=LEGAL_BERT_MODEL)
            raise
    return _legal_bert_tokenizer, _legal_bert_model


def _sync_generate_legal_embedding(text: str) -> Optional[List[float]]:
    """
    Synchronous implementation of LegalBERT embedding generation.
    
    Args:
        text: The input text to embed with LegalBERT.
        
    Returns:
        A list of floats representing the embedding, or None if embedding fails.
    """
    if not text:  # Handle empty input
        return None

    try:
        tokenizer, model = _get_legal_bert_model()
        
        # Tokenize and prepare for model
        inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
        
        # Get model output
        with torch.no_grad():
            outputs = model(**inputs)
        
        # Use [CLS] token embedding as sentence representation (common practice)
        sentence_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()
        
        # Convert to list
        return sentence_embedding.tolist()

    except Exception as e:
        # Log the error with context
        exception(
            f"Error generating LegalBERT embedding for text", 
            exc=e, 
            text_snippet=text[:50] + ("..." if len(text) > 50 else "")
        )
        return None


async def generate_legal_embedding(text: str) -> Optional[List[float]]:
    """
    Asynchronously generates a LegalBERT embedding for the given text.
    
    Uses LegalBERT to generate embeddings that capture legal domain knowledge
    and legal terminology relationships better than general-purpose models.
    
    Args:
        text: The input text (e.g., a trademark term) to embed with legal context.
        
    Returns:
        A list of floats representing the legal-domain embedding, or None if embedding fails.
    """
    if not text:  # Handle empty input
        return None
    
    # Use the lock to prevent multiple threads from initializing the model simultaneously
    async with _legal_bert_lock:
        # Ensure model is loaded (lazy loading)
        if _legal_bert_tokenizer is None or _legal_bert_model is None:
            try:
                _legal_bert_tokenizer, _legal_bert_model = _get_legal_bert_model()
            except Exception as e:
                logger.exception("Failed to load LegalBERT model", exc=e)
                return None
    
    # Run the CPU-bound embedding generation in a separate thread
    try:
        # This effectively makes the synchronous operation non-blocking
        return await asyncio.to_thread(_sync_generate_legal_embedding, text)
    except Exception as e:
        # Log any errors that occur during thread execution
        exception(
            "Error in async LegalBERT embedding generation", 
            exc=e, 
            text_snippet=text[:50] + ("..." if len(text) > 50 else "")
        )
        return None


# Optional: Batch embedding generation
async def generate_embeddings_batch(
    texts: List[str], 
    batch_size: int = 32,
    use_legal_bert: bool = False
) -> Dict[str, Optional[List[float]]]:
    """
    Asynchronously generates embeddings for multiple texts in batches.
    
    This can be more efficient than generating embeddings one by one
    when processing large numbers of terms.
    
    Args:
        texts: List of input texts to embed.
        batch_size: Number of texts to process in each batch.
        use_legal_bert: Whether to use LegalBERT for legal-domain specific embeddings.
        
    Returns:
        A dictionary mapping each input text to its embedding vector,
        or None if embedding generation failed for that text.
    """
    # Initialize results dict
    results: Dict[str, Optional[List[float]]] = {text: None for text in texts}
    
    # Process in batches to avoid memory issues with large lists
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i + batch_size]
        
        # Create tasks for all texts in the batch
        if use_legal_bert:
            tasks = [generate_legal_embedding(text) for text in batch]
        else:
            tasks = [generate_embedding(text) for text in batch]
        
        # Wait for all embeddings in this batch
        batch_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Process results, skipping any that raised exceptions
        for text, result in zip(batch, batch_results):
            if isinstance(result, Exception):
                logger.warning(f"Exception in batch embedding", 
                              exc_type=type(result).__name__,
                              text_snippet=text[:30])
                results[text] = None
            else:
                results[text] = result
    
    return results 


================================================
FILE: src/gemini_agent_prompt.py
================================================
"""
Prompt templates for the Trademark AI Agent using Google's Agent Development Kit (ADK).

This module provides optimized prompts for the Trademark Decision Intelligence AI Agent,
including system prompts for the agent and specialized analysis prompts focused on
UK/EU trademark opposition analysis across visual, aural, conceptual, and goods/services
similarity dimensions.
"""

import json
from typing import Dict, List, Any, Optional

# Load prompt templates from files
import os
import pathlib

# Get the project root directory (3 levels up from this file)
PROJECT_ROOT = pathlib.Path(__file__).parent.parent.parent.absolute()
PROMPTS_DIR = PROJECT_ROOT / "data" / "prompts"

def _load_prompt_file(filename: str) -> Dict[str, Any]:
    """
    Load a prompt template from a JSON file.
    
    Args:
        filename: Name of the JSON file in the prompts directory
        
    Returns:
        Loaded prompt template as a dictionary
    """
    try:
        with open(PROMPTS_DIR / filename, 'r') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        # Return a minimal fallback if file can't be loaded
        return {"prompt": f"Error loading {filename}: {str(e)}"}

def get_adk_agent_prompt(include_examples: bool = True) -> str:
    """
    Generate the main system prompt for the Trademark AI Agent.
    
    Args:
        include_examples: Whether to include few-shot examples
        
    Returns:
        Formatted system prompt string
    """
    # Core agent capabilities and framework
    prompt = """
    # Trademark Decision Intelligence AI Agent

    ## Role
    You are an expert trademark examiner specializing in UK/EU trademark law and opposition proceedings. Your purpose is to assist with the analysis of trademark opposition cases by comparing trademarks and predicting likely outcomes.

    ## Core Framework
    You analyze trademark similarity across four dimensions:
    1. **Visual similarity** - How the marks appear visually to the average consumer
    2. **Aural similarity** - How the marks sound when pronounced
    3. **Conceptual similarity** - The meaning or concept behind the marks
    4. **Goods/Services similarity** - The relationship between the goods/services covered

    ## Tools at Your Disposal
    You have access to specialized tools that can help with your analysis:

    - **Visual Similarity Calculator**: Analyzes textual wordmarks for visual similarity
    - **Aural Similarity Calculator**: Analyzes phonetic similarity of wordmarks
    - **Conceptual Similarity Calculator**: Analyzes meaning-based similarity of wordmarks
    - **Goods/Services Similarity Calculator**: Analyzes similarity between goods and services descriptions
    - **Opposition Outcome Predictor**: Predicts the likely outcome of trademark opposition proceedings

    ## Trademark Opposition Legal Framework
    When analyzing trademark oppositions, apply these legal principles:

    1. **Likelihood of Confusion Assessment**:
       - Consider the average consumer's perspective with imperfect recollection
       - Apply the global appreciation test (overall impression)
       - Consider interdependence principle (higher similarity in one aspect can offset lower similarity in another)
       - Focus on distinctive and dominant elements of the marks
       - Consider the distinctive character of the earlier mark

    2. **Section 5(2)(b) of the UK Trademarks Act** - Opposition succeeds if:
       - The marks are identical or similar
       - The goods/services are identical or similar
       - There exists a likelihood of confusion, including association
       
    3. **ECJ Guidance**:
       - The more distinctive the earlier mark, the greater the likelihood of confusion
       - Marks with highly distinctive elements receive broader protection
       - Visual, aural and conceptual similarities must be assessed globally

    ## Your Task
    For each trademark comparison:
    1. Analyze the visual, aural, conceptual and goods/services similarities
    2. Apply relevant legal principles to the specific case
    3. Predict the likely outcome with a confidence level
    4. Provide structured reasoning for your prediction

    ## Response Format
    Always maintain a formal, precise style appropriate for legal analysis. Your responses should:
    - Identify the key similarities and differences between marks
    - Apply legal principles to the specific case facts
    - Provide clear reasoning for your similarity assessments
    - Support your prediction with substantiated legal analysis
    - Use concise, structured formatting for clarity
    """
    
    # Tool input templates
    tools_description = """
    ## Tool Input Templates
    
    ### Visual Similarity Analysis
    ```
    {
      "applicant_wordmark": {
        "mark_text": "EXAMPLE", 
        "is_stylized": false
      },
      "opponent_wordmark": {
        "mark_text": "EXAMPLAR", 
        "is_stylized": false
      }
    }
    ```
    
    ### Aural Similarity Analysis
    ```
    {
      "applicant_wordmark": {
        "mark_text": "EXAMPLE", 
        "language": "en"
      },
      "opponent_wordmark": {
        "mark_text": "EXAMPLAR", 
        "language": "en"
      }
    }
    ```
    
    ### Conceptual Similarity Analysis
    ```
    {
      "applicant_wordmark": {
        "mark_text": "MOUNTAIN", 
        "language": "en"
      },
      "opponent_wordmark": {
        "mark_text": "PEAK", 
        "language": "en"
      }
    }
    ```
    
    ### Goods/Services Similarity Analysis
    ```
    {
      "applicant_goods_services": [
        {"term": "clothing", "nice_class": 25},
        {"term": "footwear", "nice_class": 25}
      ],
      "opponent_goods_services": [
        {"term": "apparel", "nice_class": 25},
        {"term": "hats", "nice_class": 25}
      ]
    }
    ```
    
    ### Opposition Outcome Prediction
    ```
    {
      "prediction_task": {
        "applicant_trademark": {
          "identifier": "UK12345",
          "wordmark": {"mark_text": "EXAMPLE"},
          "goods_services": [{"term": "clothing", "nice_class": 25}]
        },
        "opponent_trademark": {
          "identifier": "UK67890",
          "wordmark": {"mark_text": "EXAMPLAR"},
          "goods_services": [{"term": "apparel", "nice_class": 25}]
        },
        "similarity_scores": {
          "visual_similarity": 0.75,
          "aural_similarity": 0.80,
          "conceptual_similarity": 0.60,
          "goods_services_similarity": 0.90
        }
      }
    }
    ```
    """
    
    # Load specialized analytical prompts
    visual_analysis = _load_prompt_file("mark_visual_comparison.json")
    aural_analysis = _load_prompt_file("mark_aural_comparison.json")
    conceptual_analysis = _load_prompt_file("mark_conceptual_comparison.json")
    goods_services_analysis = _load_prompt_file("goods_services_comparison.json")
    
    # Specialized analytical prompts
    specialized_prompts = """
    ## Specialized Analysis Instructions
    
    ### Visual Analysis
    When analyzing visual similarity, consider:
    - Overall visual impression of the marks
    - Length of the marks and number of words
    - Common letters or elements
    - Distinctive and dominant elements
    - Beginning portions (often given more weight)
    - Stylization (if applicable)
    
    ### Aural Analysis
    When analyzing aural similarity, consider:
    - Syllable count and structure
    - Pronunciation in relevant language
    - Stress patterns and rhythm
    - Vowel and consonant sequences
    - Beginning and ending sounds
    
    ### Conceptual Analysis
    When analyzing conceptual similarity, consider:
    - Semantic meaning of the marks
    - Associations and connotations
    - Whether marks share a common origin or theme
    - Whether one mark is the translation of the other
    - Cultural or contextual references
    
    ### Goods/Services Analysis
    When analyzing goods/services similarity, consider:
    - Nature and purpose of the goods/services
    - Distribution channels and end users
    - Whether they are complementary or competitive
    - Nice Classification (though not determinative)
    - Market reality and consumer perception
    """
    
    # Combine all sections
    full_prompt = prompt.strip() + "\n\n" + tools_description.strip() + "\n\n" + specialized_prompts.strip()
    
    # Add examples if requested
    if include_examples:
        # Examples section from prediction_prompt.json if available
        prediction_prompt = _load_prompt_file("prediction_prompt.json")
        if "examples" in prediction_prompt:
            examples_text = "\n\n## Examples\n\n"
            for i, example in enumerate(prediction_prompt.get("examples", [])):
                examples_text += f"### Example {i+1}\n"
                examples_text += json.dumps(example, indent=2)
                examples_text += "\n\n"
            full_prompt += examples_text
    
    return full_prompt

def format_analysis_prompt(
    applicant_mark: str,
    opponent_mark: str,
    applicant_classes: List[int],
    opponent_classes: List[int],
    applicant_goods_services: List[str],
    opponent_goods_services: List[str]
) -> str:
    """
    Format a structured analysis prompt for trademark comparison.
    
    Args:
        applicant_mark: The applicant's wordmark text
        opponent_mark: The opponent's wordmark text
        applicant_classes: List of Nice classes for applicant
        opponent_classes: List of Nice classes for opponent
        applicant_goods_services: List of goods/services terms for applicant
        opponent_goods_services: List of goods/services terms for opponent
        
    Returns:
        Formatted analysis prompt
    """
    # Join classes and goods/services into readable strings
    applicant_classes_str = ", ".join(map(str, applicant_classes))
    opponent_classes_str = ", ".join(map(str, opponent_classes))
    
    applicant_goods_str = "\n- " + "\n- ".join(applicant_goods_services)
    opponent_goods_str = "\n- " + "\n- ".join(opponent_goods_services)
    
    # Create a structured prompt that highlights the comparison task
    prompt = f"""
    # Trademark Opposition Analysis Request

    Please analyze these trademarks and predict the opposition outcome:

    ## Trademark Details

    ### APPLICANT TRADEMARK
    **Wordmark:** {applicant_mark}
    **Nice Classes:** {applicant_classes_str}
    **Goods/Services:** {applicant_goods_str}

    ### OPPONENT TRADEMARK
    **Wordmark:** {opponent_mark}
    **Nice Classes:** {opponent_classes_str}
    **Goods/Services:** {opponent_goods_str}

    ## Analysis Tasks
    
    1. Compare the visual similarity between the wordmarks
    2. Compare the aural (phonetic) similarity between the wordmarks
    3. Compare the conceptual similarity between the wordmarks
    4. Compare the similarity between the goods/services
    5. Predict the likely outcome of the opposition proceedings
    
    Use the appropriate tools for each analysis step and provide your reasoning based on UK/EU trademark law principles.
    """
    
    return prompt.strip() 


================================================
FILE: src/logger.py
================================================
"""
Structured logging setup for the Trademark AI Agent.
"""

import logging
import os
import json
from typing import Any, Dict, Optional, Union

# Configure logging level from environment variables with default fallback
LOG_LEVEL = os.environ.get("LOG_LEVEL", "INFO").upper()
DEBUG = os.environ.get("DEBUG", "false").lower() == "true"

if DEBUG:
    LOG_LEVEL = "DEBUG"

# Create a custom JSON formatter for structured logging
class JsonFormatter(logging.Formatter):
    """
    Custom formatter to output logs in JSON format for structured logging.
    """
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record as JSON string."""
        log_record: Dict[str, Any] = {
            "timestamp": self.formatTime(record, self.datefmt),
            "level": record.levelname,
            "name": record.name,
            "message": record.getMessage(),
        }
        
        # Add exception info if available
        if record.exc_info:
            log_record["exception"] = self.formatException(record.exc_info)
        
        # Add any additional attributes from record.__dict__
        # that don't have defaults in LogRecord
        for key, value in record.__dict__.items():
            if key not in [
                "args", "asctime", "created", "exc_info", "exc_text", "filename",
                "funcName", "id", "levelname", "levelno", "lineno", "module",
                "msecs", "message", "msg", "name", "pathname", "process",
                "processName", "relativeCreated", "stack_info", "thread", "threadName"
            ]:
                log_record[key] = value
        
        return json.dumps(log_record)

# Create a logger factory
def get_logger(name: str) -> logging.Logger:
    """
    Creates and returns a logger with the specified name,
    configured for structured logging with proper handlers.
    
    Args:
        name: The name of the logger, typically __name__.
        
    Returns:
        A configured logger instance.
    """
    logger = logging.getLogger(name)
    
    # Avoid adding handlers if they already exist
    if logger.handlers:
        return logger
    
    # Set level from environment
    level = getattr(logging, LOG_LEVEL, logging.INFO)
    logger.setLevel(level)
    
    # Create console handler with a JSON formatter
    handler = logging.StreamHandler()
    handler.setFormatter(JsonFormatter())
    logger.addHandler(handler)
    
    return logger

# Create a base logger for the application
logger = get_logger("trademark_ai")

# Convenience methods for adding context to logs
def log_with_context(
    level: int,
    msg: str,
    context: Optional[Dict[str, Any]] = None,
    **kwargs: Any
) -> None:
    """
    Log a message with additional context.
    
    Args:
        level: The logging level (e.g., logging.INFO).
        msg: The log message.
        context: Optional dictionary with additional context.
        **kwargs: Additional key-value pairs to include in the log.
    """
    if context:
        kwargs.update(context)
    
    extra = {"context": kwargs} if kwargs else {}
    logger.log(level, msg, extra=extra)

def debug(msg: str, context: Optional[Dict[str, Any]] = None, **kwargs: Any) -> None:
    """Log a DEBUG level message with context."""
    log_with_context(logging.DEBUG, msg, context, **kwargs)

def info(msg: str, context: Optional[Dict[str, Any]] = None, **kwargs: Any) -> None:
    """Log an INFO level message with context."""
    log_with_context(logging.INFO, msg, context, **kwargs)

def warning(msg: str, context: Optional[Dict[str, Any]] = None, **kwargs: Any) -> None:
    """Log a WARNING level message with context."""
    log_with_context(logging.WARNING, msg, context, **kwargs)

def error(msg: str, context: Optional[Dict[str, Any]] = None, **kwargs: Any) -> None:
    """Log an ERROR level message with context."""
    log_with_context(logging.ERROR, msg, context, **kwargs)

def critical(msg: str, context: Optional[Dict[str, Any]] = None, **kwargs: Any) -> None:
    """Log a CRITICAL level message with context."""
    log_with_context(logging.CRITICAL, msg, context, **kwargs)

def exception(
    msg: str, 
    exc: Optional[Exception] = None, 
    context: Optional[Dict[str, Any]] = None, 
    **kwargs: Any
) -> None:
    """
    Log an exception with context.
    
    Args:
        msg: The error message.
        exc: The exception object.
        context: Additional context information.
        **kwargs: Additional key-value pairs for the log.
    """
    if exc:
        kwargs["exception_type"] = type(exc).__name__
        kwargs["exception_message"] = str(exc)
    
    log_with_context(logging.ERROR, msg, context, **kwargs)
    if exc:
        logger.exception(msg)  # This adds the traceback 


================================================
FILE: src/main.py
================================================
# src/main.py
"""
Google Cloud Function entry point for the Trademark AI Agent.

This function receives HTTP requests, parses the incoming JSON payload
into a Pydantic model, initializes the ADK agent, invokes the agent
to process the request, and returns the formatted response.
"""

import json
import os
from typing import Any, Dict, List, Tuple, Union
from uuid import uuid4 # Added for session management

import functions_framework
from flask import Request, Response
# Updated ADK imports
from google.adk.agents import Agent
from google.genai import Content, Part
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from google.adk.artifacts import InMemoryArtifactService
from google.adk.tools import BaseTool # Aligning with documentation pattern
from pydantic import ValidationError
from fastapi import FastAPI, Depends
from google.adk.cli.fast_api import get_fast_api_app

# Import input/output models and the list of tools
from src.models import SimilarityTaskInput, SimilarityScores, Trademark, Wordmark, GoodsService
from src.tools.similarity_tools import trademark_similarity_tools # Import the list
from src.tools.prediction_tools import prediction_tools # Import prediction tools
from src.db import initialize_database
from src.logger import get_logger, info, warning, error, exception
from src.prompts.gemini_agent_prompt import get_adk_agent_prompt, format_analysis_prompt

# Initialize logger
logger = get_logger(__name__)

# Get the directory where main.py is located
APP_DIR = os.path.dirname(os.path.abspath(__file__))

# Example session DB URL (using SQLite for simplicity)
SESSION_DB_URL = "sqlite:///./sessions.db"

# Example allowed origins for CORS
ALLOWED_ORIGINS = ["*"]  # Adjust based on your security requirements

# Set web=False since we're using Cloud Functions
SERVE_WEB_INTERFACE = False

# Create toolkit with all available tools
trademark_tools = trademark_similarity_tools + prediction_tools

# Get the FastAPI app instance
app: FastAPI = get_fast_api_app(
    agent_dir=APP_DIR,
    session_db_url=SESSION_DB_URL,
    allow_origins=ALLOWED_ORIGINS,
    web=SERVE_WEB_INTERFACE,
)

# Initialize the agent with tools
async def get_agent() -> Agent:
    """
    Creates and returns the ADK Agent with properly configured tools.
    Called as a FastAPI dependency.
    """
    # Create services for session management and artifact storage
    session_service = InMemorySessionService()
    artifact_service = InMemoryArtifactService()
    
    # Get the optimized agent prompt with examples
    agent_prompt = get_adk_agent_prompt(include_examples=True)
    
    # Create the agent with tools and prompt template
    agent = Agent(
        tools=trademark_tools,
        session_service=session_service,
        artifact_service=artifact_service,
        default_prompt_context=agent_prompt,
    )
    
    return agent

# Set up startup event to run database initialization
@app.on_event("startup")
async def startup_db_client():
    """Initialize database on application startup."""
    try:
        logger.info("Running startup tasks")
        await initialize_database()
    except Exception as e:
        logger.exception("Error during startup", exc=e)
        # We log the error but don't raise to allow the service to start
        # even if DB initialization fails

# Set up shutdown event
@app.on_event("shutdown")
async def shutdown_db_client():
    """Clean up resources on application shutdown."""
    logger.info("Shutting down application")
    # Add any cleanup logic here (closing sessions, etc.)

# --- Main Cloud Function Handler ---

@functions_framework.http
async def handle_request(request: Request) -> Response:
    """
    Cloud Function entry point that forwards requests to the FastAPI application.
    """
    # Convert Flask request to FastAPI request and handle it
    path = request.path
    if not path:
        path = "/"
        
    # Forward the request to the appropriate FastAPI endpoint
    if request.method == "POST" and path == "/":
        # Default to /run endpoint for POST requests to root
        path = "/run"
    
    # Get query parameters
    query_params = request.args.to_dict()
    
    # Get headers
    headers = {k: v for k, v in request.headers}
    
    # Get body
    body = request.get_data()
    
    # Log the incoming request
    logger.info(
        "Incoming request",
        method=request.method,
        path=path,
        content_length=len(body) if body else 0
    )
    
    # Create scope for FastAPI
    scope = {
        "type": "http",
        "http_version": "1.1",
        "method": request.method,
        "scheme": request.scheme,
        "path": path,
        "query_string": request.query_string,
        "headers": [(k.lower().encode(), v.encode()) for k, v in headers.items()],
    }
    
    # Handle the request through FastAPI
    async def receive():
        return {"type": "http.request", "body": body}
    
    async def send(message):
        if message["type"] == "http.response.start":
            nonlocal status_code, response_headers
            status_code = message["status"]
            response_headers = {k.decode(): v.decode() for k, v in message["headers"]}
        elif message["type"] == "http.response.body":
            nonlocal response_body
            response_body = message["body"]
    
    status_code = 200
    response_headers = {}
    response_body = b""
    
    # Call FastAPI
    await app(scope, receive, send)
    
    # Log the response
    logger.info(
        "Sending response",
        status_code=status_code,
        content_length=len(response_body) if response_body else 0
    )
    
    # Convert to Flask response
    response = Response(
        response=response_body,
        status=status_code,
        headers=response_headers,
    )
    return response

# Define a custom ADK endpoint in FastAPI
@app.post("/analyze")
async def analyze_trademarks(
    data: SimilarityTaskInput,
    agent: Agent = Depends(get_agent)
):
    """
    Custom endpoint for trademark analysis.
    Provides a more structured API interface for direct integration.
    
    Args:
        data: The trademark comparison data.
        agent: ADK agent dependency.
    
    Returns:
        Analysis results with similarity scores and prediction.
    """
    try:
        # Log the request
        logger.info("Analyzing trademarks", 
                   applicant=data.applicant_trademark.identifier,
                   opponent=data.opponent_trademark.identifier)
        
        # Extract trademark details for the prompt
        applicant_mark = data.applicant_trademark.wordmark.mark_text
        opponent_mark = data.opponent_trademark.wordmark.mark_text
        
        # Extract classes and goods/services lists
        applicant_classes = [gs.nice_class for gs in data.applicant_trademark.goods_services]
        opponent_classes = [gs.nice_class for gs in data.opponent_trademark.goods_services]
        
        applicant_goods_services = [gs.term for gs in data.applicant_trademark.goods_services]
        opponent_goods_services = [gs.term for gs in data.opponent_trademark.goods_services]
        
        # Generate a structured analysis prompt
        analysis_prompt = format_analysis_prompt(
            applicant_mark=applicant_mark,
            opponent_mark=opponent_mark,
            applicant_classes=applicant_classes,
            opponent_classes=opponent_classes,
            applicant_goods_services=applicant_goods_services,
            opponent_goods_services=opponent_goods_services
        )
        
        # Prepare input for the agent
        session_id = str(uuid4())
        
        # Create a request content with the structured analysis prompt
        request_content = [
            Content(
                parts=[
                    Part(text=analysis_prompt),
                ],
                role="user",
            )
        ]
        
        # Create a runner and run the agent
        runner = Runner(agent)
        response = await runner.chat_async(
            session_id=session_id,
            message=request_content,
            tools=trademark_tools,
        )
        
        # Process and structure the agent's response
        analysis_result = {
            "message": "Trademark analysis completed",
            "applicant_identifier": data.applicant_trademark.identifier,
            "opponent_identifier": data.opponent_trademark.identifier,
            "analysis": response.text,
        }
        
        # Extract tool calls and results if present
        if hasattr(response, 'tool_calls') and response.tool_calls:
            tool_results = []
            for tool_call in response.tool_calls:
                tool_results.append({
                    "tool": tool_call.name,
                    "input": tool_call.input,
                    "output": tool_call.output
                })
            analysis_result["tool_results"] = tool_results
        
        return analysis_result
    
    except ValidationError as e:
        logger.error("Validation error", error=str(e))
        return {"error": f"Invalid input data: {e}"}
    except Exception as e:
        logger.exception("Error processing trademark analysis", exc=e)
        return {"error": f"Error processing request: {str(e)}"}

# Define an endpoint for individual similarity calculations
@app.post("/calculate-similarity")
async def calculate_similarity(
    data: SimilarityTaskInput,
    similarity_type: str,
    agent: Agent = Depends(get_agent)
):
    """
    Endpoint for calculating individual similarity metrics between trademarks.
    
    Args:
        data: The trademark comparison data
        similarity_type: Type of similarity to calculate (visual, aural, conceptual, goods_services)
        agent: ADK agent dependency
        
    Returns:
        Similarity calculation result
    """
    valid_types = ["visual", "aural", "conceptual", "goods_services", "overall"]
    
    if similarity_type not in valid_types:
        return {"error": f"Invalid similarity type. Must be one of: {', '.join(valid_types)}"}
    
    try:
        # Create session ID
        session_id = str(uuid4())
        
        # Determine which tool to call based on similarity type
        if similarity_type == "visual":
            tool_name = "calculate_visual_wordmark_similarity_tool"
            tool_input = {
                "applicant_wordmark": data.applicant_trademark.wordmark,
                "opponent_wordmark": data.opponent_trademark.wordmark
            }
        elif similarity_type == "aural":
            tool_name = "calculate_aural_wordmark_similarity_tool"
            tool_input = {
                "applicant_wordmark": data.applicant_trademark.wordmark,
                "opponent_wordmark": data.opponent_trademark.wordmark
            }
        elif similarity_type == "conceptual":
            tool_name = "calculate_conceptual_wordmark_similarity_tool"
            tool_input = {
                "applicant_wordmark": data.applicant_trademark.wordmark,
                "opponent_wordmark": data.opponent_trademark.wordmark
            }
        elif similarity_type == "goods_services":
            tool_name = "calculate_goods_services_similarity_tool"
            tool_input = {
                "applicant_goods_services": data.applicant_trademark.goods_services,
                "opponent_goods_services": data.opponent_trademark.goods_services
            }
        elif similarity_type == "overall":
            # For overall similarity, we first need to calculate all individual similarities
            # and then pass them to the overall similarity calculator
            # This logic would need to be implemented
            return {"error": "Overall similarity calculation requires all other similarity scores first"}
        
        # Directly invoke the appropriate tool using runner.adk_tool_call_async
        runner = Runner(agent)
        response = await runner.adk_tool_call_async(
            session_id=session_id,
            tool_name=tool_name,
            tool_input=tool_input
        )
        
        return {
            "similarity_type": similarity_type,
            "score": response,
            "applicant_identifier": data.applicant_trademark.identifier,
            "opponent_identifier": data.opponent_trademark.identifier
        }
    
    except Exception as e:
        logger.exception(f"Error calculating {similarity_type} similarity", exc=e)
        return {"error": f"Error calculating similarity: {str(e)}"}

# Define a prediction endpoint for opposition outcomes
@app.post("/predict")
async def predict_opposition_outcome(
    scores: SimilarityScores,
    data: SimilarityTaskInput,
    agent: Agent = Depends(get_agent)
):
    """
    Endpoint for predicting trademark opposition outcomes based on calculated similarity scores.
    
    Args:
        scores: The similarity scores calculated for the trademarks
        data: The trademark comparison data
        agent: ADK agent dependency
        
    Returns:
        Opposition prediction result
    """
    try:
        # Create session ID
        session_id = str(uuid4())
        
        # Create the prediction input
        prediction_input = {
            "prediction_task": {
                "applicant_trademark": data.applicant_trademark,
                "opponent_trademark": data.opponent_trademark,
                "similarity_scores": scores
            }
        }
        
        # Directly invoke the prediction tool
        runner = Runner(agent)
        prediction = await runner.adk_tool_call_async(
            session_id=session_id,
            tool_name="predict_opposition_outcome_tool",
            tool_input=prediction_input
        )
        
        return {
            "applicant_identifier": data.applicant_trademark.identifier,
            "opponent_identifier": data.opponent_trademark.identifier,
            "prediction": prediction
        }
    
    except Exception as e:
        logger.exception("Error predicting opposition outcome", exc=e)
        return {"error": f"Error predicting opposition outcome: {str(e)}"}

if __name__ == "__main__":
    # For local development
    import uvicorn
    port = int(os.environ.get("PORT", 8080))
    uvicorn.run(app, host="0.0.0.0", port=port)


================================================
FILE: src/models.py
================================================
# src/models.py
"""
Pydantic models for representing trademark data, similarity inputs/outputs,
and prediction results within the UK/EU Trademark AI Agent.

SQLAlchemy models for database interaction.
"""

from typing import List, Optional

from pydantic import BaseModel, Field
import sqlalchemy  # Add import for sqlalchemy module

# --- Pydantic Models ---

class GoodsService(BaseModel):
    """
    Represents a single item of goods or services associated with a trademark.

    Attributes:
        term: The specific description of the good or service.
        nice_class: The NICE classification class number.
        # Removed embedding: it's stored separately according to the schema
    """

    term: str = Field(..., description="The specific description of the good or service.")
    nice_class: int = Field(..., description="The NICE classification class number.")
    # embedding: Optional[List[float]] = Field( <-- Removed
    #     default=None,
    #     description="Vector embedding for semantic similarity using pgvector.",
    # )


class Wordmark(BaseModel):
    """
    Represents the textual element (wordmark) of a trademark.

    This is used for comparisons based on visual, aural, and conceptual
    similarity algorithms (e.g., Levenshtein, phonetic matching).

    Attributes:
        mark_text: The literal text of the wordmark.
    """

    mark_text: str = Field(..., description="The literal text of the wordmark.")


class Trademark(BaseModel):
    """
    Represents the core comparable elements of a trademark application or registration.
    (Note: This Pydantic model represents input/transfer data, not the DB structure directly)

    Attributes:
        identifier: A unique identifier for the trademark (e.g., application number).
        wordmark: The textual Wordmark component of the trademark.
        goods_services: A list of GoodsService items associated with the trademark.
    """

    identifier: str = Field(
        ..., description="Unique identifier (e.g., application/registration number)."
    )
    wordmark: Wordmark = Field(..., description="The textual Wordmark component.")
    goods_services: List[GoodsService] = Field(
        ..., description="List of goods and services associated with the trademark."
    )


class SimilarityTaskInput(BaseModel):
    """
    Input data structure for the trademark similarity analysis task.

    Bundles the two trademarks (applicant's and opponent's) to be compared.

    Attributes:
        applicant_trademark: The Trademark object representing the applicant's mark.
        opponent_trademark: The Trademark object representing the opponent's mark.
    """

    applicant_trademark: Trademark = Field(
        ..., description="The applicant's trademark data."
    )
    opponent_trademark: Trademark = Field(
        ..., description="The opponent's trademark data."
    )


class SimilarityScores(BaseModel):
    """
    Holds the calculated similarity scores between two trademarks across various dimensions.

    These scores result from different comparison algorithms (e.g., vector distance
    for goods/services, Levenshtein for visual, phonetic algorithms for aural).

    Attributes:
        goods_services_similarity: Similarity score based on goods/services (often semantic/vector).
        visual_similarity: Similarity score based on visual appearance of wordmarks (e.g., Levenshtein).
        aural_similarity: Similarity score based on phonetic similarity of wordmarks.
        conceptual_similarity: Similarity score based on the meaning/concept of wordmarks.
    """

    goods_services_similarity: Optional[float] = Field(
        default=None, description="Similarity score for goods and services."
    )
    visual_similarity: Optional[float] = Field(
        default=None, description="Visual similarity score for wordmarks."
    )
    aural_similarity: Optional[float] = Field(
        default=None, description="Aural similarity score for wordmarks."
    )
    conceptual_similarity: Optional[float] = Field(
        default=None, description="Conceptual similarity score for wordmarks."
    )


class PredictionTaskInput(BaseModel):
    """
    Input data structure for the opposition outcome prediction task.

    Combines the details of the compared trademarks and their calculated
    similarity scores, serving as features for the prediction model/logic.

    Attributes:
        applicant_trademark: The Trademark object representing the applicant's mark.
        opponent_trademark: The Trademark object representing the opponent's mark.
        similarity_scores: The calculated SimilarityScores between the two trademarks.
    """

    applicant_trademark: Trademark = Field(
        ..., description="The applicant's trademark data."
    )
    opponent_trademark: Trademark = Field(
        ..., description="The opponent's trademark data."
    )
    similarity_scores: SimilarityScores = Field(
        ..., description="Calculated similarity scores between the trademarks."
    )


class PredictionResult(BaseModel):
    """
    Represents the output of the trademark opposition outcome prediction.

    Attributes:
        predicted_outcome: The predicted outcome string (e.g., 'Opposition Likely Succeeds').
        confidence_score: An optional score indicating the prediction confidence (0.0 to 1.0).
        reasoning: An optional explanation or justification for the predicted outcome.
    """

    predicted_outcome: str = Field(..., description="The predicted outcome string.")
    confidence_score: Optional[float] = Field(
        default=None, description="Confidence score of the prediction (0.0-1.0)."
    )
    reasoning: Optional[str] = Field(
        default=None, description="Explanation for the prediction."
    )


# --- SQLAlchemy ORM Definitions ---

from sqlalchemy import Column, Integer, String, Float, ForeignKey, Index, VARCHAR, TIMESTAMP
from sqlalchemy.orm import declarative_base, relationship
from sqlalchemy.dialects.postgresql import ARRAY
from pgvector.sqlalchemy import Vector  # Changed from sqlalchemy_pgvector.types import VECTOR

# Embedding dimension based on the migration file
# EMBEDDING_DIMENSION = 1536
# Update dimension based on the chosen model (all-MiniLM-L6-v2)
EMBEDDING_DIMENSION = 384

Base = declarative_base()


# Removed TrademarkOrm as it doesn't align with the provided schema's structure
# (trademark_cases, applicant_marks, etc.)
# class TrademarkOrm(Base):
#     ...


class GoodsServiceOrm(Base):
    """
    SQLAlchemy ORM model representing the 'goods_services' table.

    Stores individual goods or services items, including their term,
    NICE class, and creation/update timestamps. Embeddings are stored
    in the separate 'vector_embeddings' table according to the schema.
    """
    __tablename__ = 'goods_services'

    id: Column[int] = Column(Integer, primary_key=True)
    term: Column[str] = Column(String, nullable=False) # Assuming String is appropriate, adjust if Text needed
    nice_class: Column[int] = Column(Integer, index=True, nullable=False)
    # Removed embedding column:
    # embedding: Column[ARRAY] = Column(ARRAY(Float), nullable=True)
    # trademark_id: Column[int] = Column(Integer, ForeignKey('trademarks.id'), nullable=False) <-- Removed, schema links differently
    created_at: Column[TIMESTAMP] = Column(TIMESTAMP(timezone=True), server_default=sqlalchemy.func.now())
    updated_at: Column[TIMESTAMP] = Column(TIMESTAMP(timezone=True), server_default=sqlalchemy.func.now(), onupdate=sqlalchemy.func.now())


    # Relationship to embeddings
    # Note: This defines how to load embeddings *related* to this GoodsServiceOrm instance.
    # The condition links VectorEmbeddingOrm based on entity_type and this instance's ID.
    embeddings = relationship(
        "VectorEmbeddingOrm",
        primaryjoin="and_(VectorEmbeddingOrm.entity_type=='goods_services', foreign(VectorEmbeddingOrm.entity_id)==GoodsServiceOrm.id)",
        back_populates="goods_service", # Links back to the relationship in VectorEmbeddingOrm
        viewonly=True, # Typically viewonly if embeddings aren't managed *through* GoodsServiceOrm
        # overlaps="embeddings" # Removed 'overlaps' as it was causing issues previously and might not be needed with explicit primaryjoin and back_populates
    )


    # Relationship back to the parent trademark (REMOVED, needs rethinking based on full schema)
    # trademark = relationship("TrademarkOrm", back_populates="goods_services")

    # Relationship to embeddings (if needed, needs explicit setup)
    # embeddings = relationship("VectorEmbeddingOrm", primaryjoin="and_(VectorEmbeddingOrm.entity_type=='goods_services', foreign(VectorEmbeddingOrm.entity_id)==GoodsServiceOrm.id)", overlaps="embeddings")


    def __repr__(self) -> str:
        # return f"<GoodsServiceOrm(id={self.id}, term='{self.term}', nice_class={self.nice_class}, trademark_id={self.trademark_id})>" <-- Updated
        return f"<GoodsServiceOrm(id={self.id}, term='{self.term}', nice_class={self.nice_class})>"


class VectorEmbeddingOrm(Base):
    """
    SQLAlchemy ORM model representing the 'vector_embeddings' table.

    Stores vector embeddings linked to different entity types (e.g., goods_services).
    """
    __tablename__ = 'vector_embeddings'

    id: Column[int] = Column(Integer, primary_key=True)
    entity_type: Column[str] = Column(VARCHAR(50), nullable=False, index=True) # Added index based on schema
    entity_id: Column[int] = Column(Integer, nullable=False, index=True) # Added index based on schema
    embedding: Column[Vector] = Column(Vector(EMBEDDING_DIMENSION), nullable=False) # Use Vector type (updated from VECTOR)
    created_at: Column[TIMESTAMP] = Column(TIMESTAMP(timezone=True), server_default=sqlalchemy.func.now())
    updated_at: Column[TIMESTAMP] = Column(TIMESTAMP(timezone=True), server_default=sqlalchemy.func.now(), onupdate=sqlalchemy.func.now())

    # Define relationship back to the specific GoodsServiceOrm entity
    # This allows navigating from an embedding back to the specific GoodsServiceOrm it belongs to.
    goods_service = relationship(
        "GoodsServiceOrm",
        primaryjoin="and_(VectorEmbeddingOrm.entity_type=='goods_services', foreign(VectorEmbeddingOrm.entity_id)==GoodsServiceOrm.id)",
        back_populates="embeddings", # Links back to the relationship defined in GoodsServiceOrm
        uselist=False, # An embedding belongs to one GoodsServiceOrm
        viewonly=True, # Typically viewonly if GoodsServiceOrm isn't managed *through* the embedding
        # overlaps="goods_service" # Removed 'overlaps' as it was causing issues previously and might not be needed with explicit primaryjoin and back_populates
    )

    # NOTE: If relationships to other entity types (e.g., 'trademark_cases') are needed,
    # similar relationship definitions would be added here and in the corresponding ORM classes.

    __table_args__ = (
        Index('idx_vector_embeddings_entity', 'entity_type', 'entity_id'), # Explicit index based on schema
    )

    def __repr__(self) -> str:
        return f"<VectorEmbeddingOrm(id={self.id}, entity_type='{self.entity_type}', entity_id={self.entity_id})>"

# Need to import sqlalchemy for server_default=sqlalchemy.func.now()
import sqlalchemy


================================================
FILE: src/similarity.py
================================================
# src/similarity.py
"""
Functions for calculating trademark similarity metrics.

Includes visual similarity based on Levenshtein distance and
goods/services similarity based on vector embeddings.
"""

import Levenshtein
import numpy as np
from typing import List, Optional

# Assuming db functions handle sessions appropriately or we manage them here
from src.db import find_similar_goods_services, get_async_session # Import async version
from src.embeddings import generate_embedding
from src.models import Wordmark, GoodsService
from src.logger import get_logger, info, warning, error, exception

# Import for aural similarity
from metaphone import doublemetaphone

# Import for conceptual similarity (using numpy for cosine calculation)
import numpy as np

# Initialize logger
logger = get_logger(__name__)

def calculate_visual_similarity(mark1: Wordmark, mark2: Wordmark) -> float:
    """
    Calculates the normalized visual similarity between two wordmarks.

    Uses the Levenshtein ratio algorithm, which measures the similarity
    between two strings as a float between 0.0 and 1.0 (inclusive).
    1.0 indicates identical strings, 0.0 indicates maximum dissimilarity.

    The comparison is case-insensitive. Empty strings are handled according
    to the Levenshtein library's behavior (ratio is 0.0 if one string is
    empty, 1.0 if both are empty).

    Args:
        mark1: The first Wordmark object.
        mark2: The second Wordmark object.

    Returns:
        A float between 0.0 and 1.0 representing the normalized
        visual similarity ratio.
    """
    text1: str = mark1.mark_text.lower() if mark1 and mark1.mark_text else ""
    text2: str = mark2.mark_text.lower() if mark2 and mark2.mark_text else ""

    # Levenshtein.ratio returns 1.0 for two empty strings, 0.0 if one is empty.
    # It handles None implicitly if converted to "" first.
    similarity_ratio: float = Levenshtein.ratio(text1, text2)
    
    # Log the calculation
    info("Calculated visual similarity", mark1=text1, mark2=text2, similarity=similarity_ratio)

    return similarity_ratio


async def calculate_goods_services_similarity( # Make the function async
    applicant_gs: List[GoodsService],
    opponent_gs: List[GoodsService], # Currently unused, assumes opponent data is in DB
    similarity_threshold: float = 0.8 # Example threshold for cosine similarity (1 - distance)
) -> Optional[float]:
    """
    Calculates an aggregate similarity score between two lists of goods/services asynchronously.

    This version generates embeddings for the applicant's terms and searches
    for the most similar terms in the database (assumed to contain opponent/indexed data)
    using asynchronous database operations.
    It averages the similarity scores of the best matches found for each applicant term.

    Args:
        applicant_gs: List of GoodsService objects for the applicant.
        opponent_gs: List of GoodsService objects for the opponent (currently unused).
        similarity_threshold: Minimum cosine similarity score to consider a match.

    Returns:
        An aggregate similarity score (0.0 to 1.0), or None if calculation fails
        (e.g., no applicant terms, embedding errors, no matches found).
    """
    if not applicant_gs:
        logger.warning("Empty applicant goods/services list provided")
        return 0.0 # Or None, depending on desired handling of empty lists

    AsyncSessionLocal = await get_async_session() # Await the async session factory
    all_min_distances = [] # Store the minimum distance found for each applicant term

    # Use async session context manager
    async with AsyncSessionLocal() as session:
        # Optionally use session.begin() to manage transactions if storing embeddings here
        # async with session.begin():
        try:
            for app_item in applicant_gs:
                if not app_item.term:
                    continue

                # Use the async version of generate_embedding
                app_embedding = await generate_embedding(app_item.term)
                if app_embedding is None:
                    warning("Could not generate embedding for applicant term", term=app_item.term)
                    continue

                # Find the most similar term(s) asynchronously
                similar_items = await find_similar_goods_services(
                    app_embedding,
                    limit=1,
                    session=session # Pass the async session
                )

                if similar_items:
                    # similar_items is List[Tuple[GoodsServiceOrm, float]]
                    best_match_distance = similar_items[0][1]
                    best_match_term = similar_items[0][0].term
                    all_min_distances.append(best_match_distance)
                    info("Found similar goods/services term", 
                         applicant_term=app_item.term, 
                         best_match=best_match_term, 
                         distance=best_match_distance)
                else:
                    warning("No similar item found in DB for applicant term", term=app_item.term)
                    all_min_distances.append(2.0) # Max cosine distance

            if not all_min_distances:
                warning("No comparable goods/services found after embedding/search")
                return None

            avg_min_distance = np.mean(all_min_distances)
            aggregate_similarity = max(0.0, 1.0 - (avg_min_distance / 2.0))
            
            info("Calculated goods/services similarity", 
                 similarity=aggregate_similarity, 
                 avg_distance=avg_min_distance, 
                 num_terms=len(all_min_distances))

            return aggregate_similarity

        except Exception as e:
            exception("Error calculating goods/services similarity", exc=e)
            # Rollback is handled automatically if using session.begin()
            # If not using session.begin(), explicit rollback might be needed depending on error and operations
            # await session.rollback() # Consider if needed without session.begin()
            return None
        # No finally block needed to close session, context manager handles it


def calculate_aural_similarity(mark1: Wordmark, mark2: Wordmark) -> float:
    """
    Calculates the normalized aural similarity between two wordmarks.

    Uses the Double Metaphone algorithm to generate phonetic codes for the words
    and then calculates the Levenshtein ratio between these codes.
    Comparison is case-insensitive.

    Args:
        mark1: The first Wordmark object.
        mark2: The second Wordmark object.

    Returns:
        A float between 0.0 and 1.0 representing the normalized aural similarity ratio.
    """
    text1: str = mark1.mark_text.strip() if mark1 and mark1.mark_text else ""
    text2: str = mark2.mark_text.strip() if mark2 and mark2.mark_text else ""

    if not text1 and not text2:
        info("Both wordmarks are empty, aural similarity set to 1.0")
        return 1.0 # Both empty
    if not text1 or not text2:
        info("One wordmark is empty, aural similarity set to 0.0", 
             mark1=text1 or "(empty)", mark2=text2 or "(empty)")
        return 0.0 # One empty

    # Generate Double Metaphone codes (primary, alternate)
    # We compare primary to primary and alternate to alternate if available,
    # taking the max similarity. Simpler approach: just use primary.
    codes1 = doublemetaphone(text1)
    codes2 = doublemetaphone(text2)

    primary_code1 = codes1[0]
    primary_code2 = codes2[0]

    # Calculate similarity based on primary codes
    similarity = Levenshtein.ratio(primary_code1, primary_code2)
    
    info("Calculated aural similarity", 
         mark1=text1, mark2=text2, 
         phonetic_code1=primary_code1, phonetic_code2=primary_code2,
         similarity=similarity)

    # Optional: Consider alternate codes for potentially higher similarity
    # alt_code1 = codes1[1]
    # alt_code2 = codes2[1]
    # if alt_code1 and alt_code2:
    #     alt_similarity = Levenshtein.ratio(alt_code1, alt_code2)
    #     similarity = max(similarity, alt_similarity)
    # Could also compare primary1 vs alt2 and primary2 vs alt1 if needed.

    return similarity


async def calculate_conceptual_similarity(mark1: Wordmark, mark2: Wordmark) -> Optional[float]:
    """
    Calculates the conceptual similarity between two wordmarks based on embeddings
    and legal trademark conceptual patterns.
    
    This enhanced version combines multiple approaches:
    1. Vector embedding similarity (capturing general semantic relationships)
    2. LegalBERT domain-specific legal embeddings (for legal conceptual relationships)
    3. Detection of common conceptual relationships in trademark law:
       - Direct synonyms or near-synonyms
       - Conceptual opposites (which can still be similar in trademark context)
       - Words sharing the same root/stem
       - Special category patterns (animals, colors, numbers, etc.)
       - Translation equivalents
    
    Args:
        mark1: The first Wordmark object.
        mark2: The second Wordmark object.
        
    Returns:
        A float between 0.0 (conceptually dissimilar) and 1.0 (conceptually identical) 
        representing the legal conceptual similarity, or None if analysis fails.
    """
    from nltk.stem import PorterStemmer, WordNetLemmatizer
    import nltk
    from nltk.corpus import wordnet
    import re
    import numpy as np
    
    # Ensure required NLTK data is available
    try:
        nltk.data.find('corpora/wordnet')
    except LookupError:
        try:
            logger.info("Downloading wordnet for enhanced conceptual similarity")
            nltk.download('wordnet', quiet=True)
        except Exception as e:
            exception("Could not download wordnet for enhanced conceptual similarity", exc=e)
    
    text1: str = mark1.mark_text.strip().lower() if mark1 and mark1.mark_text else ""
    text2: str = mark2.mark_text.strip().lower() if mark2 and mark2.mark_text else ""
    
    if not text1 or not text2:
        # Cannot compare if one is empty in this context
        warning("Cannot calculate conceptual similarity with empty wordmark(s)", 
                mark1=text1 or "(empty)", mark2=text2 or "(empty)")
        return None
    
    # --- 1. Base vector similarity (using existing code) ---
    base_similarity = None
    try:
        # Use the async version of generate_embedding
        emb1 = await generate_embedding(text1)
        emb2 = await generate_embedding(text2)
        
        if emb1 is None or emb2 is None:
            warning("Could not generate embedding for one or both wordmarks for conceptual similarity", 
                    mark1=text1, mark2=text2)
        else:
            # Calculate Cosine Similarity
            vec1 = np.array(emb1)
            vec2 = np.array(emb2)
            cosine_sim = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
            
            # Clamp the value between 0 and 1 (cosine similarity is -1 to 1)
            # We map it to 0-1 where 1 is most similar
            base_similarity = (cosine_sim + 1) / 2.0
            base_similarity = max(0.0, min(1.0, base_similarity))  # Ensure bounds
            
            info("Calculated base vector similarity for conceptual comparison",
                 mark1=text1, mark2=text2, base_similarity=base_similarity)
    except Exception as e:
        exception("Error calculating base vector similarity", exc=e, mark1=text1, mark2=text2)
    
    # --- 1.5 NEW: Legal domain-specific similarity with LegalBERT ---
    legal_similarity = None
    try:
        # Use the LegalBERT embeddings
        from src.embeddings import generate_legal_embedding
        
        legal_emb1 = await generate_legal_embedding(text1)
        legal_emb2 = await generate_legal_embedding(text2)
        
        if legal_emb1 is None or legal_emb2 is None:
            warning("Could not generate LegalBERT embedding for one or both wordmarks", 
                    mark1=text1, mark2=text2)
        else:
            # Calculate Cosine Similarity for legal embeddings
            legal_vec1 = np.array(legal_emb1)
            legal_vec2 = np.array(legal_emb2)
            legal_cosine_sim = np.dot(legal_vec1, legal_vec2) / (np.linalg.norm(legal_vec1) * np.linalg.norm(legal_vec2))
            
            # Normalize to 0-1 scale
            legal_similarity = (legal_cosine_sim + 1) / 2.0
            legal_similarity = max(0.0, min(1.0, legal_similarity))  # Ensure bounds
            
            info("Calculated LegalBERT similarity for conceptual comparison",
                 mark1=text1, mark2=text2, legal_similarity=legal_similarity)
            
            # We can give legal_similarity a bit more weight in the legal trademark context
            if base_similarity is not None:
                # Weighted average: 60% legal domain knowledge, 40% general semantics
                base_similarity = (legal_similarity * 0.6) + (base_similarity * 0.4)
                info("Combined LegalBERT and general embeddings",
                     mark1=text1, mark2=text2, combined_similarity=base_similarity)
            else:
                # If base_similarity failed, use legal_similarity as base
                base_similarity = legal_similarity
    except Exception as e:
        exception("Error calculating LegalBERT similarity", exc=e, mark1=text1, mark2=text2)
    
    # --- 2. Enhanced legal conceptual analysis ---
    
    # Helper function to tokenize wordmarks
    def tokenize(text):
        # Simple tokenization - split on non-alphanumeric chars and normalize
        return [t.lower() for t in re.findall(r'\w+', text)]
    
    # Extract tokens
    tokens1 = tokenize(text1)
    tokens2 = tokenize(text2)
    
    # --- ENHANCEMENT: Legal domain term matching ---
    # Dictionary of common legal trademark categories and their members
    # This could be expanded with more comprehensive lists from legal resources
    legal_trademark_categories = {
        "colors": {"red", "blue", "green", "yellow", "orange", "purple", "black", 
                 "white", "brown", "pink", "grey", "gray", "silver", "gold"},
        "animals": {"lion", "tiger", "bear", "eagle", "falcon", "hawk", "wolf", "fox", 
                  "deer", "bull", "dragon", "phoenix", "shark", "dolphin"},
        "luxury_terms": {"premium", "luxury", "elite", "exclusive", "supreme", "royal", 
                       "imperial", "prestige", "superior", "excellence", "deluxe"},
        "tech_terms": {"digital", "tech", "smart", "cyber", "web", "net", "online", 
                     "virtual", "electronic", "data", "cloud", "mobile", "app"},
        "number_prefixes": {"uni", "mono", "bi", "duo", "tri", "triple", "quad", "tetra", 
                          "penta", "hexa", "hepta", "octa", "nona", "deca"}
    }
    
    # Check if marks fall into same legal category (important in trademark law)
    legal_category_match = False
    for category, terms in legal_trademark_categories.items():
        # Check if both marks have terms from the same category
        if any(token in terms for token in tokens1) and any(token in terms for token in tokens2):
            legal_category_match = True
            info(f"Marks share terms from legal category '{category}'", 
                 mark1=text1, mark2=text2, category=category)
            break
    
    # Handle single-word marks efficiently
    if len(tokens1) == 1 and len(tokens2) == 1:
        word1, word2 = tokens1[0], tokens2[0]
        
        # Check for exact match first
        if word1 == word2:
            info("Exact word match for conceptual similarity", word=word1, similarity=1.0)
            return 1.0
            
        # Initialize similarity boosters
        legal_concept_boosts = []
        
        # --- Special category patterns ---
        
        # Color detection (simplified - a real impl would have a comprehensive list)
        colors = legal_trademark_categories["colors"]
        if word1 in colors and word2 in colors:
            legal_concept_boosts.append(0.7)  # Colors are conceptually related in TM law
            info("Color relationship detected for conceptual similarity", color1=word1, color2=word2, boost=0.7)
            
        # Number detection
        if word1.isdigit() and word2.isdigit():
            # Numbers are related but similarity depends on proximity
            num_similarity = 1.0 - min(abs(int(word1) - int(word2)) / 100, 0.9)
            legal_concept_boosts.append(num_similarity)
            info("Numeric relationship detected for conceptual similarity", 
                 num1=word1, num2=word2, boost=num_similarity)
        
        # --- Lexical relationship detection ---
        
        # Check word stems (e.g., "running" and "runner" share stem "run")
        try:
            stemmer = PorterStemmer()
            lemmatizer = WordNetLemmatizer()
            
            # Get stems and lemmas
            stem1, stem2 = stemmer.stem(word1), stemmer.stem(word2)
            lemma1 = lemmatizer.lemmatize(word1)
            lemma2 = lemmatizer.lemmatize(word2)
            
            # Compare stems and lemmas
            if stem1 == stem2:
                legal_concept_boosts.append(0.8)  # Same stem = conceptually linked
                info("Same stem detected for conceptual similarity", word1=word1, word2=word2, stem=stem1, boost=0.8)
            elif lemma1 == lemma2:
                legal_concept_boosts.append(0.75)  # Same lemma = conceptually linked
                info("Same lemma detected for conceptual similarity", word1=word1, word2=word2, lemma=lemma1, boost=0.75)
        except Exception as e:
            exception("Stem/lemma comparison failed", exc=e, word1=word1, word2=word2)
        
        # Check WordNet for synonyms/antonyms/hypernyms (semantic relationships)
        try:
            # Get all synsets for both words
            synsets1 = wordnet.synsets(word1)
            synsets2 = wordnet.synsets(word2)
            
            if synsets1 and synsets2:
                # Check if they share any synsets (synonyms)
                shared_synsets = set(synsets1).intersection(set(synsets2))
                if shared_synsets:
                    legal_concept_boosts.append(0.9)  # Direct synonyms
                    info("Shared synsets detected for conceptual similarity", 
                         word1=word1, word2=word2, synset=str(next(iter(shared_synsets))), boost=0.9)
                else:
                    # Check for antonyms (conceptual opposites - important in TM law)
                    has_antonym_relation = False
                    for syn1 in synsets1:
                        for lemma1 in syn1.lemmas():
                            for antonym in lemma1.antonyms():
                                antonym_word = antonym.name().lower()
                                if antonym_word == word2 or any(antonym_word == lemma2.name().lower() 
                                                            for syn2 in synsets2 
                                                            for lemma2 in syn2.lemmas()):
                                    has_antonym_relation = True
                                    break
                            if has_antonym_relation:
                                break
                        if has_antonym_relation:
                            break
                    
                    if has_antonym_relation:
                        legal_concept_boosts.append(0.7)  # Antonyms can be conceptually related in TM law
                        info("Antonym relationship detected for conceptual similarity", word1=word1, word2=word2, boost=0.7)
                    
                    # Check for hypernym/hyponym relationships (broader/narrower terms)
                    max_similarity = 0.0
                    for syn1 in synsets1:
                        for syn2 in synsets2:
                            # Path similarity measures taxonomic similarity
                            sim = syn1.path_similarity(syn2)
                            if sim is not None and sim > max_similarity:
                                max_similarity = sim
                    
                    if max_similarity > 0:
                        # Scale the similarity to reflect legal concepts better
                        # WordNet path_similarity is already 0-1
                        adjusted_similarity = max_similarity * 0.7
                        legal_concept_boosts.append(adjusted_similarity)
                        info("WordNet path similarity detected", word1=word1, word2=word2, 
                             path_similarity=max_similarity, boost=adjusted_similarity)
        except Exception as e:
            exception("WordNet analysis failed", exc=e, word1=word1, word2=word2)
    
    # --- 3. Combine scores ---
    
    # Start with base vector similarity or legal similarity
    final_similarity = base_similarity if base_similarity is not None else 0.5  # Default mid-point if vectors fail
    
    # Boost if marks share a legal category (important in trademark law)
    if legal_category_match:
        final_similarity = min(1.0, final_similarity + 0.15)  # Boost by 0.15 but cap at 1.0
    
    # Apply legal concept boosts if any were found (single-word analysis)
    if legal_concept_boosts:
        # Take the maximum of the vector similarity and the highest legal boost
        # This ensures conceptual relationships recognized in law are properly weighted
        legal_boost = max(legal_concept_boosts)
        final_similarity = max(final_similarity, legal_boost)
        
    # Ensure bounds
    final_similarity = max(0.0, min(1.0, final_similarity))
    
    info("Final conceptual similarity calculated", 
         mark1=text1, mark2=text2, 
         final_similarity=final_similarity)
    
    return final_similarity


# An enhanced version of the conceptual similarity function has been implemented.
# It attempts to capture legal nuances of trademark conceptual similarity through:
# 1. Base vector embedding similarity (as before)
# 2. Detection of special semantic relationships relevant in trademark law:
#    - Word stems/lemmas (morphological similarity)
#    - Synonyms, antonyms, and hypernym/hyponym relationships (using WordNet)
#    - Special categories (e.g., colors, numbers)
# This implements the suggestions from the original TODO comment.

# --- End of File ---




================================================
FILE: src/tools/__init__.py
================================================
"""Tools for the Trademark AI Agent.""" 


================================================
FILE: src/tools/prediction_tools.py
================================================
# src/tools/prediction_tools.py
"""
ADK Tools for trademark opposition prediction based on similarity scores.
"""

from typing import Optional, Dict, Tuple, List
from pydantic import BaseModel, Field

from src.models import (
    PredictionTaskInput, 
    PredictionResult, 
    SimilarityScores
)

# --- Tool Input Schemas ---

class PredictionInput(BaseModel):
    """Input schema for the trademark opposition prediction tool."""
    prediction_task: PredictionTaskInput = Field(
        ..., description="The prediction task input with trademark details and similarity scores."
    )

# --- Define Tool Functions ---

def predict_opposition_outcome_tool(input_data: PredictionInput) -> PredictionResult:
    """
    Predicts the likely outcome of a trademark opposition based on similarity scores.
    
    This tool analyzes various similarity dimensions (visual, aural, conceptual, 
    goods/services) to determine if an opposition is likely to succeed, partially 
    succeed, or fail. It provides reasoning based on UK/EU trademark law principles.
    
    Args:
        input_data: An object containing the trademarks being compared and their similarity scores.
        
    Returns:
        A PredictionResult containing the predicted outcome, confidence score, and reasoning.
    """
    # Extract prediction task data
    task = input_data.prediction_task
    scores = task.similarity_scores
    
    # Define threshold values
    HIGH_SIMILARITY = 0.70
    MEDIUM_SIMILARITY = 0.50
    LOW_SIMILARITY = 0.30
    
    # Track reasons for the prediction
    reasons: List[str] = []
    
    # Store similarity assessments
    assessments: Dict[str, str] = {}
    
    # Calculate an overall score (use weighted combination if available)
    # This uses the same logic as the overall_similarity_tool but allows for custom analysis
    overall_score = _calculate_weighted_score(scores)
    
    # Assess each similarity dimension
    if scores.visual_similarity is not None:
        if scores.visual_similarity >= HIGH_SIMILARITY:
            assessments["visual"] = "high"
            reasons.append(f"Visual similarity is high ({scores.visual_similarity:.2f}), as the marks share substantial visual elements.")
        elif scores.visual_similarity >= MEDIUM_SIMILARITY:
            assessments["visual"] = "medium"
            reasons.append(f"Visual similarity is moderate ({scores.visual_similarity:.2f}), with some shared visual elements.")
        else:
            assessments["visual"] = "low"
            reasons.append(f"Visual similarity is low ({scores.visual_similarity:.2f}), with few shared visual elements.")
    
    if scores.aural_similarity is not None:
        if scores.aural_similarity >= HIGH_SIMILARITY:
            assessments["aural"] = "high"
            reasons.append(f"Aural similarity is high ({scores.aural_similarity:.2f}), as the marks sound similar when spoken.")
        elif scores.aural_similarity >= MEDIUM_SIMILARITY:
            assessments["aural"] = "medium"
            reasons.append(f"Aural similarity is moderate ({scores.aural_similarity:.2f}), with some phonetic similarities.")
        else:
            assessments["aural"] = "low"
            reasons.append(f"Aural similarity is low ({scores.aural_similarity:.2f}), with different pronunciations.")
    
    if scores.conceptual_similarity is not None:
        if scores.conceptual_similarity >= HIGH_SIMILARITY:
            assessments["conceptual"] = "high"
            # Enhanced reasoning for conceptual similarity with legal domain knowledge
            reasons.append(f"Conceptual similarity is high ({scores.conceptual_similarity:.2f}), as the marks convey similar meanings or fall within the same conceptual category recognized in trademark law.")
            
            # Additional explanation for very high conceptual similarity
            if scores.conceptual_similarity >= 0.85:
                # Extract wordmarks for detailed reasoning
                app_mark = task.applicant_trademark.wordmark.mark_text
                opp_mark = task.opponent_trademark.wordmark.mark_text
                reasons.append(f"The marks '{app_mark}' and '{opp_mark}' share strong conceptual associations that would be recognized by the average consumer, increasing the likelihood of confusion.")
        elif scores.conceptual_similarity >= MEDIUM_SIMILARITY:
            assessments["conceptual"] = "medium"
            reasons.append(f"Conceptual similarity is moderate ({scores.conceptual_similarity:.2f}), with related but distinct meanings that may be associated by consumers.")
        else:
            assessments["conceptual"] = "low"
            reasons.append(f"Conceptual similarity is low ({scores.conceptual_similarity:.2f}), with different meanings or concepts.")
    
    if scores.goods_services_similarity is not None:
        if scores.goods_services_similarity >= HIGH_SIMILARITY:
            assessments["goods_services"] = "high"
            reasons.append(f"Goods/services similarity is high ({scores.goods_services_similarity:.2f}), indicating overlapping commercial scope.")
        elif scores.goods_services_similarity >= MEDIUM_SIMILARITY:
            assessments["goods_services"] = "medium"
            reasons.append(f"Goods/services similarity is moderate ({scores.goods_services_similarity:.2f}), with related commercial areas.")
        else:
            assessments["goods_services"] = "low"
            reasons.append(f"Goods/services similarity is low ({scores.goods_services_similarity:.2f}), with distinct commercial areas.")
    
    # Make prediction based on EU/UK trademark law principles:
    # 1. At least one similarity type must be high
    # 2. Goods/services must be at least moderately similar
    # 3. Apply the interdependence principle (lower similarity in one aspect can be offset by higher similarity in another)
    
    # Default prediction and confidence
    outcome = "Opposition Unlikely to Succeed"
    confidence = 0.5
    
    # Check for high similarity in any dimension
    high_similarities = [k for k, v in assessments.items() if v == "high"]
    medium_similarities = [k for k, v in assessments.items() if v == "medium"]
    
    # Basic opposition prediction logic
    gs_assessment = assessments.get("goods_services", "low")
    
    if gs_assessment == "high" and len(high_similarities) >= 1:
        # High similarity in goods/services and at least one mark similarity dimension
        outcome = "Opposition Likely to Succeed"
        confidence = min(0.9, 0.7 + (len(high_similarities) * 0.05))
        
        # Enhanced reasoning with legal principles
        legal_principle = "Following the interdependence principle in EU trademark law, the high similarity in goods/services combined with high similarity in mark characteristics creates a likelihood of confusion."
        
        # Add conceptual similarity specific reasoning if applicable
        if "conceptual" in high_similarities:
            legal_principle += " The conceptual similarity is particularly significant as established in cases like Lloyd Schuhfabrik Meyer (C-342/97), where the Court held that conceptual similarity can create a likelihood of confusion even with moderate visual or aural differences."
        
        reasons.append(legal_principle)
    
    elif gs_assessment in ["high", "medium"] and (len(high_similarities) >= 1 or len(medium_similarities) >= 2):
        # Moderate-to-high similarity in goods/services with substantial mark similarities
        outcome = "Opposition May Partially Succeed"
        confidence = 0.65 + (len(high_similarities) * 0.05)
        
        # Enhanced reasoning with legal principles
        legal_principle = "There is a moderate likelihood of confusion based on the similarities in specific aspects, applying the interdependence principle of EU trademark law."
        
        # Add conceptual similarity specific reasoning if applicable
        if "conceptual" in high_similarities or "conceptual" in medium_similarities:
            legal_principle += " As established in Canon Kabushiki Kaisha v Metro-Goldwyn-Mayer (C-39/97), the conceptual meaning can be an important element in the global assessment of likelihood of confusion."
        
        reasons.append(legal_principle)
    
    else:
        # Either low goods/services similarity or insufficient mark similarities
        confidence = 0.55 + (0.1 if gs_assessment == "low" else 0)
        
        # Enhanced reasoning with legal principles
        legal_principle = "The differences between the marks and/or the commercial areas are substantial enough that consumers are unlikely to be confused, applying EU trademark law principles."
        
        # Add conceptual dissimilarity specific reasoning if applicable
        if assessments.get("conceptual") == "low":
            legal_principle += " Following Sabel BV v Puma AG (C-251/95), where conceptual differences are clear, they can counteract visual and aural similarities, reducing the likelihood of confusion."
        
        reasons.append(legal_principle)
    
    # Add overall analysis
    if overall_score is not None:
        reasons.append(f"The calculated overall similarity score is {overall_score:.2f}, which supports this prediction.")
    
    # Combine reasons into a coherent reasoning paragraph
    reasoning = " ".join(reasons)
    
    # Return the prediction result
    return PredictionResult(
        predicted_outcome=outcome,
        confidence_score=confidence,
        reasoning=reasoning
    )

def _calculate_weighted_score(scores: SimilarityScores) -> Optional[float]:
    """
    Helper function to calculate a weighted overall similarity score.
    This is similar to the calculate_overall_similarity_tool but internal to this module.
    """
    # Define default weights
    weights: Dict[str, float] = {
        "visual_similarity": 0.30,
        "aural_similarity": 0.30,
        "conceptual_similarity": 0.10,
        "goods_services_similarity": 0.30,
    }
    
    # Collect available scores
    available_scores: List[Tuple[str, float]] = []
    if scores.visual_similarity is not None:
        available_scores.append(("visual_similarity", scores.visual_similarity))
    if scores.aural_similarity is not None:
        available_scores.append(("aural_similarity", scores.aural_similarity))
    if scores.conceptual_similarity is not None:
        available_scores.append(("conceptual_similarity", scores.conceptual_similarity))
    if scores.goods_services_similarity is not None:
        available_scores.append(("goods_services_similarity", scores.goods_services_similarity))
    
    if not available_scores:
        return None
    
    # Calculate weighted sum
    total_weight = 0.0
    weighted_sum = 0.0
    
    for score_name, score_value in available_scores:
        # Clamp individual scores
        score_value = max(0.0, min(1.0, score_value))
        weight = weights.get(score_name, 0.0)
        if weight > 0:
            weighted_sum += score_value * weight
            total_weight += weight
    
    if total_weight <= 0:
        # Simple average if no weights
        return sum(score for _, score in available_scores) / len(available_scores)
    
    # Normalize and return
    return weighted_sum / total_weight

# --- Create a List of Tool Functions ---
# ADK will wrap these functions into FunctionTools

prediction_tools = [
    predict_opposition_outcome_tool
] 


================================================
FILE: src/tools/similarity_tools.py
================================================
# src/tools/similarity_tools.py
"""
ADK Tools for calculating various trademark similarity scores.
"""

from typing import List, Optional, Dict, Tuple

# Remove Toolset import, import FunctionTool instead
# from google.adk.tools.toolset import Toolset 
from pydantic import BaseModel, Field

from src.models import Wordmark, GoodsService, SimilarityScores # Added SimilarityScores import
from src.similarity import (
    calculate_visual_similarity,
    calculate_goods_services_similarity,
    calculate_aural_similarity,
    calculate_conceptual_similarity,
)

# --- Tool Input Schemas (using Pydantic) ---

class VisualSimilarityInput(BaseModel):
    """Input schema for the visual wordmark similarity tool."""
    applicant_wordmark: Wordmark = Field(..., description="Applicant's wordmark details.")
    opponent_wordmark: Wordmark = Field(..., description="Opponent's wordmark details.")

class WordmarkSimilarityInput(VisualSimilarityInput):
    """Input schema for wordmark similarity tools (visual, aural, conceptual)."""
    pass # Inherits fields from VisualSimilarityInput

class GoodsServicesSimilarityInput(BaseModel):
    """Input schema for the goods and services similarity tool."""
    applicant_goods_services: List[GoodsService] = Field(
        ..., description="List of applicant's goods/services."
    )
    opponent_goods_services: List[GoodsService] = Field(
        ..., description="List of opponent's goods/services (currently unused by underlying function but kept for potential future use)."
    )
    # Optional: Add threshold if you want the agent to control it
    # similarity_threshold: float = Field(default=0.8, description="Cosine similarity threshold.")

class OverallSimilarityInput(BaseModel):
    """Input schema for the overall similarity calculation tool."""
    scores: SimilarityScores = Field(..., description="The individual similarity scores calculated previously.")
    # Optional: Weights could be passed in the input or configured elsewhere
    # weights: Optional[Dict[str, float]] = Field(default=None, description="Optional weights for each score type.")

# --- Define Tool Functions (keep existing functions) ---

# Note: The @tool decorator is removed. We'll wrap these functions manually.

def calculate_visual_wordmark_similarity_tool(input_data: WordmarkSimilarityInput) -> float:
    """
    Calculates the normalized visual similarity between two wordmarks using Levenshtein ratio.
    Args:
        input_data: An object containing the applicant and opponent Wordmark objects.
    Returns:
        A float between 0.0 (dissimilar) and 1.0 (identical) representing visual similarity.
    """
    return calculate_visual_similarity(
        mark1=input_data.applicant_wordmark,
        mark2=input_data.opponent_wordmark
    )

async def calculate_goods_services_similarity_tool(input_data: GoodsServicesSimilarityInput) -> Optional[float]:
    """
    Calculates the aggregate semantic similarity between two lists of goods and services asynchronously.
    This tool generates embeddings for the applicant's terms and performs a vector
    search against indexed opponent/existing terms in the database to find the best matches.
    It returns an aggregated similarity score (0.0 to 1.0).
    Args:
        input_data: An object containing lists of applicant and opponent GoodsService objects.
    Returns:
        An aggregate similarity score (float between 0.0 and 1.0), or None if calculation fails.
    """
    return await calculate_goods_services_similarity(
        applicant_gs=input_data.applicant_goods_services,
        opponent_gs=input_data.opponent_goods_services,
    )

def calculate_aural_wordmark_similarity_tool(input_data: WordmarkSimilarityInput) -> float:
    """
    Calculates the normalized aural (sound) similarity between two wordmarks.
    Uses the Double Metaphone phonetic encoding and Levenshtein ratio on the codes.
    Args:
        input_data: An object containing the applicant and opponent Wordmark objects.
    Returns:
        A float between 0.0 (dissimilar) and 1.0 (identical) representing aural similarity.
    """
    return calculate_aural_similarity(
        mark1=input_data.applicant_wordmark,
        mark2=input_data.opponent_wordmark
    )

def calculate_conceptual_wordmark_similarity_tool(input_data: WordmarkSimilarityInput) -> Optional[float]:
    """
    Calculates the conceptual similarity between two wordmarks using embeddings.
    Generates embeddings for the wordmarks and returns their cosine similarity (scaled 0-1).
    Args:
        input_data: An object containing the applicant and opponent Wordmark objects.
    Returns:
        A float between 0.0 (dissimilar) and 1.0 (identical) representing conceptual similarity,
        or None if embedding generation fails.
    """
    return calculate_conceptual_similarity(
        mark1=input_data.applicant_wordmark,
        mark2=input_data.opponent_wordmark
    )

# Define default weights for overall similarity calculation
DEFAULT_WEIGHTS: Dict[str, float] = {
    "visual_similarity": 0.30,
    "aural_similarity": 0.30,
    "conceptual_similarity": 0.10,
    "goods_services_similarity": 0.30,
}

def calculate_overall_similarity_tool(input_data: OverallSimilarityInput) -> Optional[float]:
    """
    Calculates a weighted overall similarity score from individual scores.
    
    This tool applies weights to each individual similarity score (visual, aural, 
    conceptual, goods/services) and computes a weighted average. It handles missing
    scores by excluding them from the calculation and normalizing the remaining weights.
    
    Args:
        input_data: An object containing the SimilarityScores.
        
    Returns:
        A single float representing the weighted overall similarity score (0.0 to 1.0),
        or None if no valid scores are available.
    """
    scores = input_data.scores
    weights = DEFAULT_WEIGHTS  # Use default weights for MVP
    
    available_scores: List[Tuple[str, float]] = []
    if scores.visual_similarity is not None:
        available_scores.append(("visual_similarity", scores.visual_similarity))
    if scores.aural_similarity is not None:
        available_scores.append(("aural_similarity", scores.aural_similarity))
    if scores.conceptual_similarity is not None:
        available_scores.append(("conceptual_similarity", scores.conceptual_similarity))
    if scores.goods_services_similarity is not None:
        available_scores.append(("goods_services_similarity", scores.goods_services_similarity))
        
    if not available_scores:
        return None  # Cannot calculate if no scores are present
        
    total_weight: float = 0.0
    weighted_sum: float = 0.0
    
    for score_name, score_value in available_scores:
        # Clamp individual scores before weighting
        score_value = max(0.0, min(1.0, score_value))
        weight = weights.get(score_name, 0.0)
        if weight > 0:  # Only consider scores with positive weights
            weighted_sum += score_value * weight
            total_weight += weight
            
    if total_weight <= 0:  # Use <= 0 to handle potential floating point issues
        # Fallback: simple average of available (clamped) scores if total_weight is zero or negative
        if available_scores:
            clamped_scores = [max(0.0, min(1.0, s)) for _, s in available_scores]
            return sum(clamped_scores) / len(clamped_scores) if clamped_scores else None
        else:
            return None
            
    # Normalize by the sum of weights used
    overall_score = weighted_sum / total_weight
    
    # Ensure final score is within bounds
    return max(0.0, min(1.0, overall_score))

# --- Create a List of Tool Functions --- 
# ADK will wrap these functions into FunctionTools automatically

trademark_similarity_tools = [
    calculate_visual_wordmark_similarity_tool,
    calculate_goods_services_similarity_tool,
    calculate_aural_wordmark_similarity_tool,
    calculate_conceptual_wordmark_similarity_tool,
    calculate_overall_similarity_tool  # Added the new overall similarity tool
]


================================================
FILE: supabase/config.toml
================================================
# For detailed configuration reference documentation, visit:
# https://supabase.com/docs/guides/local-development/cli/config
# A string used to distinguish different Supabase projects on the same host. Defaults to the
# working directory name when running `supabase init`.
project_id = "tm-sft"

[api]
enabled = true
# Port to use for the API URL.
port = 54321
# Schemas to expose in your API. Tables, views and stored procedures in this schema will get API
# endpoints. `public` and `graphql_public` schemas are included by default.
schemas = ["public", "graphql_public"]
# Extra schemas to add to the search_path of every request.
extra_search_path = ["public", "extensions"]
# The maximum number of rows returns from a view, table, or stored procedure. Limits payload size
# for accidental or malicious requests.
max_rows = 1000

[api.tls]
# Enable HTTPS endpoints locally using a self-signed certificate.
enabled = false

[db]
# Port to use for the local database URL.
port = 54322
# Port used by db diff command to initialize the shadow database.
shadow_port = 54320
# The database major version to use. This has to be the same as your remote database's. Run `SHOW
# server_version;` on the remote database to check.
major_version = 15

[db.pooler]
enabled = false
# Port to use for the local connection pooler.
port = 54329
# Specifies when a server connection can be reused by other clients.
# Configure one of the supported pooler modes: `transaction`, `session`.
pool_mode = "transaction"
# How many server connections to allow per user/database pair.
default_pool_size = 20
# Maximum number of client connections allowed.
max_client_conn = 100

# [db.vault]
# secret_key = "env(SECRET_VALUE)"

[db.migrations]
# Specifies an ordered list of schema files that describe your database.
# Supports glob patterns relative to supabase directory: "./schemas/*.sql"
schema_paths = []

[db.seed]
# If enabled, seeds the database after migrations during a db reset.
enabled = true
# Specifies an ordered list of seed files to load during db reset.
# Supports glob patterns relative to supabase directory: "./seeds/*.sql"
sql_paths = ["./seed.sql"]

[realtime]
enabled = true
# Bind realtime via either IPv4 or IPv6. (default: IPv4)
# ip_version = "IPv6"
# The maximum length in bytes of HTTP request headers. (default: 4096)
# max_header_length = 4096

[studio]
enabled = true
# Port to use for Supabase Studio.
port = 54323
# External URL of the API server that frontend connects to.
api_url = "http://127.0.0.1"
# OpenAI API Key to use for Supabase AI in the Supabase Studio.
openai_api_key = "env(OPENAI_API_KEY)"

# Email testing server. Emails sent with the local dev setup are not actually sent - rather, they
# are monitored, and you can view the emails that would have been sent from the web interface.
[inbucket]
enabled = true
# Port to use for the email testing server web interface.
port = 54324
# Uncomment to expose additional ports for testing user applications that send emails.
# smtp_port = 54325
# pop3_port = 54326
# admin_email = "admin@email.com"
# sender_name = "Admin"

[storage]
enabled = true
# The maximum file size allowed (e.g. "5MB", "500KB").
file_size_limit = "50MiB"

# Image transformation API is available to Supabase Pro plan.
# [storage.image_transformation]
# enabled = true

# Uncomment to configure local storage buckets
# [storage.buckets.images]
# public = false
# file_size_limit = "50MiB"
# allowed_mime_types = ["image/png", "image/jpeg"]
# objects_path = "./images"

[auth]
enabled = true
# The base URL of your website. Used as an allow-list for redirects and for constructing URLs used
# in emails.
site_url = "http://127.0.0.1:3000"
# A list of *exact* URLs that auth providers are permitted to redirect to post authentication.
additional_redirect_urls = ["https://127.0.0.1:3000"]
# How long tokens are valid for, in seconds. Defaults to 3600 (1 hour), maximum 604,800 (1 week).
jwt_expiry = 3600
# If disabled, the refresh token will never expire.
enable_refresh_token_rotation = true
# Allows refresh tokens to be reused after expiry, up to the specified interval in seconds.
# Requires enable_refresh_token_rotation = true.
refresh_token_reuse_interval = 10
# Allow/disallow new user signups to your project.
enable_signup = true
# Allow/disallow anonymous sign-ins to your project.
enable_anonymous_sign_ins = false
# Allow/disallow testing manual linking of accounts
enable_manual_linking = false
# Passwords shorter than this value will be rejected as weak. Minimum 6, recommended 8 or more.
minimum_password_length = 6
# Passwords that do not meet the following requirements will be rejected as weak. Supported values
# are: `letters_digits`, `lower_upper_letters_digits`, `lower_upper_letters_digits_symbols`
password_requirements = ""

# Configure one of the supported captcha providers: `hcaptcha`, `turnstile`.
# [auth.captcha]
# enabled = true
# provider = "hcaptcha"
# secret = ""

[auth.email]
# Allow/disallow new user signups via email to your project.
enable_signup = true
# If enabled, a user will be required to confirm any email change on both the old, and new email
# addresses. If disabled, only the new email is required to confirm.
double_confirm_changes = true
# If enabled, users need to confirm their email address before signing in.
enable_confirmations = false
# If enabled, users will need to reauthenticate or have logged in recently to change their password.
secure_password_change = false
# Controls the minimum amount of time that must pass before sending another signup confirmation or password reset email.
max_frequency = "1s"
# Number of characters used in the email OTP.
otp_length = 6
# Number of seconds before the email OTP expires (defaults to 1 hour).
otp_expiry = 3600

# Use a production-ready SMTP server
# [auth.email.smtp]
# enabled = true
# host = "smtp.sendgrid.net"
# port = 587
# user = "apikey"
# pass = "env(SENDGRID_API_KEY)"
# admin_email = "admin@email.com"
# sender_name = "Admin"

# Uncomment to customize email template
# [auth.email.template.invite]
# subject = "You have been invited"
# content_path = "./supabase/templates/invite.html"

[auth.sms]
# Allow/disallow new user signups via SMS to your project.
enable_signup = false
# If enabled, users need to confirm their phone number before signing in.
enable_confirmations = false
# Template for sending OTP to users
template = "Your code is {{ .Code }}"
# Controls the minimum amount of time that must pass before sending another sms otp.
max_frequency = "5s"

# Use pre-defined map of phone number to OTP for testing.
# [auth.sms.test_otp]
# 4152127777 = "123456"

# Configure logged in session timeouts.
# [auth.sessions]
# Force log out after the specified duration.
# timebox = "24h"
# Force log out if the user has been inactive longer than the specified duration.
# inactivity_timeout = "8h"

# This hook runs before a token is issued and allows you to add additional claims based on the authentication method used.
# [auth.hook.custom_access_token]
# enabled = true
# uri = "pg-functions://<database>/<schema>/<hook_name>"

# Configure one of the supported SMS providers: `twilio`, `twilio_verify`, `messagebird`, `textlocal`, `vonage`.
[auth.sms.twilio]
enabled = false
account_sid = ""
message_service_sid = ""
# DO NOT commit your Twilio auth token to git. Use environment variable substitution instead:
auth_token = "env(SUPABASE_AUTH_SMS_TWILIO_AUTH_TOKEN)"

# Multi-factor-authentication is available to Supabase Pro plan.
[auth.mfa]
# Control how many MFA factors can be enrolled at once per user.
max_enrolled_factors = 10

# Control MFA via App Authenticator (TOTP)
[auth.mfa.totp]
enroll_enabled = false
verify_enabled = false

# Configure MFA via Phone Messaging
[auth.mfa.phone]
enroll_enabled = false
verify_enabled = false
otp_length = 6
template = "Your code is {{ .Code }}"
max_frequency = "5s"

# Configure MFA via WebAuthn
# [auth.mfa.web_authn]
# enroll_enabled = true
# verify_enabled = true

# Use an external OAuth provider. The full list of providers are: `apple`, `azure`, `bitbucket`,
# `discord`, `facebook`, `github`, `gitlab`, `google`, `keycloak`, `linkedin_oidc`, `notion`, `twitch`,
# `twitter`, `slack`, `spotify`, `workos`, `zoom`.
[auth.external.apple]
enabled = false
client_id = ""
# DO NOT commit your OAuth provider secret to git. Use environment variable substitution instead:
secret = "env(SUPABASE_AUTH_EXTERNAL_APPLE_SECRET)"
# Overrides the default auth redirectUrl.
redirect_uri = ""
# Overrides the default auth provider URL. Used to support self-hosted gitlab, single-tenant Azure,
# or any other third-party OIDC providers.
url = ""
# If enabled, the nonce check will be skipped. Required for local sign in with Google auth.
skip_nonce_check = false

# Use Firebase Auth as a third-party provider alongside Supabase Auth.
[auth.third_party.firebase]
enabled = false
# project_id = "my-firebase-project"

# Use Auth0 as a third-party provider alongside Supabase Auth.
[auth.third_party.auth0]
enabled = false
# tenant = "my-auth0-tenant"
# tenant_region = "us"

# Use AWS Cognito (Amplify) as a third-party provider alongside Supabase Auth.
[auth.third_party.aws_cognito]
enabled = false
# user_pool_id = "my-user-pool-id"
# user_pool_region = "us-east-1"

[edge_runtime]
enabled = true
# Configure one of the supported request policies: `oneshot`, `per_worker`.
# Use `oneshot` for hot reload, or `per_worker` for load testing.
policy = "oneshot"
# Port to attach the Chrome inspector for debugging edge functions.
inspector_port = 8083

# Use these configurations to customize your Edge Function.
# [functions.MY_FUNCTION_NAME]
# enabled = true
# verify_jwt = true
# import_map = "./functions/MY_FUNCTION_NAME/deno.json"
# Uncomment to specify a custom file path to the entrypoint.
# Supported file extensions are: .ts, .js, .mjs, .jsx, .tsx
# entrypoint = "./functions/MY_FUNCTION_NAME/index.ts"
# Specifies static files to be bundled with the function. Supports glob patterns.
# For example, if you want to serve static HTML pages in your function:
# static_files = [ "./functions/MY_FUNCTION_NAME/*.html" ]

[analytics]
enabled = true
port = 54327
# Configure one of the supported backends: `postgres`, `bigquery`.
backend = "postgres"

# Experimental features may be deprecated any time
[experimental]
# Configures Postgres storage engine to use OrioleDB (S3)
orioledb_version = ""
# Configures S3 bucket URL, eg. <bucket_name>.s3-<region>.amazonaws.com
s3_host = "env(S3_HOST)"
# Configures S3 bucket region, eg. us-east-1
s3_region = "env(S3_REGION)"
# Configures AWS_ACCESS_KEY_ID for S3 bucket
s3_access_key = "env(S3_ACCESS_KEY)"
# Configures AWS_SECRET_ACCESS_KEY for S3 bucket
s3_secret_key = "env(S3_SECRET_KEY)"



================================================
FILE: supabase/migrations/20250404021823_remote_schema.sql
================================================
SET statement_timeout = 0;
SET lock_timeout = 0;
SET idle_in_transaction_session_timeout = 0;
SET client_encoding = 'UTF8';
SET standard_conforming_strings = on;
SELECT pg_catalog.set_config('search_path', '', false);
SET check_function_bodies = false;
SET xmloption = content;
SET client_min_messages = warning;
SET row_security = off;
CREATE EXTENSION IF NOT EXISTS "pgsodium";
COMMENT ON SCHEMA "public" IS 'standard public schema';
CREATE EXTENSION IF NOT EXISTS "pg_graphql" WITH SCHEMA "graphql";
CREATE EXTENSION IF NOT EXISTS "pg_stat_statements" WITH SCHEMA "extensions";
CREATE EXTENSION IF NOT EXISTS "pg_trgm" WITH SCHEMA "public";
CREATE EXTENSION IF NOT EXISTS "pgcrypto" WITH SCHEMA "extensions";
CREATE EXTENSION IF NOT EXISTS "pgjwt" WITH SCHEMA "extensions";
CREATE EXTENSION IF NOT EXISTS "supabase_vault" WITH SCHEMA "vault";
CREATE EXTENSION IF NOT EXISTS "uuid-ossp" WITH SCHEMA "extensions";
CREATE EXTENSION IF NOT EXISTS "vector" WITH SCHEMA "public";
CREATE TYPE "public"."attention_level" AS ENUM (
    'high',
    'medium',
    'low'
);
ALTER TYPE "public"."attention_level" OWNER TO "postgres";
CREATE TYPE "public"."conceptual_similarity_level" AS ENUM (
    'identical',
    'high degree',
    'medium degree',
    'low degree',
    'dissimilar',
    'neutral'
);
ALTER TYPE "public"."conceptual_similarity_level" OWNER TO "postgres";
CREATE TYPE "public"."confusion_type" AS ENUM (
    'direct',
    'indirect',
    'both'
);
ALTER TYPE "public"."confusion_type" OWNER TO "postgres";
CREATE TYPE "public"."distinctive_character_level" AS ENUM (
    'high',
    'medium',
    'low',
    'enhanced'
);
ALTER TYPE "public"."distinctive_character_level" OWNER TO "postgres";
CREATE TYPE "public"."jurisdiction_type" AS ENUM (
    'UKIPO',
    'EUIPO'
);
ALTER TYPE "public"."jurisdiction_type" OWNER TO "postgres";
CREATE TYPE "public"."opposition_outcome" AS ENUM (
    'successful',
    'partially successful',
    'unsuccessful'
);
ALTER TYPE "public"."opposition_outcome" OWNER TO "postgres";
CREATE TYPE "public"."proof_of_use_status" AS ENUM (
    'use_proven',
    'use_not_proven',
    'not_applicable'
);
ALTER TYPE "public"."proof_of_use_status" OWNER TO "postgres";
CREATE TYPE "public"."similarity_level" AS ENUM (
    'identical',
    'high degree',
    'medium degree',
    'low degree',
    'dissimilar'
);
ALTER TYPE "public"."similarity_level" OWNER TO "postgres";
CREATE OR REPLACE FUNCTION "public"."begin_transaction"() RETURNS "void"
    LANGUAGE "plpgsql"
    AS $$
BEGIN
  -- Start a transaction
  -- This is just a placeholder since Supabase/PostgreSQL starts transactions with BEGIN statement
  -- which is handled by the connection itself
END;
$$;
ALTER FUNCTION "public"."begin_transaction"() OWNER TO "postgres";
CREATE OR REPLACE FUNCTION "public"."commit_transaction"() RETURNS "void"
    LANGUAGE "plpgsql"
    AS $$
BEGIN
  -- Commit a transaction
  -- This is just a placeholder since Supabase/PostgreSQL commits with COMMIT statement
  -- which is handled by the connection itself
END;
$$;
ALTER FUNCTION "public"."commit_transaction"() OWNER TO "postgres";
CREATE OR REPLACE FUNCTION "public"."find_similar_cases"("mark_text" "text", "limit_count" integer DEFAULT 5) RETURNS TABLE("case_reference" "text", "similarity_score" double precision)
    LANGUAGE "plpgsql"
    AS $$
BEGIN
  RETURN QUERY
  SELECT 
    tc.case_reference,
    MAX(similarity(lower(mark_text), lower(am.mark))) as score
  FROM 
    trademark_cases tc
    JOIN applicant_marks am ON tc.case_reference = am.case_reference
  GROUP BY 
    tc.case_reference
  ORDER BY 
    score DESC
  LIMIT limit_count;
END;
$$;
ALTER FUNCTION "public"."find_similar_cases"("mark_text" "text", "limit_count" integer) OWNER TO "postgres";
CREATE OR REPLACE FUNCTION "public"."find_similar_goods_services"("search_term" "text", "class_num" integer, "limit_count" integer DEFAULT 10) RETURNS TABLE("id" integer, "term" "text", "nice_class" integer, "similarity_score" double precision)
    LANGUAGE "plpgsql"
    AS $$
BEGIN
  RETURN QUERY
  SELECT 
    gs.id, 
    gs.term, 
    gs.nice_class, 
    similarity(lower(search_term), lower(gs.term)) as sim_score
  FROM 
    goods_services gs
  WHERE 
    gs.nice_class = class_num
  ORDER BY 
    sim_score DESC
  LIMIT limit_count;
END;
$$;
ALTER FUNCTION "public"."find_similar_goods_services"("search_term" "text", "class_num" integer, "limit_count" integer) OWNER TO "postgres";
CREATE OR REPLACE FUNCTION "public"."find_similar_term"("input_term" "text", "input_nice_class" integer, "threshold" double precision) RETURNS TABLE("id" integer)
    LANGUAGE "plpgsql"
    AS $$
BEGIN
  RETURN QUERY
  SELECT gs.id 
  FROM goods_services gs
  WHERE gs.nice_class = input_nice_class
    AND similarity(lower(gs.term), lower(input_term)) > threshold
  ORDER BY similarity(lower(gs.term), lower(input_term)) DESC
  LIMIT 1;
END;
$$;
ALTER FUNCTION "public"."find_similar_term"("input_term" "text", "input_nice_class" integer, "threshold" double precision) OWNER TO "postgres";
CREATE OR REPLACE FUNCTION "public"."get_goods_services_comparisons"("limit_count" integer DEFAULT 10000) RETURNS TABLE("similarity" "text", "term1" "text", "class1" integer, "term2" "text", "class2" integer, "id1" integer, "id2" integer)
    LANGUAGE "plpgsql"
    AS $$
BEGIN
  RETURN QUERY
  SELECT 
    gsc.similarity,
    gs1.term as term1,
    gs1.nice_class as class1,
    gs2.term as term2,
    gs2.nice_class as class2,
    gs1.id as id1,
    gs2.id as id2
  FROM 
    goods_services_comparisons gsc
  JOIN 
    goods_services gs1 ON gsc.goods_services_1_id = gs1.id
  JOIN 
    goods_services gs2 ON gsc.goods_services_2_id = gs2.id
  LIMIT limit_count;
END;
$$;
ALTER FUNCTION "public"."get_goods_services_comparisons"("limit_count" integer) OWNER TO "postgres";
CREATE OR REPLACE FUNCTION "public"."predict_similarity"("term1" "text", "nice_class1" integer, "term2" "text", "nice_class2" integer) RETURNS "text"
    LANGUAGE "plpgsql"
    AS $$
DECLARE
    text_similarity double precision;
    similarity_category text;
    similar_comparison RECORD;
BEGIN
    -- First look for exact matches
    SELECT gsc.similarity::text INTO similarity_category
    FROM goods_services gs1
    JOIN goods_services_comparisons gsc ON gs1.id = gsc.goods_services_1_id
    JOIN goods_services gs2 ON gs2.id = gsc.goods_services_2_id
    WHERE 
        gs1.nice_class = nice_class1 AND 
        gs2.nice_class = nice_class2 AND
        (
            (LOWER(gs1.term) = LOWER(term1) AND LOWER(gs2.term) = LOWER(term2)) OR
            (LOWER(gs1.term) = LOWER(term2) AND LOWER(gs2.term) = LOWER(term1))
        )
    LIMIT 1;

    -- If exact match found, return it
    IF similarity_category IS NOT NULL THEN
        RETURN similarity_category;
    END IF;

    -- Look for semantically similar comparisons
    -- We'll use a combination of text similarity to find relevant comparisons
    SELECT gsc.similarity::text INTO similarity_category
    FROM goods_services gs1
    JOIN goods_services_comparisons gsc ON gs1.id = gsc.goods_services_1_id
    JOIN goods_services gs2 ON gs2.id = gsc.goods_services_2_id
    WHERE 
        gs1.nice_class = nice_class1 AND 
        gs2.nice_class = nice_class2 AND
        (
            -- Look for similar terms using pg_trgm similarity function
            (
                similarity(LOWER(gs1.term), LOWER(term1)) > 0.4 AND 
                similarity(LOWER(gs2.term), LOWER(term2)) > 0.4
            )
            OR
            (
                similarity(LOWER(gs1.term), LOWER(term2)) > 0.4 AND 
                similarity(LOWER(gs2.term), LOWER(term1)) > 0.4
            )
        )
    ORDER BY 
        GREATEST(
            similarity(LOWER(gs1.term), LOWER(term1)) + similarity(LOWER(gs2.term), LOWER(term2)),
            similarity(LOWER(gs1.term), LOWER(term2)) + similarity(LOWER(gs2.term), LOWER(term1))
        ) DESC
    LIMIT 1;

    -- If we found a similar comparison, return it
    IF similarity_category IS NOT NULL THEN
        RETURN similarity_category;
    END IF;
    
    -- If no similar comparisons found, fall back to direct text similarity
    SELECT similarity(LOWER(term1), LOWER(term2)) INTO text_similarity;
    
    -- Map the numerical score to a category
    IF text_similarity >= 0.9 THEN
        similarity_category := 'identical';
    ELSIF text_similarity >= 0.7 THEN
        similarity_category := 'high degree';
    ELSIF text_similarity >= 0.5 THEN
        similarity_category := 'medium degree';
    ELSIF text_similarity >= 0.3 THEN
        similarity_category := 'low degree';
    ELSE
        similarity_category := 'dissimilar';
    END IF;
    
    RETURN similarity_category;
END;
$$;
ALTER FUNCTION "public"."predict_similarity"("term1" "text", "nice_class1" integer, "term2" "text", "nice_class2" integer) OWNER TO "postgres";
CREATE OR REPLACE FUNCTION "public"."rollback_transaction"() RETURNS "void"
    LANGUAGE "plpgsql"
    AS $$
BEGIN
  -- Rollback a transaction
  -- This is just a placeholder since Supabase/PostgreSQL rolls back with ROLLBACK statement
  -- which is handled by the connection itself
END;
$$;
ALTER FUNCTION "public"."rollback_transaction"() OWNER TO "postgres";
CREATE OR REPLACE FUNCTION "public"."update_timestamp"() RETURNS "trigger"
    LANGUAGE "plpgsql"
    AS $$
BEGIN
  NEW.updated_at = now();
  RETURN NEW;
END;
$$;
ALTER FUNCTION "public"."update_timestamp"() OWNER TO "postgres";
SET default_tablespace = '';
SET default_table_access_method = "heap";
CREATE TABLE IF NOT EXISTS "public"."applicant_goods_services" (
    "id" integer NOT NULL,
    "mark_id" integer,
    "goods_services_id" integer,
    "created_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP,
    "updated_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP
);
ALTER TABLE "public"."applicant_goods_services" OWNER TO "postgres";
CREATE SEQUENCE IF NOT EXISTS "public"."applicant_goods_services_id_seq"
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER TABLE "public"."applicant_goods_services_id_seq" OWNER TO "postgres";
ALTER SEQUENCE "public"."applicant_goods_services_id_seq" OWNED BY "public"."applicant_goods_services"."id";
CREATE TABLE IF NOT EXISTS "public"."applicant_marks" (
    "id" integer NOT NULL,
    "case_reference" "text",
    "mark" "text" NOT NULL,
    "mark_is_figurative" boolean DEFAULT false NOT NULL,
    "created_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP,
    "updated_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP
);
ALTER TABLE "public"."applicant_marks" OWNER TO "postgres";
CREATE SEQUENCE IF NOT EXISTS "public"."applicant_marks_id_seq"
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER TABLE "public"."applicant_marks_id_seq" OWNER TO "postgres";
ALTER SEQUENCE "public"."applicant_marks_id_seq" OWNED BY "public"."applicant_marks"."id";
CREATE TABLE IF NOT EXISTS "public"."decision_rationales" (
    "id" integer NOT NULL,
    "case_reference" "text",
    "key_factors" "text"[] NOT NULL,
    "created_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP,
    "updated_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP
);
ALTER TABLE "public"."decision_rationales" OWNER TO "postgres";
CREATE SEQUENCE IF NOT EXISTS "public"."decision_rationales_id_seq"
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER TABLE "public"."decision_rationales_id_seq" OWNER TO "postgres";
ALTER SEQUENCE "public"."decision_rationales_id_seq" OWNED BY "public"."decision_rationales"."id";
CREATE TABLE IF NOT EXISTS "public"."goods_services" (
    "id" integer NOT NULL,
    "term" "text" NOT NULL,
    "nice_class" integer NOT NULL,
    "created_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP,
    "updated_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP
);
ALTER TABLE "public"."goods_services" OWNER TO "postgres";
CREATE TABLE IF NOT EXISTS "public"."goods_services_comparisons" (
    "id" integer NOT NULL,
    "goods_services_1_id" integer,
    "goods_services_2_id" integer,
    "similarity" "public"."similarity_level" NOT NULL,
    "market_context" "jsonb",
    "case_reference" "text",
    "created_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP,
    "updated_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP
);
ALTER TABLE "public"."goods_services_comparisons" OWNER TO "postgres";
CREATE SEQUENCE IF NOT EXISTS "public"."goods_services_comparisons_id_seq"
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER TABLE "public"."goods_services_comparisons_id_seq" OWNER TO "postgres";
ALTER SEQUENCE "public"."goods_services_comparisons_id_seq" OWNED BY "public"."goods_services_comparisons"."id";
CREATE SEQUENCE IF NOT EXISTS "public"."goods_services_id_seq"
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER TABLE "public"."goods_services_id_seq" OWNER TO "postgres";
ALTER SEQUENCE "public"."goods_services_id_seq" OWNED BY "public"."goods_services"."id";
CREATE TABLE IF NOT EXISTS "public"."mark_comparisons" (
    "id" integer NOT NULL,
    "applicant_mark_id" integer,
    "opponent_mark_id" integer,
    "case_reference" "text",
    "visual_similarity" "public"."similarity_level",
    "aural_similarity" "public"."similarity_level",
    "conceptual_similarity" "public"."conceptual_similarity_level",
    "created_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP,
    "updated_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP
);
ALTER TABLE "public"."mark_comparisons" OWNER TO "postgres";
CREATE SEQUENCE IF NOT EXISTS "public"."mark_comparisons_id_seq"
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER TABLE "public"."mark_comparisons_id_seq" OWNER TO "postgres";
ALTER SEQUENCE "public"."mark_comparisons_id_seq" OWNED BY "public"."mark_comparisons"."id";
CREATE TABLE IF NOT EXISTS "public"."opponent_goods_services" (
    "id" integer NOT NULL,
    "mark_id" integer,
    "goods_services_id" integer,
    "created_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP,
    "updated_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP
);
ALTER TABLE "public"."opponent_goods_services" OWNER TO "postgres";
CREATE SEQUENCE IF NOT EXISTS "public"."opponent_goods_services_id_seq"
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER TABLE "public"."opponent_goods_services_id_seq" OWNER TO "postgres";
ALTER SEQUENCE "public"."opponent_goods_services_id_seq" OWNED BY "public"."opponent_goods_services"."id";
CREATE TABLE IF NOT EXISTS "public"."opponent_marks" (
    "id" integer NOT NULL,
    "case_reference" "text",
    "mark" "text" NOT NULL,
    "mark_is_figurative" boolean DEFAULT false NOT NULL,
    "registration_number" "text",
    "filing_date" "date",
    "registration_date" "date",
    "priority_date" "date",
    "created_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP,
    "updated_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP
);
ALTER TABLE "public"."opponent_marks" OWNER TO "postgres";
CREATE SEQUENCE IF NOT EXISTS "public"."opponent_marks_id_seq"
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER TABLE "public"."opponent_marks_id_seq" OWNER TO "postgres";
ALTER SEQUENCE "public"."opponent_marks_id_seq" OWNED BY "public"."opponent_marks"."id";
CREATE TABLE IF NOT EXISTS "public"."opposition_grounds" (
    "id" integer NOT NULL,
    "case_reference" "text",
    "ground" "text" NOT NULL,
    "created_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP,
    "updated_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP
);
ALTER TABLE "public"."opposition_grounds" OWNER TO "postgres";
CREATE SEQUENCE IF NOT EXISTS "public"."opposition_grounds_id_seq"
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER TABLE "public"."opposition_grounds_id_seq" OWNER TO "postgres";
ALTER SEQUENCE "public"."opposition_grounds_id_seq" OWNED BY "public"."opposition_grounds"."id";
CREATE TABLE IF NOT EXISTS "public"."precedents_cited" (
    "id" integer NOT NULL,
    "decision_rationale_id" integer,
    "title" "text" NOT NULL,
    "case_reference" "text",
    "created_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP,
    "updated_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP
);
ALTER TABLE "public"."precedents_cited" OWNER TO "postgres";
CREATE SEQUENCE IF NOT EXISTS "public"."precedents_cited_id_seq"
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER TABLE "public"."precedents_cited_id_seq" OWNER TO "postgres";
ALTER SEQUENCE "public"."precedents_cited_id_seq" OWNED BY "public"."precedents_cited"."id";
CREATE TABLE IF NOT EXISTS "public"."trademark_cases" (
    "case_reference" "text" NOT NULL,
    "application_number" "text",
    "applicant_name" "text",
    "opponent_name" "text",
    "proof_of_use_requested" boolean,
    "proof_of_use_outcome" "public"."proof_of_use_status",
    "distinctive_character" "public"."distinctive_character_level",
    "average_consumer_attention" "public"."attention_level",
    "opposition_outcome" "public"."opposition_outcome",
    "decision_maker" "text",
    "jurisdiction" "public"."jurisdiction_type",
    "case_pdf_path" "text",
    "metadata" "jsonb",
    "created_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP,
    "updated_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP
);
ALTER TABLE "public"."trademark_cases" OWNER TO "postgres";
CREATE TABLE IF NOT EXISTS "public"."vector_embeddings" (
    "id" integer NOT NULL,
    "entity_type" character varying(50) NOT NULL,
    "entity_id" integer NOT NULL,
    "embedding" "public"."vector"(1536) NOT NULL,
    "created_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP,
    "updated_at" timestamp with time zone DEFAULT CURRENT_TIMESTAMP
);
ALTER TABLE "public"."vector_embeddings" OWNER TO "postgres";
CREATE SEQUENCE IF NOT EXISTS "public"."vector_embeddings_id_seq"
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;
ALTER TABLE "public"."vector_embeddings_id_seq" OWNER TO "postgres";
ALTER SEQUENCE "public"."vector_embeddings_id_seq" OWNED BY "public"."vector_embeddings"."id";
ALTER TABLE ONLY "public"."applicant_goods_services" ALTER COLUMN "id" SET DEFAULT "nextval"('"public"."applicant_goods_services_id_seq"'::"regclass");
ALTER TABLE ONLY "public"."applicant_marks" ALTER COLUMN "id" SET DEFAULT "nextval"('"public"."applicant_marks_id_seq"'::"regclass");
ALTER TABLE ONLY "public"."decision_rationales" ALTER COLUMN "id" SET DEFAULT "nextval"('"public"."decision_rationales_id_seq"'::"regclass");
ALTER TABLE ONLY "public"."goods_services" ALTER COLUMN "id" SET DEFAULT "nextval"('"public"."goods_services_id_seq"'::"regclass");
ALTER TABLE ONLY "public"."goods_services_comparisons" ALTER COLUMN "id" SET DEFAULT "nextval"('"public"."goods_services_comparisons_id_seq"'::"regclass");
ALTER TABLE ONLY "public"."mark_comparisons" ALTER COLUMN "id" SET DEFAULT "nextval"('"public"."mark_comparisons_id_seq"'::"regclass");
ALTER TABLE ONLY "public"."opponent_goods_services" ALTER COLUMN "id" SET DEFAULT "nextval"('"public"."opponent_goods_services_id_seq"'::"regclass");
ALTER TABLE ONLY "public"."opponent_marks" ALTER COLUMN "id" SET DEFAULT "nextval"('"public"."opponent_marks_id_seq"'::"regclass");
ALTER TABLE ONLY "public"."opposition_grounds" ALTER COLUMN "id" SET DEFAULT "nextval"('"public"."opposition_grounds_id_seq"'::"regclass");
ALTER TABLE ONLY "public"."precedents_cited" ALTER COLUMN "id" SET DEFAULT "nextval"('"public"."precedents_cited_id_seq"'::"regclass");
ALTER TABLE ONLY "public"."vector_embeddings" ALTER COLUMN "id" SET DEFAULT "nextval"('"public"."vector_embeddings_id_seq"'::"regclass");
ALTER TABLE ONLY "public"."applicant_goods_services"
    ADD CONSTRAINT "applicant_goods_services_mark_id_goods_services_id_key" UNIQUE ("mark_id", "goods_services_id");
ALTER TABLE ONLY "public"."applicant_goods_services"
    ADD CONSTRAINT "applicant_goods_services_pkey" PRIMARY KEY ("id");
ALTER TABLE ONLY "public"."applicant_marks"
    ADD CONSTRAINT "applicant_marks_pkey" PRIMARY KEY ("id");
ALTER TABLE ONLY "public"."decision_rationales"
    ADD CONSTRAINT "decision_rationales_pkey" PRIMARY KEY ("id");
ALTER TABLE ONLY "public"."goods_services_comparisons"
    ADD CONSTRAINT "goods_services_comparisons_goods_services_1_id_goods_servic_key" UNIQUE ("goods_services_1_id", "goods_services_2_id");
ALTER TABLE ONLY "public"."goods_services_comparisons"
    ADD CONSTRAINT "goods_services_comparisons_pkey" PRIMARY KEY ("id");
ALTER TABLE ONLY "public"."goods_services"
    ADD CONSTRAINT "goods_services_pkey" PRIMARY KEY ("id");
ALTER TABLE ONLY "public"."goods_services"
    ADD CONSTRAINT "goods_services_term_nice_class_key" UNIQUE ("term", "nice_class");
ALTER TABLE ONLY "public"."mark_comparisons"
    ADD CONSTRAINT "mark_comparisons_applicant_mark_id_opponent_mark_id_key" UNIQUE ("applicant_mark_id", "opponent_mark_id");
ALTER TABLE ONLY "public"."mark_comparisons"
    ADD CONSTRAINT "mark_comparisons_pkey" PRIMARY KEY ("id");
ALTER TABLE ONLY "public"."opponent_goods_services"
    ADD CONSTRAINT "opponent_goods_services_mark_id_goods_services_id_key" UNIQUE ("mark_id", "goods_services_id");
ALTER TABLE ONLY "public"."opponent_goods_services"
    ADD CONSTRAINT "opponent_goods_services_pkey" PRIMARY KEY ("id");
ALTER TABLE ONLY "public"."opponent_marks"
    ADD CONSTRAINT "opponent_marks_pkey" PRIMARY KEY ("id");
ALTER TABLE ONLY "public"."opposition_grounds"
    ADD CONSTRAINT "opposition_grounds_pkey" PRIMARY KEY ("id");
ALTER TABLE ONLY "public"."precedents_cited"
    ADD CONSTRAINT "precedents_cited_pkey" PRIMARY KEY ("id");
ALTER TABLE ONLY "public"."trademark_cases"
    ADD CONSTRAINT "trademark_cases_pkey" PRIMARY KEY ("case_reference");
ALTER TABLE ONLY "public"."vector_embeddings"
    ADD CONSTRAINT "vector_embeddings_pkey" PRIMARY KEY ("id");
CREATE INDEX "idx_applicant_marks_case" ON "public"."applicant_marks" USING "btree" ("case_reference");
CREATE INDEX "idx_case_reference" ON "public"."trademark_cases" USING "btree" ("case_reference");
CREATE INDEX "idx_goods_services_comparisons_market_context" ON "public"."goods_services_comparisons" USING "gin" ("market_context");
CREATE INDEX "idx_goods_services_comparisons_similarity" ON "public"."goods_services_comparisons" USING "btree" ("similarity");
CREATE INDEX "idx_goods_services_nice_class" ON "public"."goods_services" USING "btree" ("nice_class");
CREATE INDEX "idx_goods_services_term" ON "public"."goods_services" USING "btree" ("term");
CREATE INDEX "idx_mark_comparisons_case" ON "public"."mark_comparisons" USING "btree" ("case_reference");
CREATE INDEX "idx_opponent_marks_case" ON "public"."opponent_marks" USING "btree" ("case_reference");
CREATE INDEX "idx_trademark_cases_metadata" ON "public"."trademark_cases" USING "gin" ("metadata");
CREATE INDEX "idx_vector_embeddings_entity" ON "public"."vector_embeddings" USING "btree" ("entity_type", "entity_id");
CREATE OR REPLACE TRIGGER "update_applicant_goods_services_timestamp" BEFORE UPDATE ON "public"."applicant_goods_services" FOR EACH ROW EXECUTE FUNCTION "public"."update_timestamp"();
CREATE OR REPLACE TRIGGER "update_applicant_marks_timestamp" BEFORE UPDATE ON "public"."applicant_marks" FOR EACH ROW EXECUTE FUNCTION "public"."update_timestamp"();
CREATE OR REPLACE TRIGGER "update_decision_rationales_timestamp" BEFORE UPDATE ON "public"."decision_rationales" FOR EACH ROW EXECUTE FUNCTION "public"."update_timestamp"();
CREATE OR REPLACE TRIGGER "update_goods_services_comparisons_timestamp" BEFORE UPDATE ON "public"."goods_services_comparisons" FOR EACH ROW EXECUTE FUNCTION "public"."update_timestamp"();
CREATE OR REPLACE TRIGGER "update_goods_services_timestamp" BEFORE UPDATE ON "public"."goods_services" FOR EACH ROW EXECUTE FUNCTION "public"."update_timestamp"();
CREATE OR REPLACE TRIGGER "update_mark_comparisons_timestamp" BEFORE UPDATE ON "public"."mark_comparisons" FOR EACH ROW EXECUTE FUNCTION "public"."update_timestamp"();
CREATE OR REPLACE TRIGGER "update_opponent_goods_services_timestamp" BEFORE UPDATE ON "public"."opponent_goods_services" FOR EACH ROW EXECUTE FUNCTION "public"."update_timestamp"();
CREATE OR REPLACE TRIGGER "update_opponent_marks_timestamp" BEFORE UPDATE ON "public"."opponent_marks" FOR EACH ROW EXECUTE FUNCTION "public"."update_timestamp"();
CREATE OR REPLACE TRIGGER "update_opposition_grounds_timestamp" BEFORE UPDATE ON "public"."opposition_grounds" FOR EACH ROW EXECUTE FUNCTION "public"."update_timestamp"();
CREATE OR REPLACE TRIGGER "update_precedents_cited_timestamp" BEFORE UPDATE ON "public"."precedents_cited" FOR EACH ROW EXECUTE FUNCTION "public"."update_timestamp"();
CREATE OR REPLACE TRIGGER "update_trademark_cases_timestamp" BEFORE UPDATE ON "public"."trademark_cases" FOR EACH ROW EXECUTE FUNCTION "public"."update_timestamp"();
CREATE OR REPLACE TRIGGER "update_vector_embeddings_timestamp" BEFORE UPDATE ON "public"."vector_embeddings" FOR EACH ROW EXECUTE FUNCTION "public"."update_timestamp"();
ALTER TABLE ONLY "public"."applicant_goods_services"
    ADD CONSTRAINT "applicant_goods_services_goods_services_id_fkey" FOREIGN KEY ("goods_services_id") REFERENCES "public"."goods_services"("id") ON DELETE CASCADE;
ALTER TABLE ONLY "public"."applicant_goods_services"
    ADD CONSTRAINT "applicant_goods_services_mark_id_fkey" FOREIGN KEY ("mark_id") REFERENCES "public"."applicant_marks"("id") ON DELETE CASCADE;
ALTER TABLE ONLY "public"."applicant_marks"
    ADD CONSTRAINT "applicant_marks_case_reference_fkey" FOREIGN KEY ("case_reference") REFERENCES "public"."trademark_cases"("case_reference") ON DELETE CASCADE;
ALTER TABLE ONLY "public"."decision_rationales"
    ADD CONSTRAINT "decision_rationales_case_reference_fkey" FOREIGN KEY ("case_reference") REFERENCES "public"."trademark_cases"("case_reference") ON DELETE CASCADE;
ALTER TABLE ONLY "public"."goods_services_comparisons"
    ADD CONSTRAINT "goods_services_comparisons_case_reference_fkey" FOREIGN KEY ("case_reference") REFERENCES "public"."trademark_cases"("case_reference") ON DELETE SET NULL;
ALTER TABLE ONLY "public"."goods_services_comparisons"
    ADD CONSTRAINT "goods_services_comparisons_goods_services_1_id_fkey" FOREIGN KEY ("goods_services_1_id") REFERENCES "public"."goods_services"("id") ON DELETE CASCADE;
ALTER TABLE ONLY "public"."goods_services_comparisons"
    ADD CONSTRAINT "goods_services_comparisons_goods_services_2_id_fkey" FOREIGN KEY ("goods_services_2_id") REFERENCES "public"."goods_services"("id") ON DELETE CASCADE;
ALTER TABLE ONLY "public"."mark_comparisons"
    ADD CONSTRAINT "mark_comparisons_applicant_mark_id_fkey" FOREIGN KEY ("applicant_mark_id") REFERENCES "public"."applicant_marks"("id") ON DELETE CASCADE;
ALTER TABLE ONLY "public"."mark_comparisons"
    ADD CONSTRAINT "mark_comparisons_case_reference_fkey" FOREIGN KEY ("case_reference") REFERENCES "public"."trademark_cases"("case_reference") ON DELETE CASCADE;
ALTER TABLE ONLY "public"."mark_comparisons"
    ADD CONSTRAINT "mark_comparisons_opponent_mark_id_fkey" FOREIGN KEY ("opponent_mark_id") REFERENCES "public"."opponent_marks"("id") ON DELETE CASCADE;
ALTER TABLE ONLY "public"."opponent_goods_services"
    ADD CONSTRAINT "opponent_goods_services_goods_services_id_fkey" FOREIGN KEY ("goods_services_id") REFERENCES "public"."goods_services"("id") ON DELETE CASCADE;
ALTER TABLE ONLY "public"."opponent_goods_services"
    ADD CONSTRAINT "opponent_goods_services_mark_id_fkey" FOREIGN KEY ("mark_id") REFERENCES "public"."opponent_marks"("id") ON DELETE CASCADE;
ALTER TABLE ONLY "public"."opponent_marks"
    ADD CONSTRAINT "opponent_marks_case_reference_fkey" FOREIGN KEY ("case_reference") REFERENCES "public"."trademark_cases"("case_reference") ON DELETE CASCADE;
ALTER TABLE ONLY "public"."opposition_grounds"
    ADD CONSTRAINT "opposition_grounds_case_reference_fkey" FOREIGN KEY ("case_reference") REFERENCES "public"."trademark_cases"("case_reference") ON DELETE CASCADE;
ALTER TABLE ONLY "public"."precedents_cited"
    ADD CONSTRAINT "precedents_cited_decision_rationale_id_fkey" FOREIGN KEY ("decision_rationale_id") REFERENCES "public"."decision_rationales"("id") ON DELETE CASCADE;
ALTER PUBLICATION "supabase_realtime" OWNER TO "postgres";
GRANT USAGE ON SCHEMA "public" TO "postgres";
GRANT USAGE ON SCHEMA "public" TO "anon";
GRANT USAGE ON SCHEMA "public" TO "authenticated";
GRANT USAGE ON SCHEMA "public" TO "service_role";
GRANT ALL ON FUNCTION "public"."gtrgm_in"("cstring") TO "postgres";
GRANT ALL ON FUNCTION "public"."gtrgm_in"("cstring") TO "anon";
GRANT ALL ON FUNCTION "public"."gtrgm_in"("cstring") TO "authenticated";
GRANT ALL ON FUNCTION "public"."gtrgm_in"("cstring") TO "service_role";
GRANT ALL ON FUNCTION "public"."gtrgm_out"("public"."gtrgm") TO "postgres";
GRANT ALL ON FUNCTION "public"."gtrgm_out"("public"."gtrgm") TO "anon";
GRANT ALL ON FUNCTION "public"."gtrgm_out"("public"."gtrgm") TO "authenticated";
GRANT ALL ON FUNCTION "public"."gtrgm_out"("public"."gtrgm") TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_in"("cstring", "oid", integer) TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_in"("cstring", "oid", integer) TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_in"("cstring", "oid", integer) TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_in"("cstring", "oid", integer) TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_out"("public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_out"("public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_out"("public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_out"("public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_recv"("internal", "oid", integer) TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_recv"("internal", "oid", integer) TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_recv"("internal", "oid", integer) TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_recv"("internal", "oid", integer) TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_send"("public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_send"("public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_send"("public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_send"("public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_typmod_in"("cstring"[]) TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_typmod_in"("cstring"[]) TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_typmod_in"("cstring"[]) TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_typmod_in"("cstring"[]) TO "service_role";
GRANT ALL ON FUNCTION "public"."sparsevec_in"("cstring", "oid", integer) TO "postgres";
GRANT ALL ON FUNCTION "public"."sparsevec_in"("cstring", "oid", integer) TO "anon";
GRANT ALL ON FUNCTION "public"."sparsevec_in"("cstring", "oid", integer) TO "authenticated";
GRANT ALL ON FUNCTION "public"."sparsevec_in"("cstring", "oid", integer) TO "service_role";
GRANT ALL ON FUNCTION "public"."sparsevec_out"("public"."sparsevec") TO "postgres";
GRANT ALL ON FUNCTION "public"."sparsevec_out"("public"."sparsevec") TO "anon";
GRANT ALL ON FUNCTION "public"."sparsevec_out"("public"."sparsevec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."sparsevec_out"("public"."sparsevec") TO "service_role";
GRANT ALL ON FUNCTION "public"."sparsevec_recv"("internal", "oid", integer) TO "postgres";
GRANT ALL ON FUNCTION "public"."sparsevec_recv"("internal", "oid", integer) TO "anon";
GRANT ALL ON FUNCTION "public"."sparsevec_recv"("internal", "oid", integer) TO "authenticated";
GRANT ALL ON FUNCTION "public"."sparsevec_recv"("internal", "oid", integer) TO "service_role";
GRANT ALL ON FUNCTION "public"."sparsevec_send"("public"."sparsevec") TO "postgres";
GRANT ALL ON FUNCTION "public"."sparsevec_send"("public"."sparsevec") TO "anon";
GRANT ALL ON FUNCTION "public"."sparsevec_send"("public"."sparsevec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."sparsevec_send"("public"."sparsevec") TO "service_role";
GRANT ALL ON FUNCTION "public"."sparsevec_typmod_in"("cstring"[]) TO "postgres";
GRANT ALL ON FUNCTION "public"."sparsevec_typmod_in"("cstring"[]) TO "anon";
GRANT ALL ON FUNCTION "public"."sparsevec_typmod_in"("cstring"[]) TO "authenticated";
GRANT ALL ON FUNCTION "public"."sparsevec_typmod_in"("cstring"[]) TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_in"("cstring", "oid", integer) TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_in"("cstring", "oid", integer) TO "anon";
GRANT ALL ON FUNCTION "public"."vector_in"("cstring", "oid", integer) TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_in"("cstring", "oid", integer) TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_out"("public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_out"("public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."vector_out"("public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_out"("public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_recv"("internal", "oid", integer) TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_recv"("internal", "oid", integer) TO "anon";
GRANT ALL ON FUNCTION "public"."vector_recv"("internal", "oid", integer) TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_recv"("internal", "oid", integer) TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_send"("public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_send"("public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."vector_send"("public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_send"("public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_typmod_in"("cstring"[]) TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_typmod_in"("cstring"[]) TO "anon";
GRANT ALL ON FUNCTION "public"."vector_typmod_in"("cstring"[]) TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_typmod_in"("cstring"[]) TO "service_role";
GRANT ALL ON FUNCTION "public"."array_to_halfvec"(real[], integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."array_to_halfvec"(real[], integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."array_to_halfvec"(real[], integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."array_to_halfvec"(real[], integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."array_to_sparsevec"(real[], integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."array_to_sparsevec"(real[], integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."array_to_sparsevec"(real[], integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."array_to_sparsevec"(real[], integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."array_to_vector"(real[], integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."array_to_vector"(real[], integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."array_to_vector"(real[], integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."array_to_vector"(real[], integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."array_to_halfvec"(double precision[], integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."array_to_halfvec"(double precision[], integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."array_to_halfvec"(double precision[], integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."array_to_halfvec"(double precision[], integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."array_to_sparsevec"(double precision[], integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."array_to_sparsevec"(double precision[], integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."array_to_sparsevec"(double precision[], integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."array_to_sparsevec"(double precision[], integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."array_to_vector"(double precision[], integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."array_to_vector"(double precision[], integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."array_to_vector"(double precision[], integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."array_to_vector"(double precision[], integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."array_to_halfvec"(integer[], integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."array_to_halfvec"(integer[], integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."array_to_halfvec"(integer[], integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."array_to_halfvec"(integer[], integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."array_to_sparsevec"(integer[], integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."array_to_sparsevec"(integer[], integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."array_to_sparsevec"(integer[], integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."array_to_sparsevec"(integer[], integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."array_to_vector"(integer[], integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."array_to_vector"(integer[], integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."array_to_vector"(integer[], integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."array_to_vector"(integer[], integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."array_to_halfvec"(numeric[], integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."array_to_halfvec"(numeric[], integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."array_to_halfvec"(numeric[], integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."array_to_halfvec"(numeric[], integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."array_to_sparsevec"(numeric[], integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."array_to_sparsevec"(numeric[], integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."array_to_sparsevec"(numeric[], integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."array_to_sparsevec"(numeric[], integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."array_to_vector"(numeric[], integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."array_to_vector"(numeric[], integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."array_to_vector"(numeric[], integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."array_to_vector"(numeric[], integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_to_float4"("public"."halfvec", integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_to_float4"("public"."halfvec", integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_to_float4"("public"."halfvec", integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_to_float4"("public"."halfvec", integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec"("public"."halfvec", integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec"("public"."halfvec", integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec"("public"."halfvec", integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec"("public"."halfvec", integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_to_sparsevec"("public"."halfvec", integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_to_sparsevec"("public"."halfvec", integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_to_sparsevec"("public"."halfvec", integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_to_sparsevec"("public"."halfvec", integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_to_vector"("public"."halfvec", integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_to_vector"("public"."halfvec", integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_to_vector"("public"."halfvec", integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_to_vector"("public"."halfvec", integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."sparsevec_to_halfvec"("public"."sparsevec", integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."sparsevec_to_halfvec"("public"."sparsevec", integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."sparsevec_to_halfvec"("public"."sparsevec", integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."sparsevec_to_halfvec"("public"."sparsevec", integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."sparsevec"("public"."sparsevec", integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."sparsevec"("public"."sparsevec", integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."sparsevec"("public"."sparsevec", integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."sparsevec"("public"."sparsevec", integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."sparsevec_to_vector"("public"."sparsevec", integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."sparsevec_to_vector"("public"."sparsevec", integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."sparsevec_to_vector"("public"."sparsevec", integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."sparsevec_to_vector"("public"."sparsevec", integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_to_float4"("public"."vector", integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_to_float4"("public"."vector", integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."vector_to_float4"("public"."vector", integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_to_float4"("public"."vector", integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_to_halfvec"("public"."vector", integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_to_halfvec"("public"."vector", integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."vector_to_halfvec"("public"."vector", integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_to_halfvec"("public"."vector", integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_to_sparsevec"("public"."vector", integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_to_sparsevec"("public"."vector", integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."vector_to_sparsevec"("public"."vector", integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_to_sparsevec"("public"."vector", integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."vector"("public"."vector", integer, boolean) TO "postgres";
GRANT ALL ON FUNCTION "public"."vector"("public"."vector", integer, boolean) TO "anon";
GRANT ALL ON FUNCTION "public"."vector"("public"."vector", integer, boolean) TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector"("public"."vector", integer, boolean) TO "service_role";
GRANT ALL ON FUNCTION "public"."begin_transaction"() TO "anon";
GRANT ALL ON FUNCTION "public"."begin_transaction"() TO "authenticated";
GRANT ALL ON FUNCTION "public"."begin_transaction"() TO "service_role";
GRANT ALL ON FUNCTION "public"."binary_quantize"("public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."binary_quantize"("public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."binary_quantize"("public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."binary_quantize"("public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."binary_quantize"("public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."binary_quantize"("public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."binary_quantize"("public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."binary_quantize"("public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."commit_transaction"() TO "anon";
GRANT ALL ON FUNCTION "public"."commit_transaction"() TO "authenticated";
GRANT ALL ON FUNCTION "public"."commit_transaction"() TO "service_role";
GRANT ALL ON FUNCTION "public"."cosine_distance"("public"."halfvec", "public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."cosine_distance"("public"."halfvec", "public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."cosine_distance"("public"."halfvec", "public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."cosine_distance"("public"."halfvec", "public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."cosine_distance"("public"."sparsevec", "public"."sparsevec") TO "postgres";
GRANT ALL ON FUNCTION "public"."cosine_distance"("public"."sparsevec", "public"."sparsevec") TO "anon";
GRANT ALL ON FUNCTION "public"."cosine_distance"("public"."sparsevec", "public"."sparsevec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."cosine_distance"("public"."sparsevec", "public"."sparsevec") TO "service_role";
GRANT ALL ON FUNCTION "public"."cosine_distance"("public"."vector", "public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."cosine_distance"("public"."vector", "public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."cosine_distance"("public"."vector", "public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."cosine_distance"("public"."vector", "public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."find_similar_cases"("mark_text" "text", "limit_count" integer) TO "anon";
GRANT ALL ON FUNCTION "public"."find_similar_cases"("mark_text" "text", "limit_count" integer) TO "authenticated";
GRANT ALL ON FUNCTION "public"."find_similar_cases"("mark_text" "text", "limit_count" integer) TO "service_role";
GRANT ALL ON FUNCTION "public"."find_similar_goods_services"("search_term" "text", "class_num" integer, "limit_count" integer) TO "anon";
GRANT ALL ON FUNCTION "public"."find_similar_goods_services"("search_term" "text", "class_num" integer, "limit_count" integer) TO "authenticated";
GRANT ALL ON FUNCTION "public"."find_similar_goods_services"("search_term" "text", "class_num" integer, "limit_count" integer) TO "service_role";
GRANT ALL ON FUNCTION "public"."find_similar_term"("input_term" "text", "input_nice_class" integer, "threshold" double precision) TO "anon";
GRANT ALL ON FUNCTION "public"."find_similar_term"("input_term" "text", "input_nice_class" integer, "threshold" double precision) TO "authenticated";
GRANT ALL ON FUNCTION "public"."find_similar_term"("input_term" "text", "input_nice_class" integer, "threshold" double precision) TO "service_role";
GRANT ALL ON FUNCTION "public"."get_goods_services_comparisons"("limit_count" integer) TO "anon";
GRANT ALL ON FUNCTION "public"."get_goods_services_comparisons"("limit_count" integer) TO "authenticated";
GRANT ALL ON FUNCTION "public"."get_goods_services_comparisons"("limit_count" integer) TO "service_role";
GRANT ALL ON FUNCTION "public"."gin_extract_query_trgm"("text", "internal", smallint, "internal", "internal", "internal", "internal") TO "postgres";
GRANT ALL ON FUNCTION "public"."gin_extract_query_trgm"("text", "internal", smallint, "internal", "internal", "internal", "internal") TO "anon";
GRANT ALL ON FUNCTION "public"."gin_extract_query_trgm"("text", "internal", smallint, "internal", "internal", "internal", "internal") TO "authenticated";
GRANT ALL ON FUNCTION "public"."gin_extract_query_trgm"("text", "internal", smallint, "internal", "internal", "internal", "internal") TO "service_role";
GRANT ALL ON FUNCTION "public"."gin_extract_value_trgm"("text", "internal") TO "postgres";
GRANT ALL ON FUNCTION "public"."gin_extract_value_trgm"("text", "internal") TO "anon";
GRANT ALL ON FUNCTION "public"."gin_extract_value_trgm"("text", "internal") TO "authenticated";
GRANT ALL ON FUNCTION "public"."gin_extract_value_trgm"("text", "internal") TO "service_role";
GRANT ALL ON FUNCTION "public"."gin_trgm_consistent"("internal", smallint, "text", integer, "internal", "internal", "internal", "internal") TO "postgres";
GRANT ALL ON FUNCTION "public"."gin_trgm_consistent"("internal", smallint, "text", integer, "internal", "internal", "internal", "internal") TO "anon";
GRANT ALL ON FUNCTION "public"."gin_trgm_consistent"("internal", smallint, "text", integer, "internal", "internal", "internal", "internal") TO "authenticated";
GRANT ALL ON FUNCTION "public"."gin_trgm_consistent"("internal", smallint, "text", integer, "internal", "internal", "internal", "internal") TO "service_role";
GRANT ALL ON FUNCTION "public"."gin_trgm_triconsistent"("internal", smallint, "text", integer, "internal", "internal", "internal") TO "postgres";
GRANT ALL ON FUNCTION "public"."gin_trgm_triconsistent"("internal", smallint, "text", integer, "internal", "internal", "internal") TO "anon";
GRANT ALL ON FUNCTION "public"."gin_trgm_triconsistent"("internal", smallint, "text", integer, "internal", "internal", "internal") TO "authenticated";
GRANT ALL ON FUNCTION "public"."gin_trgm_triconsistent"("internal", smallint, "text", integer, "internal", "internal", "internal") TO "service_role";
GRANT ALL ON FUNCTION "public"."gtrgm_compress"("internal") TO "postgres";
GRANT ALL ON FUNCTION "public"."gtrgm_compress"("internal") TO "anon";
GRANT ALL ON FUNCTION "public"."gtrgm_compress"("internal") TO "authenticated";
GRANT ALL ON FUNCTION "public"."gtrgm_compress"("internal") TO "service_role";
GRANT ALL ON FUNCTION "public"."gtrgm_consistent"("internal", "text", smallint, "oid", "internal") TO "postgres";
GRANT ALL ON FUNCTION "public"."gtrgm_consistent"("internal", "text", smallint, "oid", "internal") TO "anon";
GRANT ALL ON FUNCTION "public"."gtrgm_consistent"("internal", "text", smallint, "oid", "internal") TO "authenticated";
GRANT ALL ON FUNCTION "public"."gtrgm_consistent"("internal", "text", smallint, "oid", "internal") TO "service_role";
GRANT ALL ON FUNCTION "public"."gtrgm_decompress"("internal") TO "postgres";
GRANT ALL ON FUNCTION "public"."gtrgm_decompress"("internal") TO "anon";
GRANT ALL ON FUNCTION "public"."gtrgm_decompress"("internal") TO "authenticated";
GRANT ALL ON FUNCTION "public"."gtrgm_decompress"("internal") TO "service_role";
GRANT ALL ON FUNCTION "public"."gtrgm_distance"("internal", "text", smallint, "oid", "internal") TO "postgres";
GRANT ALL ON FUNCTION "public"."gtrgm_distance"("internal", "text", smallint, "oid", "internal") TO "anon";
GRANT ALL ON FUNCTION "public"."gtrgm_distance"("internal", "text", smallint, "oid", "internal") TO "authenticated";
GRANT ALL ON FUNCTION "public"."gtrgm_distance"("internal", "text", smallint, "oid", "internal") TO "service_role";
GRANT ALL ON FUNCTION "public"."gtrgm_options"("internal") TO "postgres";
GRANT ALL ON FUNCTION "public"."gtrgm_options"("internal") TO "anon";
GRANT ALL ON FUNCTION "public"."gtrgm_options"("internal") TO "authenticated";
GRANT ALL ON FUNCTION "public"."gtrgm_options"("internal") TO "service_role";
GRANT ALL ON FUNCTION "public"."gtrgm_penalty"("internal", "internal", "internal") TO "postgres";
GRANT ALL ON FUNCTION "public"."gtrgm_penalty"("internal", "internal", "internal") TO "anon";
GRANT ALL ON FUNCTION "public"."gtrgm_penalty"("internal", "internal", "internal") TO "authenticated";
GRANT ALL ON FUNCTION "public"."gtrgm_penalty"("internal", "internal", "internal") TO "service_role";
GRANT ALL ON FUNCTION "public"."gtrgm_picksplit"("internal", "internal") TO "postgres";
GRANT ALL ON FUNCTION "public"."gtrgm_picksplit"("internal", "internal") TO "anon";
GRANT ALL ON FUNCTION "public"."gtrgm_picksplit"("internal", "internal") TO "authenticated";
GRANT ALL ON FUNCTION "public"."gtrgm_picksplit"("internal", "internal") TO "service_role";
GRANT ALL ON FUNCTION "public"."gtrgm_same"("public"."gtrgm", "public"."gtrgm", "internal") TO "postgres";
GRANT ALL ON FUNCTION "public"."gtrgm_same"("public"."gtrgm", "public"."gtrgm", "internal") TO "anon";
GRANT ALL ON FUNCTION "public"."gtrgm_same"("public"."gtrgm", "public"."gtrgm", "internal") TO "authenticated";
GRANT ALL ON FUNCTION "public"."gtrgm_same"("public"."gtrgm", "public"."gtrgm", "internal") TO "service_role";
GRANT ALL ON FUNCTION "public"."gtrgm_union"("internal", "internal") TO "postgres";
GRANT ALL ON FUNCTION "public"."gtrgm_union"("internal", "internal") TO "anon";
GRANT ALL ON FUNCTION "public"."gtrgm_union"("internal", "internal") TO "authenticated";
GRANT ALL ON FUNCTION "public"."gtrgm_union"("internal", "internal") TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_accum"(double precision[], "public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_accum"(double precision[], "public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_accum"(double precision[], "public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_accum"(double precision[], "public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_add"("public"."halfvec", "public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_add"("public"."halfvec", "public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_add"("public"."halfvec", "public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_add"("public"."halfvec", "public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_avg"(double precision[]) TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_avg"(double precision[]) TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_avg"(double precision[]) TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_avg"(double precision[]) TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_cmp"("public"."halfvec", "public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_cmp"("public"."halfvec", "public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_cmp"("public"."halfvec", "public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_cmp"("public"."halfvec", "public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_combine"(double precision[], double precision[]) TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_combine"(double precision[], double precision[]) TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_combine"(double precision[], double precision[]) TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_combine"(double precision[], double precision[]) TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_concat"("public"."halfvec", "public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_concat"("public"."halfvec", "public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_concat"("public"."halfvec", "public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_concat"("public"."halfvec", "public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_eq"("public"."halfvec", "public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_eq"("public"."halfvec", "public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_eq"("public"."halfvec", "public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_eq"("public"."halfvec", "public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_ge"("public"."halfvec", "public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_ge"("public"."halfvec", "public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_ge"("public"."halfvec", "public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_ge"("public"."halfvec", "public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_gt"("public"."halfvec", "public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_gt"("public"."halfvec", "public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_gt"("public"."halfvec", "public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_gt"("public"."halfvec", "public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_l2_squared_distance"("public"."halfvec", "public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_l2_squared_distance"("public"."halfvec", "public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_l2_squared_distance"("public"."halfvec", "public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_l2_squared_distance"("public"."halfvec", "public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_le"("public"."halfvec", "public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_le"("public"."halfvec", "public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_le"("public"."halfvec", "public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_le"("public"."halfvec", "public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_lt"("public"."halfvec", "public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_lt"("public"."halfvec", "public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_lt"("public"."halfvec", "public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_lt"("public"."halfvec", "public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_mul"("public"."halfvec", "public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_mul"("public"."halfvec", "public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_mul"("public"."halfvec", "public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_mul"("public"."halfvec", "public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_ne"("public"."halfvec", "public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_ne"("public"."halfvec", "public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_ne"("public"."halfvec", "public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_ne"("public"."halfvec", "public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_negative_inner_product"("public"."halfvec", "public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_negative_inner_product"("public"."halfvec", "public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_negative_inner_product"("public"."halfvec", "public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_negative_inner_product"("public"."halfvec", "public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_spherical_distance"("public"."halfvec", "public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_spherical_distance"("public"."halfvec", "public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_spherical_distance"("public"."halfvec", "public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_spherical_distance"("public"."halfvec", "public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."halfvec_sub"("public"."halfvec", "public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."halfvec_sub"("public"."halfvec", "public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."halfvec_sub"("public"."halfvec", "public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."halfvec_sub"("public"."halfvec", "public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."hamming_distance"(bit, bit) TO "postgres";
GRANT ALL ON FUNCTION "public"."hamming_distance"(bit, bit) TO "anon";
GRANT ALL ON FUNCTION "public"."hamming_distance"(bit, bit) TO "authenticated";
GRANT ALL ON FUNCTION "public"."hamming_distance"(bit, bit) TO "service_role";
GRANT ALL ON FUNCTION "public"."hnsw_bit_support"("internal") TO "postgres";
GRANT ALL ON FUNCTION "public"."hnsw_bit_support"("internal") TO "anon";
GRANT ALL ON FUNCTION "public"."hnsw_bit_support"("internal") TO "authenticated";
GRANT ALL ON FUNCTION "public"."hnsw_bit_support"("internal") TO "service_role";
GRANT ALL ON FUNCTION "public"."hnsw_halfvec_support"("internal") TO "postgres";
GRANT ALL ON FUNCTION "public"."hnsw_halfvec_support"("internal") TO "anon";
GRANT ALL ON FUNCTION "public"."hnsw_halfvec_support"("internal") TO "authenticated";
GRANT ALL ON FUNCTION "public"."hnsw_halfvec_support"("internal") TO "service_role";
GRANT ALL ON FUNCTION "public"."hnsw_sparsevec_support"("internal") TO "postgres";
GRANT ALL ON FUNCTION "public"."hnsw_sparsevec_support"("internal") TO "anon";
GRANT ALL ON FUNCTION "public"."hnsw_sparsevec_support"("internal") TO "authenticated";
GRANT ALL ON FUNCTION "public"."hnsw_sparsevec_support"("internal") TO "service_role";
GRANT ALL ON FUNCTION "public"."hnswhandler"("internal") TO "postgres";
GRANT ALL ON FUNCTION "public"."hnswhandler"("internal") TO "anon";
GRANT ALL ON FUNCTION "public"."hnswhandler"("internal") TO "authenticated";
GRANT ALL ON FUNCTION "public"."hnswhandler"("internal") TO "service_role";
GRANT ALL ON FUNCTION "public"."inner_product"("public"."halfvec", "public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."inner_product"("public"."halfvec", "public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."inner_product"("public"."halfvec", "public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."inner_product"("public"."halfvec", "public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."inner_product"("public"."sparsevec", "public"."sparsevec") TO "postgres";
GRANT ALL ON FUNCTION "public"."inner_product"("public"."sparsevec", "public"."sparsevec") TO "anon";
GRANT ALL ON FUNCTION "public"."inner_product"("public"."sparsevec", "public"."sparsevec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."inner_product"("public"."sparsevec", "public"."sparsevec") TO "service_role";
GRANT ALL ON FUNCTION "public"."inner_product"("public"."vector", "public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."inner_product"("public"."vector", "public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."inner_product"("public"."vector", "public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."inner_product"("public"."vector", "public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."ivfflat_bit_support"("internal") TO "postgres";
GRANT ALL ON FUNCTION "public"."ivfflat_bit_support"("internal") TO "anon";
GRANT ALL ON FUNCTION "public"."ivfflat_bit_support"("internal") TO "authenticated";
GRANT ALL ON FUNCTION "public"."ivfflat_bit_support"("internal") TO "service_role";
GRANT ALL ON FUNCTION "public"."ivfflat_halfvec_support"("internal") TO "postgres";
GRANT ALL ON FUNCTION "public"."ivfflat_halfvec_support"("internal") TO "anon";
GRANT ALL ON FUNCTION "public"."ivfflat_halfvec_support"("internal") TO "authenticated";
GRANT ALL ON FUNCTION "public"."ivfflat_halfvec_support"("internal") TO "service_role";
GRANT ALL ON FUNCTION "public"."ivfflathandler"("internal") TO "postgres";
GRANT ALL ON FUNCTION "public"."ivfflathandler"("internal") TO "anon";
GRANT ALL ON FUNCTION "public"."ivfflathandler"("internal") TO "authenticated";
GRANT ALL ON FUNCTION "public"."ivfflathandler"("internal") TO "service_role";
GRANT ALL ON FUNCTION "public"."jaccard_distance"(bit, bit) TO "postgres";
GRANT ALL ON FUNCTION "public"."jaccard_distance"(bit, bit) TO "anon";
GRANT ALL ON FUNCTION "public"."jaccard_distance"(bit, bit) TO "authenticated";
GRANT ALL ON FUNCTION "public"."jaccard_distance"(bit, bit) TO "service_role";
GRANT ALL ON FUNCTION "public"."l1_distance"("public"."halfvec", "public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."l1_distance"("public"."halfvec", "public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."l1_distance"("public"."halfvec", "public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."l1_distance"("public"."halfvec", "public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."l1_distance"("public"."sparsevec", "public"."sparsevec") TO "postgres";
GRANT ALL ON FUNCTION "public"."l1_distance"("public"."sparsevec", "public"."sparsevec") TO "anon";
GRANT ALL ON FUNCTION "public"."l1_distance"("public"."sparsevec", "public"."sparsevec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."l1_distance"("public"."sparsevec", "public"."sparsevec") TO "service_role";
GRANT ALL ON FUNCTION "public"."l1_distance"("public"."vector", "public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."l1_distance"("public"."vector", "public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."l1_distance"("public"."vector", "public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."l1_distance"("public"."vector", "public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."l2_distance"("public"."halfvec", "public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."l2_distance"("public"."halfvec", "public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."l2_distance"("public"."halfvec", "public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."l2_distance"("public"."halfvec", "public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."l2_distance"("public"."sparsevec", "public"."sparsevec") TO "postgres";
GRANT ALL ON FUNCTION "public"."l2_distance"("public"."sparsevec", "public"."sparsevec") TO "anon";
GRANT ALL ON FUNCTION "public"."l2_distance"("public"."sparsevec", "public"."sparsevec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."l2_distance"("public"."sparsevec", "public"."sparsevec") TO "service_role";
GRANT ALL ON FUNCTION "public"."l2_distance"("public"."vector", "public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."l2_distance"("public"."vector", "public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."l2_distance"("public"."vector", "public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."l2_distance"("public"."vector", "public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."l2_norm"("public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."l2_norm"("public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."l2_norm"("public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."l2_norm"("public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."l2_norm"("public"."sparsevec") TO "postgres";
GRANT ALL ON FUNCTION "public"."l2_norm"("public"."sparsevec") TO "anon";
GRANT ALL ON FUNCTION "public"."l2_norm"("public"."sparsevec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."l2_norm"("public"."sparsevec") TO "service_role";
GRANT ALL ON FUNCTION "public"."l2_normalize"("public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."l2_normalize"("public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."l2_normalize"("public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."l2_normalize"("public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."l2_normalize"("public"."sparsevec") TO "postgres";
GRANT ALL ON FUNCTION "public"."l2_normalize"("public"."sparsevec") TO "anon";
GRANT ALL ON FUNCTION "public"."l2_normalize"("public"."sparsevec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."l2_normalize"("public"."sparsevec") TO "service_role";
GRANT ALL ON FUNCTION "public"."l2_normalize"("public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."l2_normalize"("public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."l2_normalize"("public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."l2_normalize"("public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."predict_similarity"("term1" "text", "nice_class1" integer, "term2" "text", "nice_class2" integer) TO "anon";
GRANT ALL ON FUNCTION "public"."predict_similarity"("term1" "text", "nice_class1" integer, "term2" "text", "nice_class2" integer) TO "authenticated";
GRANT ALL ON FUNCTION "public"."predict_similarity"("term1" "text", "nice_class1" integer, "term2" "text", "nice_class2" integer) TO "service_role";
GRANT ALL ON FUNCTION "public"."rollback_transaction"() TO "anon";
GRANT ALL ON FUNCTION "public"."rollback_transaction"() TO "authenticated";
GRANT ALL ON FUNCTION "public"."rollback_transaction"() TO "service_role";
GRANT ALL ON FUNCTION "public"."set_limit"(real) TO "postgres";
GRANT ALL ON FUNCTION "public"."set_limit"(real) TO "anon";
GRANT ALL ON FUNCTION "public"."set_limit"(real) TO "authenticated";
GRANT ALL ON FUNCTION "public"."set_limit"(real) TO "service_role";
GRANT ALL ON FUNCTION "public"."show_limit"() TO "postgres";
GRANT ALL ON FUNCTION "public"."show_limit"() TO "anon";
GRANT ALL ON FUNCTION "public"."show_limit"() TO "authenticated";
GRANT ALL ON FUNCTION "public"."show_limit"() TO "service_role";
GRANT ALL ON FUNCTION "public"."show_trgm"("text") TO "postgres";
GRANT ALL ON FUNCTION "public"."show_trgm"("text") TO "anon";
GRANT ALL ON FUNCTION "public"."show_trgm"("text") TO "authenticated";
GRANT ALL ON FUNCTION "public"."show_trgm"("text") TO "service_role";
GRANT ALL ON FUNCTION "public"."similarity"("text", "text") TO "postgres";
GRANT ALL ON FUNCTION "public"."similarity"("text", "text") TO "anon";
GRANT ALL ON FUNCTION "public"."similarity"("text", "text") TO "authenticated";
GRANT ALL ON FUNCTION "public"."similarity"("text", "text") TO "service_role";
GRANT ALL ON FUNCTION "public"."similarity_dist"("text", "text") TO "postgres";
GRANT ALL ON FUNCTION "public"."similarity_dist"("text", "text") TO "anon";
GRANT ALL ON FUNCTION "public"."similarity_dist"("text", "text") TO "authenticated";
GRANT ALL ON FUNCTION "public"."similarity_dist"("text", "text") TO "service_role";
GRANT ALL ON FUNCTION "public"."similarity_op"("text", "text") TO "postgres";
GRANT ALL ON FUNCTION "public"."similarity_op"("text", "text") TO "anon";
GRANT ALL ON FUNCTION "public"."similarity_op"("text", "text") TO "authenticated";
GRANT ALL ON FUNCTION "public"."similarity_op"("text", "text") TO "service_role";
GRANT ALL ON FUNCTION "public"."sparsevec_cmp"("public"."sparsevec", "public"."sparsevec") TO "postgres";
GRANT ALL ON FUNCTION "public"."sparsevec_cmp"("public"."sparsevec", "public"."sparsevec") TO "anon";
GRANT ALL ON FUNCTION "public"."sparsevec_cmp"("public"."sparsevec", "public"."sparsevec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."sparsevec_cmp"("public"."sparsevec", "public"."sparsevec") TO "service_role";
GRANT ALL ON FUNCTION "public"."sparsevec_eq"("public"."sparsevec", "public"."sparsevec") TO "postgres";
GRANT ALL ON FUNCTION "public"."sparsevec_eq"("public"."sparsevec", "public"."sparsevec") TO "anon";
GRANT ALL ON FUNCTION "public"."sparsevec_eq"("public"."sparsevec", "public"."sparsevec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."sparsevec_eq"("public"."sparsevec", "public"."sparsevec") TO "service_role";
GRANT ALL ON FUNCTION "public"."sparsevec_ge"("public"."sparsevec", "public"."sparsevec") TO "postgres";
GRANT ALL ON FUNCTION "public"."sparsevec_ge"("public"."sparsevec", "public"."sparsevec") TO "anon";
GRANT ALL ON FUNCTION "public"."sparsevec_ge"("public"."sparsevec", "public"."sparsevec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."sparsevec_ge"("public"."sparsevec", "public"."sparsevec") TO "service_role";
GRANT ALL ON FUNCTION "public"."sparsevec_gt"("public"."sparsevec", "public"."sparsevec") TO "postgres";
GRANT ALL ON FUNCTION "public"."sparsevec_gt"("public"."sparsevec", "public"."sparsevec") TO "anon";
GRANT ALL ON FUNCTION "public"."sparsevec_gt"("public"."sparsevec", "public"."sparsevec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."sparsevec_gt"("public"."sparsevec", "public"."sparsevec") TO "service_role";
GRANT ALL ON FUNCTION "public"."sparsevec_l2_squared_distance"("public"."sparsevec", "public"."sparsevec") TO "postgres";
GRANT ALL ON FUNCTION "public"."sparsevec_l2_squared_distance"("public"."sparsevec", "public"."sparsevec") TO "anon";
GRANT ALL ON FUNCTION "public"."sparsevec_l2_squared_distance"("public"."sparsevec", "public"."sparsevec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."sparsevec_l2_squared_distance"("public"."sparsevec", "public"."sparsevec") TO "service_role";
GRANT ALL ON FUNCTION "public"."sparsevec_le"("public"."sparsevec", "public"."sparsevec") TO "postgres";
GRANT ALL ON FUNCTION "public"."sparsevec_le"("public"."sparsevec", "public"."sparsevec") TO "anon";
GRANT ALL ON FUNCTION "public"."sparsevec_le"("public"."sparsevec", "public"."sparsevec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."sparsevec_le"("public"."sparsevec", "public"."sparsevec") TO "service_role";
GRANT ALL ON FUNCTION "public"."sparsevec_lt"("public"."sparsevec", "public"."sparsevec") TO "postgres";
GRANT ALL ON FUNCTION "public"."sparsevec_lt"("public"."sparsevec", "public"."sparsevec") TO "anon";
GRANT ALL ON FUNCTION "public"."sparsevec_lt"("public"."sparsevec", "public"."sparsevec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."sparsevec_lt"("public"."sparsevec", "public"."sparsevec") TO "service_role";
GRANT ALL ON FUNCTION "public"."sparsevec_ne"("public"."sparsevec", "public"."sparsevec") TO "postgres";
GRANT ALL ON FUNCTION "public"."sparsevec_ne"("public"."sparsevec", "public"."sparsevec") TO "anon";
GRANT ALL ON FUNCTION "public"."sparsevec_ne"("public"."sparsevec", "public"."sparsevec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."sparsevec_ne"("public"."sparsevec", "public"."sparsevec") TO "service_role";
GRANT ALL ON FUNCTION "public"."sparsevec_negative_inner_product"("public"."sparsevec", "public"."sparsevec") TO "postgres";
GRANT ALL ON FUNCTION "public"."sparsevec_negative_inner_product"("public"."sparsevec", "public"."sparsevec") TO "anon";
GRANT ALL ON FUNCTION "public"."sparsevec_negative_inner_product"("public"."sparsevec", "public"."sparsevec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."sparsevec_negative_inner_product"("public"."sparsevec", "public"."sparsevec") TO "service_role";
GRANT ALL ON FUNCTION "public"."strict_word_similarity"("text", "text") TO "postgres";
GRANT ALL ON FUNCTION "public"."strict_word_similarity"("text", "text") TO "anon";
GRANT ALL ON FUNCTION "public"."strict_word_similarity"("text", "text") TO "authenticated";
GRANT ALL ON FUNCTION "public"."strict_word_similarity"("text", "text") TO "service_role";
GRANT ALL ON FUNCTION "public"."strict_word_similarity_commutator_op"("text", "text") TO "postgres";
GRANT ALL ON FUNCTION "public"."strict_word_similarity_commutator_op"("text", "text") TO "anon";
GRANT ALL ON FUNCTION "public"."strict_word_similarity_commutator_op"("text", "text") TO "authenticated";
GRANT ALL ON FUNCTION "public"."strict_word_similarity_commutator_op"("text", "text") TO "service_role";
GRANT ALL ON FUNCTION "public"."strict_word_similarity_dist_commutator_op"("text", "text") TO "postgres";
GRANT ALL ON FUNCTION "public"."strict_word_similarity_dist_commutator_op"("text", "text") TO "anon";
GRANT ALL ON FUNCTION "public"."strict_word_similarity_dist_commutator_op"("text", "text") TO "authenticated";
GRANT ALL ON FUNCTION "public"."strict_word_similarity_dist_commutator_op"("text", "text") TO "service_role";
GRANT ALL ON FUNCTION "public"."strict_word_similarity_dist_op"("text", "text") TO "postgres";
GRANT ALL ON FUNCTION "public"."strict_word_similarity_dist_op"("text", "text") TO "anon";
GRANT ALL ON FUNCTION "public"."strict_word_similarity_dist_op"("text", "text") TO "authenticated";
GRANT ALL ON FUNCTION "public"."strict_word_similarity_dist_op"("text", "text") TO "service_role";
GRANT ALL ON FUNCTION "public"."strict_word_similarity_op"("text", "text") TO "postgres";
GRANT ALL ON FUNCTION "public"."strict_word_similarity_op"("text", "text") TO "anon";
GRANT ALL ON FUNCTION "public"."strict_word_similarity_op"("text", "text") TO "authenticated";
GRANT ALL ON FUNCTION "public"."strict_word_similarity_op"("text", "text") TO "service_role";
GRANT ALL ON FUNCTION "public"."subvector"("public"."halfvec", integer, integer) TO "postgres";
GRANT ALL ON FUNCTION "public"."subvector"("public"."halfvec", integer, integer) TO "anon";
GRANT ALL ON FUNCTION "public"."subvector"("public"."halfvec", integer, integer) TO "authenticated";
GRANT ALL ON FUNCTION "public"."subvector"("public"."halfvec", integer, integer) TO "service_role";
GRANT ALL ON FUNCTION "public"."subvector"("public"."vector", integer, integer) TO "postgres";
GRANT ALL ON FUNCTION "public"."subvector"("public"."vector", integer, integer) TO "anon";
GRANT ALL ON FUNCTION "public"."subvector"("public"."vector", integer, integer) TO "authenticated";
GRANT ALL ON FUNCTION "public"."subvector"("public"."vector", integer, integer) TO "service_role";
GRANT ALL ON FUNCTION "public"."update_timestamp"() TO "anon";
GRANT ALL ON FUNCTION "public"."update_timestamp"() TO "authenticated";
GRANT ALL ON FUNCTION "public"."update_timestamp"() TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_accum"(double precision[], "public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_accum"(double precision[], "public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."vector_accum"(double precision[], "public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_accum"(double precision[], "public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_add"("public"."vector", "public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_add"("public"."vector", "public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."vector_add"("public"."vector", "public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_add"("public"."vector", "public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_avg"(double precision[]) TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_avg"(double precision[]) TO "anon";
GRANT ALL ON FUNCTION "public"."vector_avg"(double precision[]) TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_avg"(double precision[]) TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_cmp"("public"."vector", "public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_cmp"("public"."vector", "public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."vector_cmp"("public"."vector", "public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_cmp"("public"."vector", "public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_combine"(double precision[], double precision[]) TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_combine"(double precision[], double precision[]) TO "anon";
GRANT ALL ON FUNCTION "public"."vector_combine"(double precision[], double precision[]) TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_combine"(double precision[], double precision[]) TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_concat"("public"."vector", "public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_concat"("public"."vector", "public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."vector_concat"("public"."vector", "public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_concat"("public"."vector", "public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_dims"("public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_dims"("public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."vector_dims"("public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_dims"("public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_dims"("public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_dims"("public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."vector_dims"("public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_dims"("public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_eq"("public"."vector", "public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_eq"("public"."vector", "public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."vector_eq"("public"."vector", "public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_eq"("public"."vector", "public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_ge"("public"."vector", "public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_ge"("public"."vector", "public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."vector_ge"("public"."vector", "public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_ge"("public"."vector", "public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_gt"("public"."vector", "public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_gt"("public"."vector", "public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."vector_gt"("public"."vector", "public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_gt"("public"."vector", "public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_l2_squared_distance"("public"."vector", "public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_l2_squared_distance"("public"."vector", "public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."vector_l2_squared_distance"("public"."vector", "public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_l2_squared_distance"("public"."vector", "public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_le"("public"."vector", "public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_le"("public"."vector", "public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."vector_le"("public"."vector", "public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_le"("public"."vector", "public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_lt"("public"."vector", "public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_lt"("public"."vector", "public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."vector_lt"("public"."vector", "public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_lt"("public"."vector", "public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_mul"("public"."vector", "public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_mul"("public"."vector", "public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."vector_mul"("public"."vector", "public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_mul"("public"."vector", "public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_ne"("public"."vector", "public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_ne"("public"."vector", "public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."vector_ne"("public"."vector", "public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_ne"("public"."vector", "public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_negative_inner_product"("public"."vector", "public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_negative_inner_product"("public"."vector", "public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."vector_negative_inner_product"("public"."vector", "public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_negative_inner_product"("public"."vector", "public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_norm"("public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_norm"("public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."vector_norm"("public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_norm"("public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_spherical_distance"("public"."vector", "public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_spherical_distance"("public"."vector", "public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."vector_spherical_distance"("public"."vector", "public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_spherical_distance"("public"."vector", "public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."vector_sub"("public"."vector", "public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."vector_sub"("public"."vector", "public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."vector_sub"("public"."vector", "public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."vector_sub"("public"."vector", "public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."word_similarity"("text", "text") TO "postgres";
GRANT ALL ON FUNCTION "public"."word_similarity"("text", "text") TO "anon";
GRANT ALL ON FUNCTION "public"."word_similarity"("text", "text") TO "authenticated";
GRANT ALL ON FUNCTION "public"."word_similarity"("text", "text") TO "service_role";
GRANT ALL ON FUNCTION "public"."word_similarity_commutator_op"("text", "text") TO "postgres";
GRANT ALL ON FUNCTION "public"."word_similarity_commutator_op"("text", "text") TO "anon";
GRANT ALL ON FUNCTION "public"."word_similarity_commutator_op"("text", "text") TO "authenticated";
GRANT ALL ON FUNCTION "public"."word_similarity_commutator_op"("text", "text") TO "service_role";
GRANT ALL ON FUNCTION "public"."word_similarity_dist_commutator_op"("text", "text") TO "postgres";
GRANT ALL ON FUNCTION "public"."word_similarity_dist_commutator_op"("text", "text") TO "anon";
GRANT ALL ON FUNCTION "public"."word_similarity_dist_commutator_op"("text", "text") TO "authenticated";
GRANT ALL ON FUNCTION "public"."word_similarity_dist_commutator_op"("text", "text") TO "service_role";
GRANT ALL ON FUNCTION "public"."word_similarity_dist_op"("text", "text") TO "postgres";
GRANT ALL ON FUNCTION "public"."word_similarity_dist_op"("text", "text") TO "anon";
GRANT ALL ON FUNCTION "public"."word_similarity_dist_op"("text", "text") TO "authenticated";
GRANT ALL ON FUNCTION "public"."word_similarity_dist_op"("text", "text") TO "service_role";
GRANT ALL ON FUNCTION "public"."word_similarity_op"("text", "text") TO "postgres";
GRANT ALL ON FUNCTION "public"."word_similarity_op"("text", "text") TO "anon";
GRANT ALL ON FUNCTION "public"."word_similarity_op"("text", "text") TO "authenticated";
GRANT ALL ON FUNCTION "public"."word_similarity_op"("text", "text") TO "service_role";
GRANT ALL ON FUNCTION "public"."avg"("public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."avg"("public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."avg"("public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."avg"("public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."avg"("public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."avg"("public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."avg"("public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."avg"("public"."vector") TO "service_role";
GRANT ALL ON FUNCTION "public"."sum"("public"."halfvec") TO "postgres";
GRANT ALL ON FUNCTION "public"."sum"("public"."halfvec") TO "anon";
GRANT ALL ON FUNCTION "public"."sum"("public"."halfvec") TO "authenticated";
GRANT ALL ON FUNCTION "public"."sum"("public"."halfvec") TO "service_role";
GRANT ALL ON FUNCTION "public"."sum"("public"."vector") TO "postgres";
GRANT ALL ON FUNCTION "public"."sum"("public"."vector") TO "anon";
GRANT ALL ON FUNCTION "public"."sum"("public"."vector") TO "authenticated";
GRANT ALL ON FUNCTION "public"."sum"("public"."vector") TO "service_role";
GRANT ALL ON TABLE "public"."applicant_goods_services" TO "anon";
GRANT ALL ON TABLE "public"."applicant_goods_services" TO "authenticated";
GRANT ALL ON TABLE "public"."applicant_goods_services" TO "service_role";
GRANT ALL ON SEQUENCE "public"."applicant_goods_services_id_seq" TO "anon";
GRANT ALL ON SEQUENCE "public"."applicant_goods_services_id_seq" TO "authenticated";
GRANT ALL ON SEQUENCE "public"."applicant_goods_services_id_seq" TO "service_role";
GRANT ALL ON TABLE "public"."applicant_marks" TO "anon";
GRANT ALL ON TABLE "public"."applicant_marks" TO "authenticated";
GRANT ALL ON TABLE "public"."applicant_marks" TO "service_role";
GRANT ALL ON SEQUENCE "public"."applicant_marks_id_seq" TO "anon";
GRANT ALL ON SEQUENCE "public"."applicant_marks_id_seq" TO "authenticated";
GRANT ALL ON SEQUENCE "public"."applicant_marks_id_seq" TO "service_role";
GRANT ALL ON TABLE "public"."decision_rationales" TO "anon";
GRANT ALL ON TABLE "public"."decision_rationales" TO "authenticated";
GRANT ALL ON TABLE "public"."decision_rationales" TO "service_role";
GRANT ALL ON SEQUENCE "public"."decision_rationales_id_seq" TO "anon";
GRANT ALL ON SEQUENCE "public"."decision_rationales_id_seq" TO "authenticated";
GRANT ALL ON SEQUENCE "public"."decision_rationales_id_seq" TO "service_role";
GRANT ALL ON TABLE "public"."goods_services" TO "anon";
GRANT ALL ON TABLE "public"."goods_services" TO "authenticated";
GRANT ALL ON TABLE "public"."goods_services" TO "service_role";
GRANT ALL ON TABLE "public"."goods_services_comparisons" TO "anon";
GRANT ALL ON TABLE "public"."goods_services_comparisons" TO "authenticated";
GRANT ALL ON TABLE "public"."goods_services_comparisons" TO "service_role";
GRANT ALL ON SEQUENCE "public"."goods_services_comparisons_id_seq" TO "anon";
GRANT ALL ON SEQUENCE "public"."goods_services_comparisons_id_seq" TO "authenticated";
GRANT ALL ON SEQUENCE "public"."goods_services_comparisons_id_seq" TO "service_role";
GRANT ALL ON SEQUENCE "public"."goods_services_id_seq" TO "anon";
GRANT ALL ON SEQUENCE "public"."goods_services_id_seq" TO "authenticated";
GRANT ALL ON SEQUENCE "public"."goods_services_id_seq" TO "service_role";
GRANT ALL ON TABLE "public"."mark_comparisons" TO "anon";
GRANT ALL ON TABLE "public"."mark_comparisons" TO "authenticated";
GRANT ALL ON TABLE "public"."mark_comparisons" TO "service_role";
GRANT ALL ON SEQUENCE "public"."mark_comparisons_id_seq" TO "anon";
GRANT ALL ON SEQUENCE "public"."mark_comparisons_id_seq" TO "authenticated";
GRANT ALL ON SEQUENCE "public"."mark_comparisons_id_seq" TO "service_role";
GRANT ALL ON TABLE "public"."opponent_goods_services" TO "anon";
GRANT ALL ON TABLE "public"."opponent_goods_services" TO "authenticated";
GRANT ALL ON TABLE "public"."opponent_goods_services" TO "service_role";
GRANT ALL ON SEQUENCE "public"."opponent_goods_services_id_seq" TO "anon";
GRANT ALL ON SEQUENCE "public"."opponent_goods_services_id_seq" TO "authenticated";
GRANT ALL ON SEQUENCE "public"."opponent_goods_services_id_seq" TO "service_role";
GRANT ALL ON TABLE "public"."opponent_marks" TO "anon";
GRANT ALL ON TABLE "public"."opponent_marks" TO "authenticated";
GRANT ALL ON TABLE "public"."opponent_marks" TO "service_role";
GRANT ALL ON SEQUENCE "public"."opponent_marks_id_seq" TO "anon";
GRANT ALL ON SEQUENCE "public"."opponent_marks_id_seq" TO "authenticated";
GRANT ALL ON SEQUENCE "public"."opponent_marks_id_seq" TO "service_role";
GRANT ALL ON TABLE "public"."opposition_grounds" TO "anon";
GRANT ALL ON TABLE "public"."opposition_grounds" TO "authenticated";
GRANT ALL ON TABLE "public"."opposition_grounds" TO "service_role";
GRANT ALL ON SEQUENCE "public"."opposition_grounds_id_seq" TO "anon";
GRANT ALL ON SEQUENCE "public"."opposition_grounds_id_seq" TO "authenticated";
GRANT ALL ON SEQUENCE "public"."opposition_grounds_id_seq" TO "service_role";
GRANT ALL ON TABLE "public"."precedents_cited" TO "anon";
GRANT ALL ON TABLE "public"."precedents_cited" TO "authenticated";
GRANT ALL ON TABLE "public"."precedents_cited" TO "service_role";
GRANT ALL ON SEQUENCE "public"."precedents_cited_id_seq" TO "anon";
GRANT ALL ON SEQUENCE "public"."precedents_cited_id_seq" TO "authenticated";
GRANT ALL ON SEQUENCE "public"."precedents_cited_id_seq" TO "service_role";
GRANT ALL ON TABLE "public"."trademark_cases" TO "anon";
GRANT ALL ON TABLE "public"."trademark_cases" TO "authenticated";
GRANT ALL ON TABLE "public"."trademark_cases" TO "service_role";
GRANT ALL ON TABLE "public"."vector_embeddings" TO "anon";
GRANT ALL ON TABLE "public"."vector_embeddings" TO "authenticated";
GRANT ALL ON TABLE "public"."vector_embeddings" TO "service_role";
GRANT ALL ON SEQUENCE "public"."vector_embeddings_id_seq" TO "anon";
GRANT ALL ON SEQUENCE "public"."vector_embeddings_id_seq" TO "authenticated";
GRANT ALL ON SEQUENCE "public"."vector_embeddings_id_seq" TO "service_role";
ALTER DEFAULT PRIVILEGES FOR ROLE "postgres" IN SCHEMA "public" GRANT ALL ON SEQUENCES  TO "postgres";
ALTER DEFAULT PRIVILEGES FOR ROLE "postgres" IN SCHEMA "public" GRANT ALL ON SEQUENCES  TO "anon";
ALTER DEFAULT PRIVILEGES FOR ROLE "postgres" IN SCHEMA "public" GRANT ALL ON SEQUENCES  TO "authenticated";
ALTER DEFAULT PRIVILEGES FOR ROLE "postgres" IN SCHEMA "public" GRANT ALL ON SEQUENCES  TO "service_role";
ALTER DEFAULT PRIVILEGES FOR ROLE "postgres" IN SCHEMA "public" GRANT ALL ON FUNCTIONS  TO "postgres";
ALTER DEFAULT PRIVILEGES FOR ROLE "postgres" IN SCHEMA "public" GRANT ALL ON FUNCTIONS  TO "anon";
ALTER DEFAULT PRIVILEGES FOR ROLE "postgres" IN SCHEMA "public" GRANT ALL ON FUNCTIONS  TO "authenticated";
ALTER DEFAULT PRIVILEGES FOR ROLE "postgres" IN SCHEMA "public" GRANT ALL ON FUNCTIONS  TO "service_role";
ALTER DEFAULT PRIVILEGES FOR ROLE "postgres" IN SCHEMA "public" GRANT ALL ON TABLES  TO "postgres";
ALTER DEFAULT PRIVILEGES FOR ROLE "postgres" IN SCHEMA "public" GRANT ALL ON TABLES  TO "anon";
ALTER DEFAULT PRIVILEGES FOR ROLE "postgres" IN SCHEMA "public" GRANT ALL ON TABLES  TO "authenticated";
ALTER DEFAULT PRIVILEGES FOR ROLE "postgres" IN SCHEMA "public" GRANT ALL ON TABLES  TO "service_role";
RESET ALL;



================================================
FILE: supabase/migrations/_alter_embedding_dimension.sql
================================================
ALTER TABLE public.vector_embeddings ALTER COLUMN embedding TYPE vector(384) USING embedding::vector(384);



================================================
FILE: tests/__init__.py
================================================
# tests/__init__.py
"""Tests package for the Trademark AI Agent."""



================================================
FILE: tests/test_main.py
================================================
# tests/test_main.py
"""Placeholder tests for the main Cloud Function entry point."""

from typing import TYPE_CHECKING

if TYPE_CHECKING:
    import pytest


def test_placeholder() -> None:
    """A placeholder test to ensure the test suite runs."""
    assert True



================================================
FILE: tests/test_prediction_tools.py
================================================
# tests/test_prediction_tools.py
"""Tests for trademark opposition prediction tools."""

import pytest
from typing import Dict, Optional

from src.models import (
    PredictionTaskInput,
    SimilarityScores,
    Trademark,
    Wordmark,
    GoodsService,
)
from src.tools.prediction_tools import (
    PredictionInput,
    predict_opposition_outcome_tool,
    _calculate_weighted_score,
)


# --- Test Data Setup ---

def create_test_trademark(identifier: str, mark_text: str, terms: Dict[str, int]) -> Trademark:
    """
    Helper function to create test trademark objects.
    
    Args:
        identifier: Trademark identifier
        mark_text: The text of the wordmark
        terms: Dict mapping term text to nice_class
        
    Returns:
        A Trademark object for testing
    """
    goods_services = [
        GoodsService(term=term, nice_class=nice_class)
        for term, nice_class in terms.items()
    ]
    
    return Trademark(
        identifier=identifier,
        wordmark=Wordmark(mark_text=mark_text),
        goods_services=goods_services
    )


def create_test_scores(
    visual: Optional[float] = None,
    aural: Optional[float] = None,
    conceptual: Optional[float] = None,
    goods_services: Optional[float] = None
) -> SimilarityScores:
    """
    Helper function to create test similarity scores.
    
    Args:
        visual: Visual similarity score (0.0-1.0)
        aural: Aural similarity score (0.0-1.0)
        conceptual: Conceptual similarity score (0.0-1.0)
        goods_services: Goods/services similarity score (0.0-1.0)
        
    Returns:
        A SimilarityScores object for testing
    """
    return SimilarityScores(
        visual_similarity=visual,
        aural_similarity=aural,
        conceptual_similarity=conceptual,
        goods_services_similarity=goods_services
    )


# --- Test Setup ---

# Test case for high similarity in all dimensions
HIGH_SIMILARITY_CASE = PredictionTaskInput(
    applicant_trademark=create_test_trademark(
        "APP123", "ACME", {"Software": 9, "Software development": 42}
    ),
    opponent_trademark=create_test_trademark(
        "OPP456", "ACMEE", {"Computer software": 9, "Programming services": 42}
    ),
    similarity_scores=create_test_scores(
        visual=0.8, aural=0.9, conceptual=0.8, goods_services=0.85
    )
)

# Test case for medium similarity
MEDIUM_SIMILARITY_CASE = PredictionTaskInput(
    applicant_trademark=create_test_trademark(
        "APP789", "BLUEFIN", {"Financial services": 36}
    ),
    opponent_trademark=create_test_trademark(
        "OPP012", "BLUEFOX", {"Banking services": 36}
    ),
    similarity_scores=create_test_scores(
        visual=0.6, aural=0.7, conceptual=0.5, goods_services=0.6
    )
)

# Test case for low similarity
LOW_SIMILARITY_CASE = PredictionTaskInput(
    applicant_trademark=create_test_trademark(
        "APP345", "MOUNTAINVIEW", {"Clothing": 25}
    ),
    opponent_trademark=create_test_trademark(
        "OPP678", "SEAVIEW", {"Food products": 30}
    ),
    similarity_scores=create_test_scores(
        visual=0.3, aural=0.2, conceptual=0.4, goods_services=0.1
    )
)

# Test case with missing scores
INCOMPLETE_SCORES_CASE = PredictionTaskInput(
    applicant_trademark=create_test_trademark(
        "APP901", "PARTIAL", {"Toys": 28}
    ),
    opponent_trademark=create_test_trademark(
        "OPP234", "PORTION", {"Games": 28}
    ),
    similarity_scores=create_test_scores(
        visual=0.5, aural=None, conceptual=0.6, goods_services=None
    )
)


# --- Tests ---

def test_weighted_score_calculation_complete_scores():
    """Test calculation of weighted scores with complete input."""
    scores = create_test_scores(
        visual=0.8, aural=0.6, conceptual=0.7, goods_services=0.9
    )
    
    weighted_score = _calculate_weighted_score(scores)
    
    # Expected: (0.8*0.3) + (0.6*0.3) + (0.7*0.1) + (0.9*0.3) = 0.76
    expected_score = 0.76
    assert weighted_score == pytest.approx(expected_score, abs=0.01)


def test_weighted_score_calculation_missing_scores():
    """Test calculation of weighted scores with some missing inputs."""
    scores = create_test_scores(
        visual=0.8, aural=None, conceptual=0.7, goods_services=0.9
    )
    
    weighted_score = _calculate_weighted_score(scores)
    
    # With aural missing, weights should be adjusted
    # Expected: (0.8*0.3) + (0.7*0.1) + (0.9*0.3) = 0.65, normalized by 0.7
    expected_score = 0.24 + 0.07 + 0.27
    expected_normalized = expected_score / 0.7
    assert weighted_score == pytest.approx(expected_normalized, abs=0.01)


def test_weighted_score_calculation_all_scores_missing():
    """Test calculation of weighted scores with all inputs missing."""
    scores = create_test_scores(
        visual=None, aural=None, conceptual=None, goods_services=None
    )
    
    weighted_score = _calculate_weighted_score(scores)
    
    # Should return None when no scores are available
    assert weighted_score is None


def test_prediction_high_similarity():
    """Test prediction with high similarity scores."""
    prediction_input = PredictionInput(prediction_task=HIGH_SIMILARITY_CASE)
    
    result = predict_opposition_outcome_tool(prediction_input)
    
    # Should predict successful opposition with high confidence
    assert "Succeed" in result.predicted_outcome
    assert result.confidence_score is not None
    assert result.confidence_score > 0.7
    assert result.reasoning is not None
    assert "likelihood of confusion" in result.reasoning.lower()


def test_prediction_medium_similarity():
    """Test prediction with medium similarity scores."""
    prediction_input = PredictionInput(prediction_task=MEDIUM_SIMILARITY_CASE)
    
    result = predict_opposition_outcome_tool(prediction_input)
    
    # Should predict partial success with medium confidence
    assert "Partially" in result.predicted_outcome
    assert result.confidence_score is not None
    assert 0.5 <= result.confidence_score <= 0.8
    assert result.reasoning is not None


def test_prediction_low_similarity():
    """Test prediction with low similarity scores."""
    prediction_input = PredictionInput(prediction_task=LOW_SIMILARITY_CASE)
    
    result = predict_opposition_outcome_tool(prediction_input)
    
    # Should predict unsuccessful opposition with medium-low confidence
    assert "Unlikely" in result.predicted_outcome
    assert result.confidence_score is not None
    assert result.confidence_score < 0.7
    assert result.reasoning is not None
    assert "differences" in result.reasoning.lower()


def test_prediction_missing_scores():
    """Test prediction with some missing similarity scores."""
    prediction_input = PredictionInput(prediction_task=INCOMPLETE_SCORES_CASE)
    
    result = predict_opposition_outcome_tool(prediction_input)
    
    # Should still produce a prediction
    assert result.predicted_outcome is not None
    assert result.confidence_score is not None
    assert result.reasoning is not None


def test_prediction_reasoning_content():
    """Test that prediction reasoning contains appropriate legal concepts."""
    prediction_input = PredictionInput(prediction_task=HIGH_SIMILARITY_CASE)
    
    result = predict_opposition_outcome_tool(prediction_input)
    
    # Should mention relevant legal principles
    assert "interdependence principle" in result.reasoning.lower()
    assert "similarity" in result.reasoning.lower()
    assert any(score_type in result.reasoning.lower() for score_type in 
              ["visual", "aural", "conceptual", "goods/services"])


def test_prediction_interdependence_principle():
    """Test that the prediction applies the interdependence principle correctly."""
    # Create a case with low visual but high goods/services similarity
    mixed_case = PredictionTaskInput(
        applicant_trademark=create_test_trademark(
            "APP555", "TOTALLY_DIFFERENT", {"Computer software": 9}
        ),
        opponent_trademark=create_test_trademark(
            "OPP555", "COMPLETELY_UNLIKE", {"Software programming": 9}
        ),
        similarity_scores=create_test_scores(
            visual=0.1, aural=0.2, conceptual=0.3, goods_services=0.9
        )
    )
    
    prediction_input = PredictionInput(prediction_task=mixed_case)
    result = predict_opposition_outcome_tool(prediction_input)
    
    # Even with low mark similarity, high goods/services similarity
    # should result in at least some possibility of confusion
    assert result.predicted_outcome != "Opposition Unlikely to Succeed" 


================================================
FILE: tests/test_similarity_all.py
================================================
# tests/test_similarity_all.py
"""
Comprehensive tests for all trademark similarity calculation functions.
Includes tests for visual, aural, conceptual, and goods/services similarity.
"""
import asyncio
import pytest
import pytest_asyncio
from typing import List, Optional

from src.models import Wordmark, GoodsService
from src.similarity import (
    calculate_visual_similarity,
    calculate_aural_similarity,
    calculate_conceptual_similarity,
    calculate_goods_services_similarity
)
from src.db import get_async_session


# ---- Visual Similarity Tests ----

def test_visual_identical_wordmarks() -> None:
    """Test visual similarity with identical wordmarks expects 1.0."""
    mark1 = Wordmark(mark_text="TRADEMARK")
    mark2 = Wordmark(mark_text="TRADEMARK")
    expected_similarity = 1.0
    actual_similarity = calculate_visual_similarity(mark1, mark2)
    assert actual_similarity == pytest.approx(expected_similarity)


def test_visual_completely_different_wordmarks() -> None:
    """Test visual similarity with completely different wordmarks expects low value."""
    mark1 = Wordmark(mark_text="ABCDEFG")
    mark2 = Wordmark(mark_text="XYZ")
    expected_similarity = 0.0
    actual_similarity = calculate_visual_similarity(mark1, mark2)
    assert actual_similarity == pytest.approx(expected_similarity)


def test_visual_case_insensitivity() -> None:
    """Test visual similarity is case-insensitive."""
    mark1 = Wordmark(mark_text="TradeMark")
    mark2 = Wordmark(mark_text="trademark")
    expected_similarity = 1.0
    actual_similarity = calculate_visual_similarity(mark1, mark2)
    assert actual_similarity == pytest.approx(expected_similarity)


@pytest.mark.parametrize(
    "text1, text2, expected_similarity",
    [
        ("sitting", "kitten", 0.61538),
        ("sunday", "saturday", 0.71429),
        ("flaw", "lawn", 0.75),
        ("trademark", "trademar", 0.94118),
    ],
    ids=["substitute", "insert_delete", "mixed", "deletion_end"]
)
def test_visual_minor_variations(text1: str, text2: str, expected_similarity: float) -> None:
    """Test visual similarity with minor variations."""
    mark1 = Wordmark(mark_text=text1)
    mark2 = Wordmark(mark_text=text2)
    actual_similarity = calculate_visual_similarity(mark1, mark2)
    assert actual_similarity == pytest.approx(expected_similarity, abs=1e-5)


# ---- Aural Similarity Tests ----

def test_aural_identical_wordmarks() -> None:
    """Test aural similarity with identical wordmarks expects 1.0."""
    mark1 = Wordmark(mark_text="EXAMPLE")
    mark2 = Wordmark(mark_text="EXAMPLE")
    similarity = calculate_aural_similarity(mark1, mark2)
    assert similarity == pytest.approx(1.0)


def test_aural_phonetically_similar_wordmarks() -> None:
    """Test aural similarity with phonetically similar but visually different wordmarks."""
    mark1 = Wordmark(mark_text="NIGHT")
    mark2 = Wordmark(mark_text="NITE")
    similarity = calculate_aural_similarity(mark1, mark2)
    assert similarity > 0.7, "Phonetically similar words should have high aural similarity"


def test_aural_phonetically_different_wordmarks() -> None:
    """Test aural similarity with phonetically different wordmarks."""
    mark1 = Wordmark(mark_text="APPLE")
    mark2 = Wordmark(mark_text="CHAIR")
    similarity = calculate_aural_similarity(mark1, mark2)
    assert similarity < 0.5, "Phonetically different words should have low aural similarity"


@pytest.mark.parametrize(
    "text1, text2, expected_min_similarity",
    [
        ("COUGH", "KOFF", 0.7),
        ("PHARMACY", "FARMACY", 0.7),
        ("PHONE", "FONE", 0.7),
        ("EXPRESS", "XPRESS", 0.7),
    ],
    ids=["c-k sounds", "ph-f sounds", "ph-f initial", "ex-x initial"]
)
def test_aural_common_phonetic_equivalents(text1: str, text2: str, expected_min_similarity: float) -> None:
    """Test aural similarity with common phonetic equivalents."""
    mark1 = Wordmark(mark_text=text1)
    mark2 = Wordmark(mark_text=text2)
    actual_similarity = calculate_aural_similarity(mark1, mark2)
    assert actual_similarity >= expected_min_similarity, f"Expected at least {expected_min_similarity}, got {actual_similarity}"


def test_aural_empty_wordmarks() -> None:
    """Test aural similarity with empty wordmarks."""
    # Both empty
    mark1 = Wordmark(mark_text="")
    mark2 = Wordmark(mark_text="")
    similarity = calculate_aural_similarity(mark1, mark2)
    assert similarity == 1.0, "Two empty wordmarks should have aural similarity of 1.0"
    
    # One empty
    mark3 = Wordmark(mark_text="SOMETHING")
    similarity = calculate_aural_similarity(mark1, mark3)
    assert similarity == 0.0, "When one wordmark is empty, aural similarity should be 0.0"


# ---- Conceptual Similarity Tests ----

@pytest.mark.asyncio
async def test_conceptual_identical_wordmarks() -> None:
    """Test conceptual similarity with identical wordmarks expects 1.0."""
    mark1 = Wordmark(mark_text="EAGLE")
    mark2 = Wordmark(mark_text="EAGLE")
    similarity = await calculate_conceptual_similarity(mark1, mark2)
    assert similarity == pytest.approx(1.0)


@pytest.mark.asyncio
async def test_conceptual_synonyms() -> None:
    """Test conceptual similarity with synonyms."""
    mark1 = Wordmark(mark_text="QUICK")
    mark2 = Wordmark(mark_text="FAST")
    similarity = await calculate_conceptual_similarity(mark1, mark2)
    assert similarity >= 0.7, "Synonyms should have high conceptual similarity"


@pytest.mark.asyncio
async def test_conceptual_antonyms() -> None:
    """Test conceptual similarity with antonyms."""
    mark1 = Wordmark(mark_text="HOT")
    mark2 = Wordmark(mark_text="COLD")
    similarity = await calculate_conceptual_similarity(mark1, mark2)
    assert similarity >= 0.5, "Antonyms should have medium-high conceptual similarity in trademark context"


@pytest.mark.asyncio
async def test_conceptual_unrelated_wordmarks() -> None:
    """Test conceptual similarity with unrelated concepts."""
    mark1 = Wordmark(mark_text="APPLE")
    mark2 = Wordmark(mark_text="ROCKET")
    similarity = await calculate_conceptual_similarity(mark1, mark2)
    assert similarity < 0.5, "Unrelated concepts should have low conceptual similarity"


@pytest.mark.asyncio
async def test_conceptual_related_wordmarks() -> None:
    """Test conceptual similarity with related but not identical concepts."""
    mark1 = Wordmark(mark_text="LION")
    mark2 = Wordmark(mark_text="TIGER")
    similarity = await calculate_conceptual_similarity(mark1, mark2)
    assert 0.5 <= similarity <= 0.9, "Related animal concepts should have medium-high similarity"


@pytest.mark.asyncio
async def test_conceptual_same_stem_wordmarks() -> None:
    """Test conceptual similarity with words sharing the same stem."""
    mark1 = Wordmark(mark_text="RUNNER")
    mark2 = Wordmark(mark_text="RUNNING")
    similarity = await calculate_conceptual_similarity(mark1, mark2)
    assert similarity >= 0.7, "Words with the same stem should have high conceptual similarity"


@pytest.mark.asyncio
async def test_conceptual_color_wordmarks() -> None:
    """Test conceptual similarity with color words."""
    mark1 = Wordmark(mark_text="BLUE")
    mark2 = Wordmark(mark_text="RED")
    similarity = await calculate_conceptual_similarity(mark1, mark2)
    assert similarity >= 0.5, "Different colors should have medium conceptual similarity in trademark context"


@pytest.mark.asyncio
async def test_conceptual_empty_wordmarks() -> None:
    """Test conceptual similarity with empty wordmarks."""
    mark1 = Wordmark(mark_text="")
    mark2 = Wordmark(mark_text="CONCEPT")
    similarity = await calculate_conceptual_similarity(mark1, mark2)
    assert similarity is None, "Conceptual similarity with empty wordmark should be None"


@pytest.mark.asyncio
async def test_conceptual_legalbert_enhanced_analysis() -> None:
    """Test conceptual similarity with LegalBERT for legal domain semantic understanding."""
    # Legal terminology test
    mark1 = Wordmark(mark_text="LEGITIMATE")
    mark2 = Wordmark(mark_text="LAWFUL")
    similarity = await calculate_conceptual_similarity(mark1, mark2)
    assert similarity is not None
    assert similarity >= 0.65, "Legal terms should have higher similarity with LegalBERT"
    
    # Test with legal domain trademark pairs that should be conceptually related
    legal_pairs = [
        ("ROYAL PREMIUM", "LUXURY ELITE"),  # Luxury category
        ("CYBER TECH", "DIGITAL NET"),      # Tech category
        ("RED FOX", "BLUE TIGER"),          # Color + animal categories
    ]
    
    for mark_text1, mark_text2 in legal_pairs:
        mark1 = Wordmark(mark_text=mark_text1)
        mark2 = Wordmark(mark_text=mark_text2)
        similarity = await calculate_conceptual_similarity(mark1, mark2)
        assert similarity is not None
        assert similarity >= 0.5, f"Legal category match '{mark_text1}' and '{mark_text2}' should have higher similarity"


# ---- Goods/Services Similarity Tests ----

# Mock goods/services for testing
SOFTWARE_GOODS = [
    GoodsService(term="Computer software", nice_class=9),
    GoodsService(term="Software as a service", nice_class=42)
]

CLOTHING_GOODS = [
    GoodsService(term="Clothing", nice_class=25),
    GoodsService(term="T-shirts", nice_class=25)
]

FOOD_GOODS = [
    GoodsService(term="Coffee", nice_class=30),
    GoodsService(term="Bakery products", nice_class=30)
]

@pytest.mark.asyncio
@pytest.mark.integration  # Mark as integration test that requires DB
async def test_goods_services_identical_terms() -> None:
    """Test goods/services similarity with identical terms."""
    # This test requires database setup with embeddings stored
    similarity = await calculate_goods_services_similarity(
        SOFTWARE_GOODS, SOFTWARE_GOODS
    )
    # The function might return None if DB setup is not complete
    # Only assert if we got a valid result
    if similarity is not None:
        assert similarity > 0.8, "Identical goods/services should have high similarity"


@pytest.mark.asyncio
@pytest.mark.integration
async def test_goods_services_different_classes() -> None:
    """Test goods/services similarity with terms in different NICE classes."""
    # This test requires database setup with embeddings stored
    similarity = await calculate_goods_services_similarity(
        SOFTWARE_GOODS, CLOTHING_GOODS
    )
    # The function might return None if DB setup is not complete
    if similarity is not None:
        assert similarity < 0.5, "Terms in different classes should have lower similarity"


@pytest.mark.asyncio
@pytest.mark.integration
async def test_goods_services_related_terms() -> None:
    """Test goods/services similarity with related terms."""
    # Create related terms within software domain
    software_a = [GoodsService(term="Mobile application software", nice_class=9)]
    software_b = [GoodsService(term="Software development services", nice_class=42)]
    
    # This test requires database setup with embeddings stored
    similarity = await calculate_goods_services_similarity(
        software_a, software_b
    )
    # The function might return None if DB setup is not complete
    if similarity is not None:
        assert 0.5 <= similarity <= 0.9, "Related terms should have medium-high similarity"


@pytest.mark.asyncio
@pytest.mark.integration
async def test_goods_services_empty_list() -> None:
    """Test goods/services similarity with empty list."""
    empty_list: List[GoodsService] = []
    
    similarity = await calculate_goods_services_similarity(
        empty_list, SOFTWARE_GOODS
    )
    assert similarity == 0.0, "Empty applicant goods/services list should return 0.0"


# === Test Fixtures and Setup ===

@pytest_asyncio.fixture(scope="module")
async def setup_db():
    """Fixture to set up database for tests."""
    # This would typically initialize the database, create tables,
    # and possibly insert test data with embeddings
    
    # For now, just get the session maker to confirm DB is configured
    try:
        session_maker = await get_async_session()
        async with session_maker() as session:
            # Check if we can connect
            await session.execute(sqlalchemy.text("SELECT 1"))
        yield "Database setup complete"
    except Exception as e:
        pytest.skip(f"Database setup failed: {e}") 


